

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>3.3 Ejemplos de problemas UCO e introducción a Constrained Inequality and Equality Convex Optimization (CIECO) y puntos interiores</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/mystnb.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="3.4 Ecuaciones no lineales" href="../3.4/Ecuaciones_no_lineales.html" />
    <link rel="prev" title="3.2 Algoritmos de descenso y búsqueda de línea en Unconstrained Convex Optimization (UCO)" href="../3.2/Algoritmos_de_descenso_y_busqueda_de_linea_en_uco.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../README.html">
   Optimización
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  I. Cómputo científico
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.1/Analisis_numerico_y_computo_cientifico.html">
   1.1 Análisis numérico y cómputo científico
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.2/Sistema_de_punto_flotante.html">
   1.2 Sistema de punto flotante
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.3/Normas_vectoriales_y_matriciales.html">
   1.3 Normas vectoriales y matriciales
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.4/Condicion_de_un_problema_y_estabilidad_de_un_algoritmo.html">
   1.4 Condición de un problema y estabilidad de un algoritmo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.5/Definicion_de_funcion_continuidad_derivada.html">
   1.5 Definición de función, continuidad y derivada
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.6/Polinomios_de_Taylor_y_diferenciacion_numerica.html">
   1.6 Polinomios de Taylor y diferenciación numérica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.7/Integracion_numerica.html">
   1.7 Integración Numérica
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  II. Cómputo matricial
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.1/Operaciones_y_transformaciones_basicas_del_Algebra_Lineal_Numerica.html">
   2.1 Operaciones y transformaciones básicas del Álgebra Lineal Numérica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.2/Eigenvalores_y_eigenvectores.html">
   2.2 Eigenvalores y eigenvectores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.3/Algoritmos_y_aplicaciones_de_eigenvalores_eigenvectores_de_una_matriz.html">
   2.3 Algoritmos y aplicaciones de eigenvalores y eigenvectores de una matriz
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.4/Valores_vectores_singulares_y_algoritmos_para_calcular_la_SVD.html">
   2.4 Valores, vectores singulares y algoritmos para calcular la SVD
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  III. Optimización convexa
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../3.1/Definicion_de_problema_optimizacion_conjuntos_y_funciones_convexas.html">
   3.1 Definición de problemas de optimización, conjuntos y funciones convexas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3.2/Algoritmos_de_descenso_y_busqueda_de_linea_en_uco.html">
   3.2 Algoritmos de descenso y búsqueda de línea en
   <em>
    Unconstrained Convex Optimization
   </em>
   (UCO)
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   3.3 Ejemplos de problemas UCO e introducción a
   <em>
    Constrained Inequality and Equality Convex Optimization
   </em>
   (CIECO) y puntos interiores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3.4/Ecuaciones_no_lineales.html">
   3.4 Ecuaciones no lineales
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/III.optimizacion_convexa/3.3/Ejemplos_problemas_UCO_e_intro_CIECO_y_PI.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/palmoreck/dockerfiles-for-binder/jupyterlab_optimizacion?urlpath=lab/tree/analisis-numerico-computo-cientifico/libro_optimizacion/temas/III.optimizacion_convexa/3.3/Ejemplos_problemas_UCO_e_intro_CIECO_y_PI.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> On this page
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ejemplos-problemas-uco">
   Ejemplos problemas UCO
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#minimos-cuadrados">
     Mínimos cuadrados
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#minimos-cuadrados-lineales">
     Mínimos cuadrados lineales
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelo-en-minimos-cuadrados-lineales">
     Modelo en mínimos cuadrados lineales
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#enfoque-de-optimizacion">
     Enfoque de optimización
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regresion-logistica">
     Regresión Logística
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduccion-a-cieco">
   Introducción a CIECO
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#componentes-principales">
     Componentes principales
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#maquina-de-soporte-vectorial">
     Máquina de Soporte Vectorial
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#puntos-interiores">
   Puntos Interiores
  </a>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="ejemplos-de-problemas-uco-e-introduccion-a-constrained-inequality-and-equality-convex-optimization-cieco-y-puntos-interiores">
<span id="ejucointciecopi"></span><h1>3.3 Ejemplos de problemas UCO e introducción a <em>Constrained Inequality and Equality Convex Optimization</em> (CIECO) y puntos interiores<a class="headerlink" href="#ejemplos-de-problemas-uco-e-introduccion-a-constrained-inequality-and-equality-convex-optimization-cieco-y-puntos-interiores" title="Permalink to this headline">¶</a></h1>
<div class="admonition-notas-para-contenedor-de-docker admonition">
<p class="admonition-title">Notas para contenedor de docker:</p>
<p>Comando de docker para ejecución de la nota de forma local:</p>
<p>nota: cambiar <code class="docutils literal notranslate"><span class="pre">&lt;ruta</span> <span class="pre">a</span> <span class="pre">mi</span> <span class="pre">directorio&gt;</span></code> por la ruta de directorio que se desea mapear a <code class="docutils literal notranslate"><span class="pre">/datos</span></code> dentro del contenedor de docker.</p>
<p><code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">run</span> <span class="pre">--rm</span> <span class="pre">-v</span> <span class="pre">&lt;ruta</span> <span class="pre">a</span> <span class="pre">mi</span> <span class="pre">directorio&gt;:/datos</span> <span class="pre">--name</span> <span class="pre">jupyterlab_optimizacion</span> <span class="pre">-p</span> <span class="pre">8888:8888</span> <span class="pre">-d</span> <span class="pre">palmoreck/jupyterlab_optimizacion:2.1.4</span></code></p>
<p>password para jupyterlab: <code class="docutils literal notranslate"><span class="pre">qwerty</span></code></p>
<p>Detener el contenedor de docker:</p>
<p><code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">stop</span> <span class="pre">jupyterlab_optimizacion</span></code></p>
<p>Documentación de la imagen de docker <code class="docutils literal notranslate"><span class="pre">palmoreck/jupyterlab_optimizacion:2.1.4</span></code> en <a class="reference external" href="https://github.com/palmoreck/dockerfiles/tree/master/jupyterlab/optimizacion">liga</a>.</p>
</div>
<hr class="docutils" />
<p>Nota generada a partir de <a class="reference external" href="https://www.dropbox.com/s/6isby5h1e5f2yzs/4.2.Problemas_de_optimizacion_convexa.pdf?dl=0">liga1</a>, <a class="reference external" href="https://drive.google.com/file/d/1zCIHNAxe5Shc36Qo0XjehHgwrafKSJ_t/view">liga2</a>, <a class="reference external" href="https://drive.google.com/file/d/12L7rOCgW7NEKl_xJbIGZz05XXVrOaPBz/view">liga3</a>, <a class="reference external" href="https://drive.google.com/file/d/1RMwUXEN_SOHKue-J9Cx3Ldvj9bejLjiM/view">liga4</a>.</p>
<div class="tip admonition">
<p class="admonition-title">Al final de esta nota el y la lectora:</p>
<ul class="simple">
<li></li>
<li></li>
</ul>
</div>
<div class="section" id="ejemplos-problemas-uco">
<h2>Ejemplos problemas UCO<a class="headerlink" href="#ejemplos-problemas-uco" title="Permalink to this headline">¶</a></h2>
<div class="section" id="minimos-cuadrados">
<h3>Mínimos cuadrados<a class="headerlink" href="#minimos-cuadrados" title="Permalink to this headline">¶</a></h3>
<p>Obsérvese que hay una gran cantidad de modelos por mínimos cuadrados, por ejemplo:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Linear_least_squares">Lineales</a> u <a class="reference external" href="https://en.wikipedia.org/wiki/Ordinary_least_squares">ordinarios</a> (nombre más usado en Estadística y Econometría).</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Generalized_least_squares">Generalizados</a>, <a class="reference external" href="https://en.wikipedia.org/wiki/Weighted_least_squares">ponderados</a>.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Non-linear_least_squares">No lineales</a>.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Total_least_squares">Totales</a> y <a class="reference external" href="https://en.wikipedia.org/wiki/Partial_least_squares_regression">parciales</a>.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Non-negative_least_squares">No negativos</a>.</p></li>
<li><p><a class="reference external" href="https://epubs.siam.org/doi/abs/10.1137/1.9780898718867.ch7">Rango reducido</a>.</p></li>
</ul>
</div>
<div class="section" id="minimos-cuadrados-lineales">
<h3>Mínimos cuadrados lineales<a class="headerlink" href="#minimos-cuadrados-lineales" title="Permalink to this headline">¶</a></h3>
<p>Se <strong>asume</strong> en esta sección que <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{m \times n}\)</span> con <span class="math notranslate nohighlight">\(m \geq n\)</span> (más renglones que columnas en <span class="math notranslate nohighlight">\(A\)</span>).</p>
<p>Cada uno de los modelos anteriores tienen diversas aplicaciones y propósitos. Los lineales son un caso particular del problema más general de <strong>aproximación por normas</strong>:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min_{x \in \mathbb{R}^n} ||Ax-b||\]</div>
<p>donde: <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{m \times n}\)</span>, <span class="math notranslate nohighlight">\(b \in \mathbb{R}^m\)</span> son datos del problema, <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span> es la variable de optimización y <span class="math notranslate nohighlight">\(|| \cdot||\)</span> es una norma en <span class="math notranslate nohighlight">\(\mathbb{R}^m\)</span>.</p>
<div class="admonition-definiciones admonition">
<p class="admonition-title">Definiciones</p>
<p><span class="math notranslate nohighlight">\(x^* = \text{argmin}_{x \in \mathbb{R}^n} ||Ax-b||\)</span> se le nombra <strong>solución aproximada</strong> de <span class="math notranslate nohighlight">\(Ax \approx b\)</span> en la norma <span class="math notranslate nohighlight">\(|| \cdot ||\)</span>.</p>
<p>El vector: <span class="math notranslate nohighlight">\(r(x) = Ax -b\)</span> se le nombra <strong>residual</strong> del problema.</p>
</div>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>El problema de aproximación por normas también se le nombra <strong>problema de regresión</strong>. En este contexto, las componentes de <span class="math notranslate nohighlight">\(x\)</span> son nombradas variables regresoras, las columnas de <span class="math notranslate nohighlight">\(A\)</span> es un vector de <em>features</em> y el vector <span class="math notranslate nohighlight">\(\displaystyle \sum_{j=1}^n x_j^*a_j\)</span> con <span class="math notranslate nohighlight">\(x^*\)</span> óptimo del problema es nombrado la <strong>regresión de <span class="math notranslate nohighlight">\(b\)</span> sobre las regresoras</strong>, <span class="math notranslate nohighlight">\(b\)</span> es la <strong>respuesta.</strong></p>
</div>
<p>Si en el problema de aproximación de normas anterior se utiliza la norma Euclidiana o norma <span class="math notranslate nohighlight">\(2\)</span>, <span class="math notranslate nohighlight">\(|| \cdot ||_2\)</span>, y se eleva al cuadrado la función objetivo se tiene:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min_{x \in \mathbb{R}^n} ||Ax-b||^2_2\]</div>
<p>que es el modelo por mínimos cuadrados lineales cuyo objetivo es minimizar la suma de cuadrados de las componentes del residual <span class="math notranslate nohighlight">\(r(x)\)</span>.</p>
<p><strong>A partir de aquí, la variable de optimización será <span class="math notranslate nohighlight">\(\beta\)</span> y no <span class="math notranslate nohighlight">\(x\)</span></strong>:</p>
<p>Supóngase que se han realizado mediciones de un fenómeno de interés en diferentes puntos <span class="math notranslate nohighlight">\(x_i\)</span>’s resultando en cantidades <span class="math notranslate nohighlight">\(y_i\)</span>’s <span class="math notranslate nohighlight">\(\forall i=0,1,\dots, m\)</span> (se tienen <span class="math notranslate nohighlight">\(m+1\)</span> puntos) y además las <span class="math notranslate nohighlight">\(y_i\)</span>’s contienen un ruido aleatorio causado por errores de medición:</p>
<img src="https://dl.dropboxusercontent.com/s/iydpi0m8ndqzb0s/mcuadrados_1.jpg?dl=0" heigth="350" width="350">
<p>El objetivo de los mínimos cuadrados es construir una curva, <span class="math notranslate nohighlight">\(f(x|\beta)\)</span> que “mejor” se ajuste a los datos <span class="math notranslate nohighlight">\((x_i,y_i)\)</span>, <span class="math notranslate nohighlight">\(\forall i=0,1,\dots,m\)</span>. El término de “mejor” se refiere a que la suma:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \sum_{i=0}^m (y_i -f(x_i|\beta))^2\]</div>
<p>sea lo “más pequeña posible”, esto es, a que la suma de las distancias verticales entre <span class="math notranslate nohighlight">\(y_i\)</span> y <span class="math notranslate nohighlight">\(f(x_i|\beta)\)</span> <span class="math notranslate nohighlight">\(\forall i=0,1,\dots,m\)</span> al cuadrado sea mínima. Por ejemplo:</p>
<img src="https://dl.dropboxusercontent.com/s/0dhzv336jj6ep4z/mcuadrados_2.jpg?dl=0" heigth="350" width="350">
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>La notación <span class="math notranslate nohighlight">\(f(x|\beta)\)</span> se utiliza para denotar que <span class="math notranslate nohighlight">\(\beta\)</span> es un vector de parámetros a estimar, en específico <span class="math notranslate nohighlight">\(\beta_0, \beta_1, \dots \beta_n\)</span>, esto es: <span class="math notranslate nohighlight">\(n+1\)</span> parámetros a estimar.</p>
</div>
</div>
<div class="section" id="modelo-en-minimos-cuadrados-lineales">
<h3>Modelo en mínimos cuadrados lineales<a class="headerlink" href="#modelo-en-minimos-cuadrados-lineales" title="Permalink to this headline">¶</a></h3>
<p>En los mínimos cuadrados lineales se asume un modelo:</p>
<div class="math notranslate nohighlight">
\[f(x|\beta) = \displaystyle \sum_{j=0}^n\beta_j\phi_j(x)\]</div>
<p>con <span class="math notranslate nohighlight">\(\phi_j: \mathbb{R} \rightarrow \mathbb{R}\)</span> funciones conocidas por lo que se tiene una gran flexibilidad para el proceso de ajuste. Con las funciones <span class="math notranslate nohighlight">\(\phi_j (\cdot)\)</span> se construye a la matriz <span class="math notranslate nohighlight">\(A\)</span>.</p>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Si <span class="math notranslate nohighlight">\(n=m\)</span> entonces se tiene un problema de interpolación.</p>
</div>
<p>Si <span class="math notranslate nohighlight">\(m=3\)</span> y <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{3 \times 2}\)</span> geométricamente el problema de <strong>mínimos cuadrados lineales</strong> se puede visualizar con el siguiente dibujo:</p>
<img src="https://dl.dropboxusercontent.com/s/a6pjx0pdqa3cp60/mc_beta.png?dl=0" heigth="400" width="400">
<p>En el dibujo anterior:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(r(\beta) = y-A\beta\)</span>,</p></li>
<li><p>el vector <span class="math notranslate nohighlight">\(y \in \mathbb{R}^m\)</span> contiene las entradas <span class="math notranslate nohighlight">\(y_i\)</span>’s,</p></li>
<li><p>la matriz <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{m \times n}\)</span> contiene a las entradas <span class="math notranslate nohighlight">\(x_i\)</span>’s o funciones de éstas <span class="math notranslate nohighlight">\(\forall i=0,1,\dots,m\)</span>.</p></li>
</ul>
<p>Por el dibujo se tiene que cumplir que <span class="math notranslate nohighlight">\(A^Tr(\beta)=0\)</span>, esto es: las columnas de <span class="math notranslate nohighlight">\(A\)</span> son ortogonales a <span class="math notranslate nohighlight">\(r(\beta)\)</span>. La condición anterior conduce a las <strong>ecuaciones normales</strong>:</p>
<div class="math notranslate nohighlight">
\[0=A^Tr(\beta)=A^T(y-A\beta)=A^Ty-A^TA\beta.\]</div>
<p>donde: <span class="math notranslate nohighlight">\(A\)</span> se construye con las <span class="math notranslate nohighlight">\(\phi_j\)</span>’s evaluadas en los puntos <span class="math notranslate nohighlight">\(x_i\)</span>’s, el vector <span class="math notranslate nohighlight">\(\beta\)</span> contiene a los parámetros <span class="math notranslate nohighlight">\(\beta_j\)</span>’s a estimar y el vector <span class="math notranslate nohighlight">\(y\)</span>, la variable <strong>respuesta</strong>, se construye con los puntos <span class="math notranslate nohighlight">\(y_i\)</span>’s:</p>
<div class="math notranslate nohighlight">
\[\begin{split}A = \left[\begin{array}{cccc}
\phi_0(x_0) &amp;\phi_1(x_0)&amp;\dots&amp;\phi_n(x_0)\\
\phi_0(x_1) &amp;\phi_1(x_1)&amp;\dots&amp;\phi_n(x_1)\\
\vdots &amp;\vdots&amp; \vdots&amp;\vdots\\
\phi_0(x_n) &amp;\phi_1(x_n)&amp;\dots&amp;\phi_n(x_n)\\
\vdots &amp;\vdots&amp; \vdots&amp;\vdots\\
\phi_0(x_{m-1}) &amp;\phi_1(x_{m-1})&amp;\dots&amp;\phi_n(x_{m-1})\\
\phi_0(x_m) &amp;\phi_1(x_m)&amp;\dots&amp;\phi_n(x_m)
\end{array}
\right] \in \mathbb{R}^{(m+1)x(n+1)},
\beta=
\left[\begin{array}{c}
\beta_0\\
\beta_1\\
\vdots \\
\beta_n
\end{array}
\right] \in \mathbb{R}^n,
y=
\left[\begin{array}{c}
y_0\\
y_1\\
\vdots \\
y_m
\end{array}
\right] \in \mathbb{R}^{m + 1}
\end{split}\]</div>
<p>Finalmente, considerando la variable de optimización <span class="math notranslate nohighlight">\(\beta\)</span> y al vector <span class="math notranslate nohighlight">\(y\)</span> tenemos: <span class="math notranslate nohighlight">\(A^TA \beta = A^Ty\)</span>.</p>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Si <span class="math notranslate nohighlight">\(A\)</span> es de <span class="math notranslate nohighlight">\(rank\)</span> completo (tiene <span class="math notranslate nohighlight">\(n+1\)</span> columnas linealmente independientes) una opción para resolver el sistema anterior es calculando la factorización <span class="math notranslate nohighlight">\(QR\)</span> de <span class="math notranslate nohighlight">\(A\)</span>: <span class="math notranslate nohighlight">\(A = QR\)</span> y entonces:</p>
<div class="math notranslate nohighlight">
\[A^TA\beta = A^Ty\]</div>
<p>Dado que <span class="math notranslate nohighlight">\(A=QR\)</span> se tiene: <span class="math notranslate nohighlight">\(A^TA = (R^TQ^T)(QR)\)</span> y <span class="math notranslate nohighlight">\(A^T = R^TQ^T\)</span> por lo que:</p>
<div class="math notranslate nohighlight">
\[(R^TQ^T)(QR) \beta =  R^TQ^T y\]</div>
<p>y usando que <span class="math notranslate nohighlight">\(Q\)</span> tiene columnas ortonormales:</p>
<div class="math notranslate nohighlight">
\[R^TR\beta = R^TQ^Ty\]</div>
<p>Como <span class="math notranslate nohighlight">\(A\)</span> tiene <span class="math notranslate nohighlight">\(n+1\)</span> columnas linealmente independientes, la matriz <span class="math notranslate nohighlight">\(R\)</span> es invertible por lo que <span class="math notranslate nohighlight">\(R^T\)</span> también lo es y finalmente se tiene el sistema de ecuaciones por resolver:</p>
<div class="math notranslate nohighlight">
\[R\beta = Q^Ty\]</div>
</div>
</div>
<div class="section" id="enfoque-de-optimizacion">
<h3>Enfoque de optimización<a class="headerlink" href="#enfoque-de-optimizacion" title="Permalink to this headline">¶</a></h3>
<p>La función objetivo en los mínimos cuadrados lineales puede escribirse de las siguientes formas:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{eqnarray}
f_o(\beta)=\displaystyle \sum_{i=1}^{20} (y_i -f_o(x_i|\beta))^2 &amp;=&amp;  \displaystyle \sum_{i=1}^{20} (y_i - A[i,:]^T\beta)^2 \\
&amp;=&amp; ||y - A \beta||_2^2 \\
&amp;=&amp; (y-A\beta)^T(y-A\beta) \\
&amp;=&amp; y^Ty-2\beta^TA^Ty + \beta^TA^TA\beta
\end{eqnarray}
\end{split}\]</div>
<p>con <span class="math notranslate nohighlight">\(A[i,:]\)</span> <span class="math notranslate nohighlight">\(i\)</span>-ésimo renglón de <span class="math notranslate nohighlight">\(A\)</span> visto como un vector en <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>. Es común dividir por <span class="math notranslate nohighlight">\(2\)</span> la función objetivo para finalmente tener el problema:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min_{\beta \in \mathbb{R}^n} \quad \frac{1}{2}y^Ty-\beta^TA^Ty + \frac{1}{2}\beta^TA^TA\beta.\]</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>En cualquier reescritura de la función <span class="math notranslate nohighlight">\(f_o\)</span>, el problema de aproximación con normas, o bien en su caso particular de mínimos cuadrados, es un problema de <strong>optimización convexa</strong>.</p>
</div>
</div>
<div class="section" id="regresion-logistica">
<h3>Regresión Logística<a class="headerlink" href="#regresion-logistica" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="introduccion-a-cieco">
<h2>Introducción a CIECO<a class="headerlink" href="#introduccion-a-cieco" title="Permalink to this headline">¶</a></h2>
<div class="section" id="componentes-principales">
<h3>Componentes principales<a class="headerlink" href="#componentes-principales" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="maquina-de-soporte-vectorial">
<h3>Máquina de Soporte Vectorial<a class="headerlink" href="#maquina-de-soporte-vectorial" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="puntos-interiores">
<h2>Puntos Interiores<a class="headerlink" href="#puntos-interiores" title="Permalink to this headline">¶</a></h2>
<p><strong>Referencias:</strong></p>
<ol class="simple">
<li><p>S. P. Boyd, L. Vandenberghe, Convex Optimization, Cambridge University Press, 2009.</p></li>
<li><p>J. Dennis, R. B. Schnabel, Numerical Methods for Unconstrained Optimization and Nonlinear Equations, SIAM, 1996.</p></li>
<li><p>J. Nocedal, S. J. Wright, Numerical Optimization, Springer, 2006.</p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "palmoreck/dockerfiles-for-binder",
            ref: "jupyterlab_optimizacion",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./III.optimizacion_convexa/3.3"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../3.2/Algoritmos_de_descenso_y_busqueda_de_linea_en_uco.html" title="previous page">3.2 Algoritmos de descenso y búsqueda de línea en <em>Unconstrained Convex Optimization</em> (UCO)</a>
    <a class='right-next' id="next-link" href="../3.4/Ecuaciones_no_lineales.html" title="next page">3.4 Ecuaciones no lineales</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Erick Palacios Moreno<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../../_static/js/index.js"></script>
    
  </body>
</html>