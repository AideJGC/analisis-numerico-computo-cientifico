

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>3.3 Ejemplos de problemas UCO, introducción a Constrained Inequality and Equality Optimization (CIEO) y puntos interiores</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/mystnb.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="3.4 Ecuaciones no lineales" href="../3.4/Ecuaciones_no_lineales.html" />
    <link rel="prev" title="3.2 Algoritmos de descenso y búsqueda de línea en Unconstrained Convex Optimization (UCO)" href="../3.2/Algoritmos_de_descenso_y_busqueda_de_linea_en_uco.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../README.html">
   Optimización
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  I. Cómputo científico
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.1/Analisis_numerico_y_computo_cientifico.html">
   1.1 Análisis numérico y cómputo científico
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.2/Sistema_de_punto_flotante.html">
   1.2 Sistema de punto flotante
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.3/Normas_vectoriales_y_matriciales.html">
   1.3 Normas vectoriales y matriciales
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.4/Condicion_de_un_problema_y_estabilidad_de_un_algoritmo.html">
   1.4 Condición de un problema y estabilidad de un algoritmo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.5/Definicion_de_funcion_continuidad_derivada.html">
   1.5 Definición de función, continuidad y derivada
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.6/Polinomios_de_Taylor_y_diferenciacion_numerica.html">
   1.6 Polinomios de Taylor y diferenciación numérica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.7/Integracion_numerica.html">
   1.7 Integración Numérica
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  II. Cómputo matricial
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.1/Operaciones_y_transformaciones_basicas_del_Algebra_Lineal_Numerica.html">
   2.1 Operaciones y transformaciones básicas del Álgebra Lineal Numérica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.2/Eigenvalores_y_eigenvectores.html">
   2.2 Eigenvalores y eigenvectores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.3/Algoritmos_y_aplicaciones_de_eigenvalores_eigenvectores_de_una_matriz.html">
   2.3 Algoritmos y aplicaciones de eigenvalores y eigenvectores de una matriz
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.4/Valores_vectores_singulares_y_algoritmos_para_calcular_la_SVD.html">
   2.4 Valores, vectores singulares y algoritmos para calcular la SVD
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  III. Optimización convexa
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../3.1/Definicion_de_problema_optimizacion_conjuntos_y_funciones_convexas.html">
   3.1 Definición de problemas de optimización, conjuntos y funciones convexas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3.2/Algoritmos_de_descenso_y_busqueda_de_linea_en_uco.html">
   3.2 Algoritmos de descenso y búsqueda de línea en
   <em>
    Unconstrained Convex Optimization
   </em>
   (UCO)
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   3.3 Ejemplos de problemas UCO, introducción a
   <em>
    Constrained Inequality and Equality Optimization
   </em>
   (CIEO) y puntos interiores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3.4/Ecuaciones_no_lineales.html">
   3.4 Ecuaciones no lineales
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/III.optimizacion_convexa/3.3/Ejemplos_problemas_UCO_e_intro_CIEO_y_PI.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/palmoreck/dockerfiles-for-binder/jupyterlab_optimizacion?urlpath=lab/tree/analisis-numerico-computo-cientifico/libro_optimizacion/temas/III.optimizacion_convexa/3.3/Ejemplos_problemas_UCO_e_intro_CIEO_y_PI.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> On this page
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#minimos-cuadrados">
   Mínimos cuadrados
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#minimos-cuadrados-lineales">
   Mínimos cuadrados lineales
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelo-en-minimos-cuadrados-lineales">
     Modelo en mínimos cuadrados lineales
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#enfoque-de-optimizacion">
     Enfoque de optimización
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo">
     Ejemplo
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#el-problema-de-clasificacion-en-dos-clases-mathcal-c-0-mathcal-c-1">
   El problema de clasificación en dos clases
   <span class="math notranslate nohighlight">
    \(\mathcal{C}_0, \mathcal{C}_1\)
   </span>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regresion-logistica-clasificacion-en-mathcal-c-0-mathcal-c-1">
   Regresión logística: clasificación en
   <span class="math notranslate nohighlight">
    \(\mathcal{C}_0, \mathcal{C}_1\)
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelo-en-regresion-logistica-de-dos-clases">
     Modelo en regresión logística de dos clases
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#como-se-ajustan-los-parametros-del-modelo-por-regresion-logistica-de-dos-clases">
     ¿Cómo se ajustan los parámetros del modelo por regresión logística de dos clases?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo-iris-dataset">
     Ejemplo Iris
     <em>
      dataset
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#calculo-de-probabilidades-de-pertenencia-a-las-clases-mathcal-c-0-setosa-mathcal-c-1-versicolor">
     Cálculo de probabilidades de pertenencia a las clases
     <span class="math notranslate nohighlight">
      \(\mathcal{C}_0 :\)
     </span>
     <code class="docutils literal notranslate">
      <span class="pre">
       setosa
      </span>
     </code>
     ,
     <span class="math notranslate nohighlight">
      \(\mathcal{C}_1 :\)
     </span>
     <code class="docutils literal notranslate">
      <span class="pre">
       versicolor
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduccion-a-constrained-inequality-and-equality-optimization-cieo">
   Introducción a
   <em>
    Constrained Inequality and Equality Optimization
   </em>
   (CIEO)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo-1">
     Ejemplo 1
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#la-funcion-lagrangiana">
     La función Lagrangiana
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo-2">
     Ejemplo 2
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo-3">
     Ejemplo 3
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ejemplo-constrained-inequality-convex-optimization-cico-maquina-de-soporte-vectorial-svm-para-datos-linealmente-separables">
   Ejemplo
   <em>
    Constrained Inequality Convex Optimization
   </em>
   (CICO): Máquina de Soporte Vectorial (SVM) para datos linealmente separables
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clasificador-lineal">
     Clasificador lineal
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelo-de-svm">
     Modelo de SVM
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#problema-de-optimizacion-en-svm">
     Problema de optimización en SVM
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vectores-de-soporte">
     Vectores de soporte
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problemas-de-programacion-lineal">
   Problemas de programación lineal
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo-problema-de-transporte">
     Ejemplo: problema de transporte
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo-problema-de-flujo-maximo">
     Ejemplo: problema de flujo máximo
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#metodo-de-puntos-interiores">
   Método de puntos interiores
  </a>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="ejemplos-de-problemas-uco-introduccion-a-constrained-inequality-and-equality-optimization-cieo-y-puntos-interiores">
<span id="ejucointciecopi"></span><h1>3.3 Ejemplos de problemas UCO, introducción a <em>Constrained Inequality and Equality Optimization</em> (CIEO) y puntos interiores<a class="headerlink" href="#ejemplos-de-problemas-uco-introduccion-a-constrained-inequality-and-equality-optimization-cieo-y-puntos-interiores" title="Permalink to this headline">¶</a></h1>
<div class="admonition-notas-para-contenedor-de-docker admonition">
<p class="admonition-title">Notas para contenedor de docker:</p>
<p>Comando de docker para ejecución de la nota de forma local:</p>
<p>nota: cambiar <code class="docutils literal notranslate"><span class="pre">&lt;ruta</span> <span class="pre">a</span> <span class="pre">mi</span> <span class="pre">directorio&gt;</span></code> por la ruta de directorio que se desea mapear a <code class="docutils literal notranslate"><span class="pre">/datos</span></code> dentro del contenedor de docker.</p>
<p><code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">run</span> <span class="pre">--rm</span> <span class="pre">-v</span> <span class="pre">&lt;ruta</span> <span class="pre">a</span> <span class="pre">mi</span> <span class="pre">directorio&gt;:/datos</span> <span class="pre">--name</span> <span class="pre">jupyterlab_optimizacion</span> <span class="pre">-p</span> <span class="pre">8888:8888</span> <span class="pre">-d</span> <span class="pre">palmoreck/jupyterlab_optimizacion:2.1.4</span></code></p>
<p>password para jupyterlab: <code class="docutils literal notranslate"><span class="pre">qwerty</span></code></p>
<p>Detener el contenedor de docker:</p>
<p><code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">stop</span> <span class="pre">jupyterlab_optimizacion</span></code></p>
<p>Documentación de la imagen de docker <code class="docutils literal notranslate"><span class="pre">palmoreck/jupyterlab_optimizacion:2.1.4</span></code> en <a class="reference external" href="https://github.com/palmoreck/dockerfiles/tree/master/jupyterlab/optimizacion">liga</a>.</p>
</div>
<hr class="docutils" />
<p>Nota generada a partir de <a class="reference external" href="https://www.dropbox.com/s/6isby5h1e5f2yzs/4.2.Problemas_de_optimizacion_convexa.pdf?dl=0">liga1</a>, <a class="reference external" href="https://drive.google.com/file/d/1zCIHNAxe5Shc36Qo0XjehHgwrafKSJ_t/view">liga2</a>, <a class="reference external" href="https://drive.google.com/file/d/12L7rOCgW7NEKl_xJbIGZz05XXVrOaPBz/view">liga3</a>, <a class="reference external" href="https://drive.google.com/file/d/1RMwUXEN_SOHKue-J9Cx3Ldvj9bejLjiM/view">liga4</a>.</p>
<div class="tip admonition">
<p class="admonition-title">Al final de esta nota el y la lectora:</p>
<ul class="simple">
<li></li>
<li></li>
</ul>
</div>
<div class="section" id="minimos-cuadrados">
<h2>Mínimos cuadrados<a class="headerlink" href="#minimos-cuadrados" title="Permalink to this headline">¶</a></h2>
<p>Obsérvese que hay una gran cantidad de modelos por mínimos cuadrados, por ejemplo:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Linear_least_squares">Lineales</a> u <a class="reference external" href="https://en.wikipedia.org/wiki/Ordinary_least_squares">ordinarios</a> (nombre más usado en Estadística y Econometría).</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Generalized_least_squares">Generalizados</a>, <a class="reference external" href="https://en.wikipedia.org/wiki/Weighted_least_squares">ponderados</a>.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Non-linear_least_squares">No lineales</a>.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Total_least_squares">Totales</a> y <a class="reference external" href="https://en.wikipedia.org/wiki/Partial_least_squares_regression">parciales</a>.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Non-negative_least_squares">No negativos</a>.</p></li>
<li><p><a class="reference external" href="https://epubs.siam.org/doi/abs/10.1137/1.9780898718867.ch7">Rango reducido</a>.</p></li>
</ul>
</div>
<div class="section" id="minimos-cuadrados-lineales">
<h2>Mínimos cuadrados lineales<a class="headerlink" href="#minimos-cuadrados-lineales" title="Permalink to this headline">¶</a></h2>
<p>Se <strong>asume</strong> en esta sección que <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{m \times n}\)</span> con <span class="math notranslate nohighlight">\(m \geq n\)</span> (más renglones que columnas en <span class="math notranslate nohighlight">\(A\)</span>).</p>
<p>Cada uno de los modelos anteriores tienen diversas aplicaciones y propósitos. Los lineales son un caso particular del problema más general de <strong>aproximación por normas</strong>:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min_{x \in \mathbb{R}^n} ||Ax-b||\]</div>
<p>donde: <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{m \times n}\)</span>, <span class="math notranslate nohighlight">\(b \in \mathbb{R}^m\)</span> son datos del problema, <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span> es la variable de optimización y <span class="math notranslate nohighlight">\(|| \cdot||\)</span> es una norma en <span class="math notranslate nohighlight">\(\mathbb{R}^m\)</span>.</p>
<div class="admonition-definiciones admonition">
<p class="admonition-title">Definiciones</p>
<p><span class="math notranslate nohighlight">\(x^* = \text{argmin}_{x \in \mathbb{R}^n} ||Ax-b||\)</span> se le nombra <strong>solución aproximada</strong> de <span class="math notranslate nohighlight">\(Ax \approx b\)</span> en la norma <span class="math notranslate nohighlight">\(|| \cdot ||\)</span>.</p>
<p>El vector: <span class="math notranslate nohighlight">\(r(x) = Ax -b\)</span> se le nombra <strong>residual</strong> del problema.</p>
</div>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>El problema de aproximación por normas también se le nombra <strong>problema de regresión</strong>. En este contexto, las componentes de <span class="math notranslate nohighlight">\(x\)</span> son nombradas variables regresoras, las columnas de <span class="math notranslate nohighlight">\(A\)</span> es un vector de <em>features</em> o atributos y el vector <span class="math notranslate nohighlight">\(\displaystyle \sum_{j=1}^n x_j^*a_j\)</span> con <span class="math notranslate nohighlight">\(x^*\)</span> óptimo del problema es nombrado la <strong>regresión de <span class="math notranslate nohighlight">\(b\)</span> sobre las regresoras</strong>, <span class="math notranslate nohighlight">\(b\)</span> es la <strong>respuesta.</strong></p>
</div>
<p>Si en el problema de aproximación de normas anterior se utiliza la norma Euclidiana o norma <span class="math notranslate nohighlight">\(2\)</span>, <span class="math notranslate nohighlight">\(|| \cdot ||_2\)</span>, y se eleva al cuadrado la función objetivo se tiene:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min_{x \in \mathbb{R}^n} ||Ax-b||^2_2\]</div>
<p>que es el modelo por mínimos cuadrados lineales cuyo objetivo es minimizar la suma de cuadrados de las componentes del residual <span class="math notranslate nohighlight">\(r(x)\)</span>.</p>
<p><strong>A partir de aquí, la variable de optimización será <span class="math notranslate nohighlight">\(\beta\)</span> y no <span class="math notranslate nohighlight">\(x\)</span></strong> de modo que el problema es:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min_{\beta \in \mathbb{R}^n} ||A\beta-y||\]</div>
<p>Supóngase que se han realizado mediciones de un fenómeno de interés en diferentes puntos <span class="math notranslate nohighlight">\(x_i\)</span>’s resultando en cantidades <span class="math notranslate nohighlight">\(y_i\)</span>’s <span class="math notranslate nohighlight">\(\forall i=0,1,\dots, m\)</span> (se tienen <span class="math notranslate nohighlight">\(m+1\)</span> puntos) y además las <span class="math notranslate nohighlight">\(y_i\)</span>’s contienen un ruido aleatorio causado por errores de medición:</p>
<img src="https://dl.dropboxusercontent.com/s/iydpi0m8ndqzb0s/mcuadrados_1.jpg?dl=0" heigth="350" width="350">
<p>El objetivo de los mínimos cuadrados es construir una curva, <span class="math notranslate nohighlight">\(f(x|\beta)\)</span> que “mejor” se ajuste a los datos <span class="math notranslate nohighlight">\((x_i,y_i)\)</span>, <span class="math notranslate nohighlight">\(\forall i=0,1,\dots,m\)</span>. El término de “mejor” se refiere a que la suma:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \sum_{i=0}^m (y_i -f(x_i|\beta))^2\]</div>
<p>sea lo “más pequeña posible”, esto es, a que la suma de las distancias verticales entre <span class="math notranslate nohighlight">\(y_i\)</span> y <span class="math notranslate nohighlight">\(f(x_i|\beta)\)</span> <span class="math notranslate nohighlight">\(\forall i=0,1,\dots,m\)</span> al cuadrado sea mínima. Por ejemplo:</p>
<img src="https://dl.dropboxusercontent.com/s/0dhzv336jj6ep4z/mcuadrados_2.jpg?dl=0" heigth="350" width="350">
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>La notación <span class="math notranslate nohighlight">\(f(x|\beta)\)</span> se utiliza para denotar que <span class="math notranslate nohighlight">\(\beta\)</span> es un vector de parámetros a estimar, en específico <span class="math notranslate nohighlight">\(\beta_0, \beta_1, \dots \beta_n\)</span>, esto es: <span class="math notranslate nohighlight">\(n+1\)</span> parámetros a estimar.</p>
</div>
<div class="section" id="modelo-en-minimos-cuadrados-lineales">
<h3>Modelo en mínimos cuadrados lineales<a class="headerlink" href="#modelo-en-minimos-cuadrados-lineales" title="Permalink to this headline">¶</a></h3>
<p>En los mínimos cuadrados lineales se asume un modelo:</p>
<div class="math notranslate nohighlight">
\[f(x|\beta) = \displaystyle \sum_{j=0}^n\beta_j\phi_j(x)\]</div>
<p>con <span class="math notranslate nohighlight">\(\phi_j: \mathbb{R} \rightarrow \mathbb{R}\)</span> funciones conocidas por lo que se tiene una gran flexibilidad para el proceso de ajuste. Con las funciones <span class="math notranslate nohighlight">\(\phi_j (\cdot)\)</span> se construye a la matriz <span class="math notranslate nohighlight">\(A\)</span>.</p>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Si <span class="math notranslate nohighlight">\(n=m\)</span> entonces se tiene un problema de interpolación.</p>
</div>
<p>Si <span class="math notranslate nohighlight">\(m=3\)</span> y <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{3 \times 2}\)</span> geométricamente el problema de <strong>mínimos cuadrados lineales</strong> se puede visualizar con el siguiente dibujo:</p>
<img src="https://dl.dropboxusercontent.com/s/a6pjx0pdqa3cp60/mc_beta.png?dl=0" heigth="400" width="400">
<p>En el dibujo anterior:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(r(\beta) = y-A\beta\)</span>,</p></li>
<li><p>el vector <span class="math notranslate nohighlight">\(y \in \mathbb{R}^m\)</span> contiene las entradas <span class="math notranslate nohighlight">\(y_i\)</span>’s,</p></li>
<li><p>la matriz <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{m \times n}\)</span> contiene a las entradas <span class="math notranslate nohighlight">\(x_i\)</span>’s o funciones de éstas <span class="math notranslate nohighlight">\(\forall i=0,1,\dots,m\)</span>.</p></li>
</ul>
<p>Por el dibujo se tiene que cumplir que <span class="math notranslate nohighlight">\(A^Tr(\beta)=0\)</span>, esto es: las columnas de <span class="math notranslate nohighlight">\(A\)</span> son ortogonales a <span class="math notranslate nohighlight">\(r(\beta)\)</span>. La condición anterior conduce a las <strong>ecuaciones normales</strong>:</p>
<div class="math notranslate nohighlight">
\[0=A^Tr(\beta)=A^T(y-A\beta)=A^Ty-A^TA\beta.\]</div>
<p>donde: <span class="math notranslate nohighlight">\(A\)</span> se construye con las <span class="math notranslate nohighlight">\(\phi_j\)</span>’s evaluadas en los puntos <span class="math notranslate nohighlight">\(x_i\)</span>’s, el vector <span class="math notranslate nohighlight">\(\beta\)</span> contiene a los parámetros <span class="math notranslate nohighlight">\(\beta_j\)</span>’s a estimar y el vector <span class="math notranslate nohighlight">\(y\)</span>, la variable <strong>respuesta</strong>, se construye con los puntos <span class="math notranslate nohighlight">\(y_i\)</span>’s:</p>
<div class="math notranslate nohighlight">
\[\begin{split}A = \left[\begin{array}{cccc}
\phi_0(x_0) &amp;\phi_1(x_0)&amp;\dots&amp;\phi_n(x_0)\\
\phi_0(x_1) &amp;\phi_1(x_1)&amp;\dots&amp;\phi_n(x_1)\\
\vdots &amp;\vdots&amp; \vdots&amp;\vdots\\
\phi_0(x_n) &amp;\phi_1(x_n)&amp;\dots&amp;\phi_n(x_n)\\
\vdots &amp;\vdots&amp; \vdots&amp;\vdots\\
\phi_0(x_{m-1}) &amp;\phi_1(x_{m-1})&amp;\dots&amp;\phi_n(x_{m-1})\\
\phi_0(x_m) &amp;\phi_1(x_m)&amp;\dots&amp;\phi_n(x_m)
\end{array}
\right] \in \mathbb{R}^{(m+1)x(n+1)},
\beta=
\left[\begin{array}{c}
\beta_0\\
\beta_1\\
\vdots \\
\beta_n
\end{array}
\right] \in \mathbb{R}^n,
y=
\left[\begin{array}{c}
y_0\\
y_1\\
\vdots \\
y_m
\end{array}
\right] \in \mathbb{R}^{m + 1}
\end{split}\]</div>
<p>Finalmente, considerando la variable de optimización <span class="math notranslate nohighlight">\(\beta\)</span> y al vector <span class="math notranslate nohighlight">\(y\)</span> tenemos: <span class="math notranslate nohighlight">\(A^TA \beta = A^Ty\)</span>.</p>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Si <span class="math notranslate nohighlight">\(A\)</span> es de <span class="math notranslate nohighlight">\(rank\)</span> completo (tiene <span class="math notranslate nohighlight">\(n+1\)</span> columnas linealmente independientes) una opción para resolver el sistema anterior es calculando la factorización <span class="math notranslate nohighlight">\(QR\)</span> de <span class="math notranslate nohighlight">\(A\)</span>: <span class="math notranslate nohighlight">\(A = QR\)</span> y entonces:</p>
<div class="math notranslate nohighlight">
\[A^TA\beta = A^Ty\]</div>
<p>Dado que <span class="math notranslate nohighlight">\(A=QR\)</span> se tiene: <span class="math notranslate nohighlight">\(A^TA = (R^TQ^T)(QR)\)</span> y <span class="math notranslate nohighlight">\(A^T = R^TQ^T\)</span> por lo que:</p>
<div class="math notranslate nohighlight">
\[(R^TQ^T)(QR) \beta =  R^TQ^T y\]</div>
<p>y usando que <span class="math notranslate nohighlight">\(Q\)</span> tiene columnas ortonormales:</p>
<div class="math notranslate nohighlight">
\[R^TR\beta = R^TQ^Ty\]</div>
<p>Como <span class="math notranslate nohighlight">\(A\)</span> tiene <span class="math notranslate nohighlight">\(n+1\)</span> columnas linealmente independientes, la matriz <span class="math notranslate nohighlight">\(R\)</span> es invertible por lo que <span class="math notranslate nohighlight">\(R^T\)</span> también lo es y finalmente se tiene el <strong>sistema de ecuaciones lineales</strong> por resolver:</p>
<div class="math notranslate nohighlight">
\[R\beta = Q^Ty\]</div>
</div>
</div>
<div class="section" id="enfoque-de-optimizacion">
<h3>Enfoque de optimización<a class="headerlink" href="#enfoque-de-optimizacion" title="Permalink to this headline">¶</a></h3>
<p>La función objetivo en los mínimos cuadrados lineales puede escribirse de las siguientes formas:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{eqnarray}
f_o(\beta)=\displaystyle \sum_{i=1}^{m} (y_i -f_o(x_i|\beta))^2 &amp;=&amp;  \displaystyle \sum_{i=1}^{m} (y_i - A[i,:]^T\beta)^2 \\
&amp;=&amp; ||y - A \beta||_2^2 \\
&amp;=&amp; (y-A\beta)^T(y-A\beta) \\
&amp;=&amp; y^Ty-2\beta^TA^Ty + \beta^TA^TA\beta
\end{eqnarray}
\end{split}\]</div>
<p>con <span class="math notranslate nohighlight">\(A[i,:]\)</span> <span class="math notranslate nohighlight">\(i\)</span>-ésimo renglón de <span class="math notranslate nohighlight">\(A\)</span> visto como un vector en <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>. Es común dividir por <span class="math notranslate nohighlight">\(2\)</span> la función objetivo para finalmente tener el problema:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min_{\beta \in \mathbb{R}^n} \frac{1}{2}\beta^TA^TA\beta - \beta^TA^Ty + \frac{1}{2}y^Ty.\]</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>En cualquier reescritura de la función <span class="math notranslate nohighlight">\(f_o\)</span>, el problema de aproximación con normas, o bien en su caso particular de mínimos cuadrados, es un problema de <strong>optimización convexa</strong>.</p>
</div>
</div>
<div class="section" id="ejemplo">
<h3>Ejemplo<a class="headerlink" href="#ejemplo" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span> 
<span class="kn">import</span> <span class="nn">pprint</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span> <span class="c1">#just two decimals</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1989</span><span class="p">)</span> <span class="c1">#for reproducibility</span>
<span class="n">mpoints</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">mpoints</span><span class="p">)</span> 
<span class="n">y</span> <span class="o">=</span> <span class="o">-</span><span class="mi">3</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">mpoints</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Los datos ejemplo</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="s1">&#39;r*&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Puntos ejemplo&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Ejemplos_problemas_UCO_e_intro_CIEO_y_PI_41_0.png" src="../../_images/Ejemplos_problemas_UCO_e_intro_CIEO_y_PI_41_0.png" />
</div>
</div>
<p>Utilizamos el paquete <a class="reference external" href="https://github.com/cvxgrp/cvxpy">cvxpy</a> para resolver el problema de mínimos cuadrados:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cvxpy</span> <span class="k">as</span> <span class="nn">cp</span>
</pre></div>
</div>
</div>
</div>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Construimos a la matriz <span class="math notranslate nohighlight">\(A\)</span>.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">mpoints</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="c1">#step 1 to build matrix A</span>
<span class="n">A</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span> <span class="c1">#step 2 to build matrix A</span>
</pre></div>
</div>
</div>
</div>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Definición de variables y función objetivo: <span class="math notranslate nohighlight">\(\frac{1}{2}\beta^TA^TA\beta - \beta^TA^Ty + \frac{1}{2}y^Ty\)</span>.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># number of variables</span>
<span class="n">beta</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="c1">#optimization variable</span>
<span class="n">fo_cvxpy</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">cp</span><span class="o">.</span><span class="n">quad_form</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="nd">@A</span><span class="p">)</span> <span class="o">-</span> <span class="n">cp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="nd">@y</span><span class="p">,</span> <span class="n">beta</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="o">*</span><span class="n">y</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="c1">#objective function</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">prob</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Problem</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">Minimize</span><span class="p">(</span><span class="n">fo_cvxpy</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prob</span><span class="o">.</span><span class="n">solve</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>10.217738419387963
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">The optimal value is&quot;</span><span class="p">,</span> <span class="n">prob</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The optimal beta is&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">beta</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The norm of the residual is &quot;</span><span class="p">,</span> <span class="n">cp</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span> <span class="o">@</span> <span class="n">beta</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">value</span><span class="p">)</span> <span class="c1">#also works: cp.norm2(A @ beta - y).value</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>
The optimal value is 10.217738419387963
The optimal beta is
[ 2.03 -2.65]
The norm of the residual is  4.520561562325624
</pre></div>
</div>
</div>
</div>
<p>El paquete <em>CVXPY</em> ya tiene una función para resolver el problema anterior, ver <a class="reference external" href="https://www.cvxpy.org/examples/basic/least_squares.html">least_squares</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fo_cvxpy</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="o">*</span><span class="n">cp</span><span class="o">.</span><span class="n">sum_squares</span><span class="p">(</span><span class="n">A</span><span class="nd">@beta</span> <span class="o">-</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">prob</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Problem</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">Minimize</span><span class="p">(</span><span class="n">fo_cvxpy</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prob</span><span class="o">.</span><span class="n">solve</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>10.217738419387944
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">The optimal value is&quot;</span><span class="p">,</span> <span class="n">prob</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The optimal beta is&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">beta</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The norm of the residual is &quot;</span><span class="p">,</span> <span class="n">cp</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span> <span class="o">@</span> <span class="n">beta</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">value</span><span class="p">)</span> <span class="c1">#also works: cp.norm2(A @ beta - y).value</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>
The optimal value is 10.217738419387944
The optimal beta is
[ 2.03 -2.65]
The norm of the residual is  4.520561562325624
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="el-problema-de-clasificacion-en-dos-clases-mathcal-c-0-mathcal-c-1">
<h2>El problema de clasificación en dos clases <span class="math notranslate nohighlight">\(\mathcal{C}_0, \mathcal{C}_1\)</span><a class="headerlink" href="#el-problema-de-clasificacion-en-dos-clases-mathcal-c-0-mathcal-c-1" title="Permalink to this headline">¶</a></h2>
<p>Sean <span class="math notranslate nohighlight">\(\mathcal{C}_0 , \mathcal{C}_1\)</span> dos clases ajenas y <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span>. El problema de clasificación consiste en clasificar al vector <span class="math notranslate nohighlight">\(x\)</span> en alguna de las dos clases anteriores de modo que se minimice el error de clasificación.</p>
<p>Ejemplos de lo anterior los encontramos en medicina (persona enferma o no dada una serie de mediciones en sangre), finanzas (persona sujeta a un crédito bancario o no dado un historial crediticio) o clasificación de textos (<em>spam</em> o no <em>spam</em>).</p>
</div>
<div class="section" id="regresion-logistica-clasificacion-en-mathcal-c-0-mathcal-c-1">
<h2>Regresión logística: clasificación en <span class="math notranslate nohighlight">\(\mathcal{C}_0, \mathcal{C}_1\)</span><a class="headerlink" href="#regresion-logistica-clasificacion-en-mathcal-c-0-mathcal-c-1" title="Permalink to this headline">¶</a></h2>
<p>El modelo por regresión logística tiene por objetivo <strong>modelar las probabilidades de pertenencia a cada una de las clases</strong> <span class="math notranslate nohighlight">\(\mathcal{C}_0, \mathcal{C}_1\)</span> dado el vector de <em>features</em> o atributos <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span>: <span class="math notranslate nohighlight">\(p(\mathcal{C}_0|x) , p(\mathcal{C}_1|x)\)</span>.</p>
<p>En la regresión logística se utiliza la función <strong><a class="reference external" href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoide</a></strong> <span class="math notranslate nohighlight">\(\sigma:\mathbb{R} \rightarrow \mathbb{R}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\sigma(t)=\frac{1}{1+\exp(-t)}\]</div>
<p>para modelar ambas probabilidades ya que mapea todo el eje real al intervalo <span class="math notranslate nohighlight">\([0,1]\)</span>. Además resulta ser una aproximación continua y diferenciable a la función de <strong><a class="reference external" href="https://en.wikipedia.org/wiki/Heaviside_step_function">Heaviside</a></strong> <span class="math notranslate nohighlight">\(H:\mathbb{R} \rightarrow \mathbb{R}\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}H(t) = 
\begin{cases}
1 &amp; \text{si } t \geq 0,\\
0 &amp; \text{si } t &lt;0\\
\end{cases}
\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mpoints</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">mpoints</span><span class="p">)</span>
<span class="n">Heaviside</span> <span class="o">=</span> <span class="mi">1</span><span class="o">*</span><span class="p">(</span><span class="n">t</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">Heaviside</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Ejemplos_problemas_UCO_e_intro_CIEO_y_PI_61_0.png" src="../../_images/Ejemplos_problemas_UCO_e_intro_CIEO_y_PI_61_0.png" />
</div>
</div>
<p>A continuación graficamos a la sigmoide <span class="math notranslate nohighlight">\(\sigma(ht)\)</span> para distintos valores de <span class="math notranslate nohighlight">\(h \in \{-3, -1, -1/2, 1/2, 1, 3\}\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sigmoid</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">t_value</span><span class="p">:</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">t_value</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
<span class="n">sigmoids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">mpoints</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">h</span><span class="p">)):</span>
    <span class="n">sigmoids</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">h</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">t</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">sigmoids</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
         <span class="n">t</span><span class="p">,</span> <span class="n">sigmoids</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span>
         <span class="n">t</span><span class="p">,</span> <span class="n">sigmoids</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span>
         <span class="n">t</span><span class="p">,</span> <span class="n">sigmoids</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span>
         <span class="n">t</span><span class="p">,</span> <span class="n">sigmoids</span><span class="p">[:,</span><span class="mi">4</span><span class="p">],</span>
         <span class="n">t</span><span class="p">,</span> <span class="n">sigmoids</span><span class="p">[:,</span><span class="mi">5</span><span class="p">])</span>
<span class="n">l</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;h=-3&quot;</span><span class="p">,</span> <span class="s2">&quot;h=-1&quot;</span><span class="p">,</span> <span class="s2">&quot;h=-1/2&quot;</span><span class="p">,</span> <span class="s2">&quot;h=1/2&quot;</span><span class="p">,</span> <span class="s2">&quot;h=1&quot;</span><span class="p">,</span> <span class="s2">&quot;h=3&quot;</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Diferentes funciones sigmoides $\sigma(ht)$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Ejemplos_problemas_UCO_e_intro_CIEO_y_PI_65_0.png" src="../../_images/Ejemplos_problemas_UCO_e_intro_CIEO_y_PI_65_0.png" />
</div>
</div>
<p>Obsérvese la forma de cada curva al variar <span class="math notranslate nohighlight">\(h\)</span> en la función <span class="math notranslate nohighlight">\(\sigma(ht)\)</span>. Una regla de clasificación podría ser clasificar como perteneciente a <span class="math notranslate nohighlight">\(\mathcal{C}_0\)</span> si la probabilidad (modelada por la curva sigmoide) es menor a <span class="math notranslate nohighlight">\(0.25\)</span> (<strong>punto de corte</strong>) y perteneciente a <span class="math notranslate nohighlight">\(\mathcal{C}_1\)</span> si es mayor o igual a <span class="math notranslate nohighlight">\(0.25\)</span>. Para diferentes curvas sigmoides presentadas en la gráfica anterior obsérvese que al fijar el punto de corte y tomar un valor de <span class="math notranslate nohighlight">\(t\)</span> en el eje horizontal, la pertenencia a alguna de las clases es menos sensible al variar <span class="math notranslate nohighlight">\(t\)</span> que en otras curvas.</p>
<p>Así, la función sigmoide permite modelar la probabilidad de pertenencia a la clase <span class="math notranslate nohighlight">\(\mathcal{C}_1:\)</span></p>
<div class="math notranslate nohighlight">
\[p(\mathcal{C}_1| x)=\sigma(a)\]</div>
<p>para alguna <span class="math notranslate nohighlight">\(a \in \mathbb{R}\)</span>.</p>
<p>Con el <a class="reference external" href="https://en.wikipedia.org/wiki/Bayes%27_theorem">teorema de Bayes</a> se obtiene el valor de <span class="math notranslate nohighlight">\(a\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{eqnarray}
p(\mathcal{C}_1|x) &amp;=&amp; \frac{p(x|\mathcal{C}_1)p(\mathcal{C}_1)}{p(x|\mathcal{C}_0)p(\mathcal{C}_0)+p(x|\mathcal{C}_1)p(\mathcal{C}_1)} \nonumber \\
&amp;=&amp; \left ( 1+ \frac{p(x|\mathcal{C}_0)p(\mathcal{C}_0)}{p(x|\mathcal{C}_1)p(\mathcal{C}_1)} \right )^{-1} \nonumber
\end{eqnarray}
\end{split}\]</div>
<p>Por lo tanto:</p>
<div class="math notranslate nohighlight">
\[
\begin{eqnarray}
a(x)&amp;=&amp;\log\left( \frac{p(x|\mathcal{C}_1)p(\mathcal{C}_1)}{p(x|\mathcal{C}_0)p(\mathcal{C}_0)} \right ) \nonumber
\end{eqnarray}
\]</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Algunas propiedades que tiene la función <span class="math notranslate nohighlight">\(\sigma(\cdot)\)</span> se encuentran:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{eqnarray}
\sigma (-t)&amp;=&amp;1-\sigma (t) \nonumber \\
\frac{d\sigma (t)}{dt}&amp;=&amp;\sigma (t)(1-\sigma (t)) \nonumber
\end{eqnarray}
\end{split}\]</div>
<ul class="simple">
<li><p>En Estadística a la función:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[a=\log\left(\frac{\sigma}{1-\sigma}\right)\]</div>
<p>se le conoce como <a class="reference external" href="https://en.wikipedia.org/wiki/Logit"><strong>logit</strong></a> y modela el log momio:</p>
<div class="math notranslate nohighlight">
\[\log \left(\frac{p(\mathcal{C}_1|x)}{p(\mathcal{C}_0|x)}\right)=\log \left(\frac{p(\mathcal{C}_1|x)}{1-p(\mathcal{C}_1|x)}\right)\]</div>
<p>que tiene una interpretación directa en términos de las probabilidades de pertenencia a cada clase <span class="math notranslate nohighlight">\(\mathcal{C}_0,\mathcal{C}_1\)</span>.</p>
</div>
<div class="section" id="modelo-en-regresion-logistica-de-dos-clases">
<h3>Modelo en regresión logística de dos clases<a class="headerlink" href="#modelo-en-regresion-logistica-de-dos-clases" title="Permalink to this headline">¶</a></h3>
<p>De forma similar como en el modelo por mínimos cuadrados lineales se modeló a la variable respuesta <span class="math notranslate nohighlight">\(y\)</span> con una función lineal en sus parámetros, en el modelo en regresión logística <strong>con dos clases e intercepto</strong> se propone una <strong>función lineal</strong> en un vector de parámetros <span class="math notranslate nohighlight">\((\beta_0,\beta) \in \mathbb{R}^{n+1}\)</span> definida por el logit:</p>
<div class="math notranslate nohighlight">
\[
\beta^T x+\beta_0=a(x|\beta_0,\beta)=\log \left(\frac{p(\mathcal{C}_1|x)}{p(\mathcal{C}_0|x)}\right).
\]</div>
<p>Obsérvese que si <span class="math notranslate nohighlight">\(y\)</span> es considerada como variable respuesta que está en función de <span class="math notranslate nohighlight">\(x \in \mathbb{R}^{n+1}\)</span> dado el vector <span class="math notranslate nohighlight">\((\beta_0, \beta)\)</span> se tiene:</p>
<div class="math notranslate nohighlight">
\[p(\mathcal{C}_1 | x ) = y(x | \beta_0, \beta) = \frac{1}{1+ e^{-(\beta_0, \beta)^T x}}\]</div>
<p>que se lee “la probabilidad de pertenencia a la clase <span class="math notranslate nohighlight">\(\mathcal{C}_1\)</span> dado el vector de atributos <span class="math notranslate nohighlight">\(x\)</span> es igual a <span class="math notranslate nohighlight">\(y\)</span>”.</p>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>El modelo con <span class="math notranslate nohighlight">\(2\)</span> parámetros <span class="math notranslate nohighlight">\(\beta_0, \beta_1\)</span> se ve como:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[p(\mathcal{C}_1 | x ) = y(x | \beta_0, \beta) = \frac{1}{1+ e^{-(\beta_0 + \beta_1x)}}\]</div>
<p>con <span class="math notranslate nohighlight">\(x \in \mathbb{R}\)</span>.</p>
<ul class="simple">
<li><p>El modelo puede extenderse utilizando <span class="math notranslate nohighlight">\(n+1\)</span> funciones conocidas <span class="math notranslate nohighlight">\(\phi_j:\mathbb{R} \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(\phi_j(x)\)</span> <span class="math notranslate nohighlight">\(j=0,\dots, n\)</span> por lo que si <span class="math notranslate nohighlight">\(\phi(x)=(\phi_0(x),\phi_1(x),\dots,\phi_n(x))^T\)</span> y <span class="math notranslate nohighlight">\(\beta_0 \in \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(\beta \in \mathbb{R}^n\)</span>, entonces se tiene el modelo por regresión logística:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
p(\mathcal{C}_1|\phi(x))=y(x|\beta_0, \beta)= \frac{1}{1+ e^{-(\beta_0, \beta)^T \phi(x)}}
\]</div>
<ul class="simple">
<li><p>La notación <span class="math notranslate nohighlight">\(y(x | \beta_0, \beta)\)</span> se utiliza para denotar que <span class="math notranslate nohighlight">\((\beta_0, \beta)\)</span> es un vector de parámetros a estimar, en específico <span class="math notranslate nohighlight">\(\beta_0, \beta_1, \dots, \beta_n\)</span>, esto es: <span class="math notranslate nohighlight">\(n+1\)</span> parámetros a estimar.</p></li>
<li><p>La variable de optimización es <span class="math notranslate nohighlight">\((\beta_0, \beta) \in \mathbb{R}^{n+1}\)</span>.</p></li>
</ul>
</div>
</div>
<div class="section" id="como-se-ajustan-los-parametros-del-modelo-por-regresion-logistica-de-dos-clases">
<h3>¿Cómo se ajustan los parámetros del modelo por regresión logística de dos clases?<a class="headerlink" href="#como-se-ajustan-los-parametros-del-modelo-por-regresion-logistica-de-dos-clases" title="Permalink to this headline">¶</a></h3>
<p>Dados <span class="math notranslate nohighlight">\((x_0,\hat{y}_0), \dots (x_m, \hat{y}_m)\)</span> puntos se desean modelar <span class="math notranslate nohighlight">\(m+1\)</span> probabilidades de pertenencias a las clases <span class="math notranslate nohighlight">\(\mathcal{C}_0, \mathcal{C}_1\)</span> representadas con las etiquetas  <span class="math notranslate nohighlight">\(\hat{y}_i \in \{0,1\} \forall i=0,1,\dots, m\)</span>. El número <span class="math notranslate nohighlight">\(0\)</span> representa a la clase <span class="math notranslate nohighlight">\(\mathcal{C}_0\)</span> y el <span class="math notranslate nohighlight">\(1\)</span> a la clase <span class="math notranslate nohighlight">\(\mathcal{C}_1\)</span>. El vector <span class="math notranslate nohighlight">\(x_i \in \mathbb{R}^n\)</span> .</p>
<p>Cada probabilidad se modela como <span class="math notranslate nohighlight">\(y_0=y_0(x_0|\beta_0, \beta),y_1=y_1(x_1|\beta_0, \beta),\dots,y_m=y_m(x_n|\beta_0, \beta)\)</span> utilizando:</p>
<div class="math notranslate nohighlight">
\[p(\mathcal{C}_1|x_i) = y_i(x_i|\beta_0,\beta)  = \frac{1}{1+ e^{-(\beta_0 + \beta^T x)}} \forall i=0,1,\dots,m.\]</div>
<p>Los <span class="math notranslate nohighlight">\(n+1\)</span> parámetros <span class="math notranslate nohighlight">\(\beta_0, \beta_1, \dots, \beta_n\)</span> se ajustan <strong>maximizando</strong> la <a class="reference external" href="https://en.wikipedia.org/wiki/Likelihood_function">función de verosimilitud</a>:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(\beta_0, \beta|x)=\displaystyle \prod_{i=0}^n y_i^{\hat{y}_i}(1-y_i)^{1-\hat{y}_i}
\]</div>
<p>donde: <span class="math notranslate nohighlight">\(\hat{y}_i \sim \text{Bernoulli}(y_i)\)</span> y por tanto <span class="math notranslate nohighlight">\(\hat{y}_i \in \{0,1\}\)</span>: <span class="math notranslate nohighlight">\(\hat{y}_i = 1\)</span> con probabilidad <span class="math notranslate nohighlight">\(y_i\)</span> y <span class="math notranslate nohighlight">\(\hat{y}_i = 0\)</span> con probabilidad <span class="math notranslate nohighlight">\(1-y_i\)</span>. Entonces se tiene el problema:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \max_{(\beta_0, \beta) \in \mathbb{R}^{n+1}} \mathcal{L}(\beta_0, \beta|x)=\displaystyle \prod_{i=0}^n y_i^{\hat{y}_i}(1-y_i)^{1-\hat{y}_i}\]</div>
<p>Lo anterior es equivalente a maximizar la <strong>log-verosimilitud</strong>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{eqnarray}
\ell(\beta_0, \beta |x)&amp;=&amp;\log(\mathcal{L}(\beta_0, \beta| x)) \nonumber\\
&amp;=&amp;\displaystyle \sum_{i=1}^m \hat{y}_i\log(y_i)+(1-\hat{y}_i)\log(1-y_i) \nonumber\\
&amp;=&amp;\displaystyle \sum_{i=1}^m\hat{y}_i (\beta_0, \beta)^T x_i-\log(1+\exp((\beta_0, \beta)^Tx_i) \nonumber
\end{eqnarray}
\end{split}\]</div>
<p>o a minimizar la <a class="reference external" href="https://en.wikipedia.org/wiki/Deviance_(statistics)"><strong>devianza</strong></a>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{eqnarray}
\displaystyle \min_{(\beta_0, \beta) \in \mathbb{R}^{n+1}}\mathcal{D}(\beta_0, \beta|x)&amp;=&amp;-2\ell(\beta_0, \beta|x) \nonumber \\
&amp;=&amp;2\displaystyle \sum_{i=1}^m\log(1+\exp((\beta_0, \beta)^Tx_i))-\hat{y}_i(\beta_0, \beta)^Tx_i \nonumber
\end{eqnarray}
\end{split}\]</div>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>La devianza es una función convexa pues su Hessiana es:</p>
<div class="math notranslate nohighlight">
\[
\nabla^2 D(\beta_0, \beta |x) = 2A^TPA
\]</div>
<p>con: <span class="math notranslate nohighlight">\(P\)</span> una matriz diagonal con entradas <span class="math notranslate nohighlight">\(y_i(1-y_i)\)</span> donde: <span class="math notranslate nohighlight">\(y_i\)</span> está en función de <span class="math notranslate nohighlight">\(x_i\)</span>: <span class="math notranslate nohighlight">\(y_i(x_i|\beta_0,\beta) = \frac{1}{1+ e^{-(\beta_0 + \beta^T x_i)}} \forall i=0,1,\dots,m\)</span> y la matriz A es:</p>
<div class="math notranslate nohighlight">
\[\begin{split}A = \left[\begin{array}{c}
x_0\\
x_1\\
\vdots\\
x_m
\end{array}
\right]=\left[\begin{array}{cccc}
x_{01} &amp; x_{02}&amp;\dots&amp; x_{0n}\\
x_{11}&amp; x_{12}&amp;\dots&amp; x_{1n}\\
\vdots &amp;\vdots&amp; \vdots&amp;\vdots\\
x_{n1} &amp;x_{n2}&amp;\dots&amp;x_{nn}\\
\vdots &amp;\vdots&amp; \vdots&amp;\vdots\\
x_{m1} &amp;x_{m2}&amp;\dots&amp;x_{mn}
\end{array}
\right] \in \mathbb{R}^{(m+1)x(n+1)}
\end{split}\]</div>
<p>El valor <span class="math notranslate nohighlight">\(m\)</span> representa el número de observaciones y el valor <span class="math notranslate nohighlight">\(n\)</span> representa la dimensión del vector <span class="math notranslate nohighlight">\(\beta\)</span>.</p>
<p>La expresión anterior de la Hessiana se obtiene a partir de la expresión del gradiente:</p>
<div class="math notranslate nohighlight">
\[
\nabla D(\beta_0, \beta|x) = 2 \displaystyle \sum_{i=1}^m \left( y_i - \hat{y}_i \right )x_i  = 2\sum_{i=1}^m \left( p(\mathcal{C}_1|x_i) - \hat{y}_i \right )x_i = 2A^T(p-\hat{y})
\]</div>
<p>donde:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
p=\left[\begin{array}{c}
y_0(x_0|\beta_0,\beta)\\
y_1(x_1|\beta_0,\beta)\\
\vdots \\
y_m(x_m|\beta_0,\beta)
\end{array}
\right]=
\left[\begin{array}{c}
p(\mathcal{C}_1|x_0)\\
p(\mathcal{C}_1|x_1)\\
\vdots \\
p(\mathcal{C}_1|x_m)
\end{array}
\right] \in \mathbb{R}^{n+1},
\hat{y}=
\left[\begin{array}{c}
\hat{y}_0\\
\hat{y}_1\\
\vdots \\
\hat{y}_m
\end{array}
\right] \in \mathbb{R}^{m+1}
\end{split}\]</div>
<p>Así, la Hessiana de la devianza es simétrica semidefinida positiva y por tanto es una función convexa.</p>
</div>
</div>
<div class="section" id="ejemplo-iris-dataset">
<h3>Ejemplo <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html">Iris <em>dataset</em></a><a class="headerlink" href="#ejemplo-iris-dataset" title="Permalink to this headline">¶</a></h3>
<p>Utilizamos el conocido <em>dataset</em> de <a class="reference external" href="https://en.wikipedia.org/wiki/Iris_flower_data_set"><em>Iris</em></a> en el que se muestran <strong>tres especies del género <em>Iris</em></strong>. Las especies son: <a class="reference external" href="https://en.wikipedia.org/wiki/Iris_setosa"><em>I. setosa</em></a>, <a class="reference external" href="https://en.wikipedia.org/wiki/Iris_virginica"><em>I. virginica</em></a> y <a class="reference external" href="https://en.wikipedia.org/wiki/Iris_versicolor"><em>I. versicolor</em></a>:</p>
<img src="https://dl.dropboxusercontent.com/s/1bvsv79h0h64ijv/iris_dataset_flowers.png?dl=0" heigth="400" width="400">
<p>Imagen obtenida de <a class="reference external" href="https://rpubs.com/AjinkyaUC/Iris_DataSet">Iris Dataset</a>.</p>
<div class="cell tag_margin docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!pip3 install --quiet sklearn
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[33mWARNING: You are using pip version 20.2; however, version 20.2.4 is available.
You should consider upgrading via the &#39;/usr/bin/python3 -m pip install --upgrade pip&#39; command.[0m
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data_iris</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">data_iris</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[[5.1 3.5 1.4 0.2]
 [4.9 3.  1.4 0.2]
 [4.7 3.2 1.3 0.2]
 [4.6 3.1 1.5 0.2]
 [5.  3.6 1.4 0.2]
 [5.4 3.9 1.7 0.4]
 [4.6 3.4 1.4 0.3]
 [5.  3.4 1.5 0.2]
 [4.4 2.9 1.4 0.2]
 [4.9 3.1 1.5 0.1]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="p">,</span><span class="n">n</span> <span class="o">=</span> <span class="n">data_iris</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;número de observaciones:</span><span class="si">%d</span><span class="s2">, número de atributos: </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">n</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>número de observaciones:150, número de atributos: 4
</pre></div>
</div>
</div>
</div>
<p>Columnas en este orden: <code class="docutils literal notranslate"><span class="pre">Sepal.Length</span></code>, <code class="docutils literal notranslate"><span class="pre">Sepal.Width</span></code>, <code class="docutils literal notranslate"><span class="pre">Petal.Length</span></code>, <code class="docutils literal notranslate"><span class="pre">Petal.Width</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">iris</span><span class="p">[</span><span class="s2">&quot;target_names&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[&#39;setosa&#39; &#39;versicolor&#39; &#39;virginica&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">iris</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[0 1 2]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data_iris_setosa_versicolor</span> <span class="o">=</span> <span class="n">data_iris</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">data_iris_setosa_versicolor</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[[ 1.   -0.21  0.81  0.79]
 [-0.21  1.   -0.6  -0.57]
 [ 0.81 -0.6   1.    0.98]
 [ 0.79 -0.57  0.98  1.  ]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">classes</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>La clase <span class="math notranslate nohighlight">\(\mathcal{C}_0\)</span> es <code class="docutils literal notranslate"><span class="pre">setosa</span></code> y <span class="math notranslate nohighlight">\(\mathcal{C}_1\)</span> es <code class="docutils literal notranslate"><span class="pre">versicolor</span></code> codificadas como <span class="math notranslate nohighlight">\(0, 1\)</span> respectivamente.</p>
<p>La función objetivo como se revisó en la sección anterior está dada por la expresión de la devianza:</p>
<div class="math notranslate nohighlight">
\[\mathcal{D}(\beta_0, \beta|x)=-2\ell(\beta_0, \beta|x) = 2\displaystyle \sum_{i=1}^m\log(1+\exp((\beta_0, \beta)^Tx_i))-\hat{y}_i(\beta_0, \beta)^Tx_i\]</div>
<p>donde: <span class="math notranslate nohighlight">\(\hat{y}_i \in \{0,1\}\)</span>, <span class="math notranslate nohighlight">\(x_i\)</span> <span class="math notranslate nohighlight">\(i\)</span>-ésimo renglón de matriz <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{100 \times 4}\)</span>.</p>
<p><strong>Añadimos la columna que indica uso de intercepto y por tanto de un modelo con <span class="math notranslate nohighlight">\(\beta_0\)</span>:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="p">,</span><span class="n">n</span> <span class="o">=</span> <span class="n">data_iris_setosa_versicolor</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data_iris_setosa_versicolor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span> <span class="n">data_iris_setosa_versicolor</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data_iris_setosa_versicolor</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([[1. , 5.1, 3.5, 1.4, 0.2],
       [1. , 4.9, 3. , 1.4, 0.2],
       [1. , 4.7, 3.2, 1.3, 0.2],
       [1. , 4.6, 3.1, 1.5, 0.2],
       [1. , 5. , 3.6, 1.4, 0.2],
       [1. , 5.4, 3.9, 1.7, 0.4],
       [1. , 4.6, 3.4, 1.4, 0.3],
       [1. , 5. , 3.4, 1.5, 0.2],
       [1. , 4.4, 2.9, 1.4, 0.2],
       [1. , 4.9, 3.1, 1.5, 0.1]])
</pre></div>
</div>
</div>
</div>
<p><strong>Función objetivo:</strong></p>
<div class="math notranslate nohighlight">
\[2\displaystyle \sum_{i=1}^m\log(1+\exp((\beta_0, \beta)^Tx_i))-\hat{y}_i(\beta_0, \beta)^Tx_i\]</div>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Ver <a class="reference external" href="https://www.cvxpy.org/examples/machine_learning/logistic_regression.html">cvxpy: logistic regression</a></p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span> <span class="c1">#number of variables</span>
<span class="n">beta</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="c1">#optimization variable</span>
<span class="n">fo_cvxpy</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">cp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
             <span class="n">cp</span><span class="o">.</span><span class="n">logistic</span><span class="p">(</span><span class="n">data_iris_setosa_versicolor</span> <span class="o">@</span> <span class="n">beta</span><span class="p">)</span> <span class="o">-</span> <span class="n">cp</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">data_iris_setosa_versicolor</span> <span class="o">@</span> <span class="n">beta</span><span class="p">)</span>
                   <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">prob</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Problem</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">Minimize</span><span class="p">(</span><span class="n">fo_cvxpy</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prob</span><span class="o">.</span><span class="n">solve</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>5.393472364509651e-06
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">The optimal value is&quot;</span><span class="p">,</span> <span class="n">prob</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The optimal beta is&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">beta</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>
The optimal value is 5.393472364509651e-06
The optimal beta is
[  9.71  -3.97 -13.53  11.16  25.52]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="calculo-de-probabilidades-de-pertenencia-a-las-clases-mathcal-c-0-setosa-mathcal-c-1-versicolor">
<h3>Cálculo de probabilidades de pertenencia a las clases <span class="math notranslate nohighlight">\(\mathcal{C}_0 :\)</span> <code class="docutils literal notranslate"><span class="pre">setosa</span></code>, <span class="math notranslate nohighlight">\(\mathcal{C}_1 :\)</span> <code class="docutils literal notranslate"><span class="pre">versicolor</span></code><a class="headerlink" href="#calculo-de-probabilidades-de-pertenencia-a-las-clases-mathcal-c-0-setosa-mathcal-c-1-versicolor" title="Permalink to this headline">¶</a></h3>
<p><strong>Para individuo <span class="math notranslate nohighlight">\(i\)</span> se tiene:</strong></p>
<div class="math notranslate nohighlight">
\[p(\mathcal{C}_1|x_i) = y_i(x_i|\beta_0,\beta)  = \frac{1}{1+ e^{-(\beta_0 + \beta^T x_i)}} \forall i=0,1,\dots,m.\]</div>
<p>Por ejemplo, para el renglón <span class="math notranslate nohighlight">\(1\)</span> de <code class="docutils literal notranslate"><span class="pre">data_iris_setosa_versicolor</span></code>, que sabemos que pertenece a la clase <span class="math notranslate nohighlight">\(\mathcal{C}_0\)</span>: <code class="docutils literal notranslate"><span class="pre">setosa</span></code>:</p>
<p><strong>Estimación de la probabilidad de pertenencia a la clase <span class="math notranslate nohighlight">\(\mathcal{C}_1\)</span>, <code class="docutils literal notranslate"><span class="pre">versicolor</span></code></strong>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">linear_value</span> <span class="o">=</span> <span class="o">-</span><span class="n">data_iris_setosa_versicolor</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">beta</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">linear_value</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>7.086267696762456e-17
</pre></div>
</div>
</div>
</div>
<p><strong>Estimación de la probabilidad de pertenencia a la clase <span class="math notranslate nohighlight">\(\mathcal{C}_0\)</span>, <code class="docutils literal notranslate"><span class="pre">setosa</span></code></strong>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">linear_value</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">linear_value</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
</div>
</div>
<p>Por ejemplo, para el último renglón de <code class="docutils literal notranslate"><span class="pre">data_iris_setosa_versicolor</span></code>, que sabemos que pertenece a la clase <span class="math notranslate nohighlight">\(\mathcal{C}_1\)</span>, <code class="docutils literal notranslate"><span class="pre">versicolor</span></code>:</p>
<p><strong>Estimación de la probabilidad de pertenencia a la clase <span class="math notranslate nohighlight">\(\mathcal{C}_1\)</span>, <code class="docutils literal notranslate"><span class="pre">versicolor</span></code></strong>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">linear_value</span> <span class="o">=</span> <span class="o">-</span><span class="n">data_iris_setosa_versicolor</span><span class="p">[</span><span class="n">m</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">beta</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">linear_value</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>0.999999999999369
</pre></div>
</div>
</div>
</div>
<p><strong>Estimación de la probabilidad de pertenencia a la clase <span class="math notranslate nohighlight">\(\mathcal{C}_0\)</span>, <code class="docutils literal notranslate"><span class="pre">setosa</span></code></strong>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">linear_value</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">linear_value</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>6.311290040242794e-13
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="introduccion-a-constrained-inequality-and-equality-optimization-cieo">
<h2>Introducción a <em>Constrained Inequality and Equality Optimization</em> (CIEO)<a class="headerlink" href="#introduccion-a-constrained-inequality-and-equality-optimization-cieo" title="Permalink to this headline">¶</a></h2>
<p>Recuérdese que para <em>Unconstrained Optimization</em> (UO) se dieron <strong>condiciones</strong> que deben satisfacer puntos para ser óptimos en <a class="reference internal" href="../3.1/Definicion_de_problema_optimizacion_conjuntos_y_funciones_convexas.html#spopt"><span class="std std-ref">sobre problemas de optimización</span></a>. En esta sección se darán ejemplos que ayudarán a describir condiciones que caracterizan las soluciones para un <a class="reference internal" href="../3.1/Definicion_de_problema_optimizacion_conjuntos_y_funciones_convexas.html#pestopt"><span class="std std-ref">problema estándar de optimización</span></a>:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min f_o(x)\]</div>
<div class="math notranslate nohighlight">
\[\text{sujeto a:}\]</div>
<div class="math notranslate nohighlight">
\[f_i(x) \leq 0, \quad \forall i=1,\dots,m\]</div>
<div class="math notranslate nohighlight">
\[h_i(x) = 0, \quad \forall i=1,\dots,p\]</div>
<p>con <span class="math notranslate nohighlight">\(f_i: \mathbb{R}^n \rightarrow \mathbb{R}\)</span> <span class="math notranslate nohighlight">\(\forall i=0,\dots,m\)</span>, <span class="math notranslate nohighlight">\(h_i: \mathbb{R}^n \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(\forall i=1,\dots,p\)</span>. <span class="math notranslate nohighlight">\(f_i\)</span> son las <strong>restricciones de desigualdad</strong>, <span class="math notranslate nohighlight">\(h_i\)</span> son las <strong>restricciones de igualdad</strong>.</p>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>El problema anterior se le nombra <strong>problema primal</strong>.</p>
</div>
<p>En lo que continúa se asume que <span class="math notranslate nohighlight">\(f_i\)</span>, <span class="math notranslate nohighlight">\(h_i\)</span> son funciones de clase <span class="math notranslate nohighlight">\(\mathcal{C}^2\)</span> en sus dominios respectivos.</p>
<div class="section" id="ejemplo-1">
<h3>Ejemplo 1<a class="headerlink" href="#ejemplo-1" title="Permalink to this headline">¶</a></h3>
<p>Considérese el siguiente problema de optimización:</p>
<div class="math notranslate nohighlight">
\[\min x_1 + x_2\]</div>
<div class="math notranslate nohighlight">
\[\text{sujeto a:}\]</div>
<div class="math notranslate nohighlight">
\[x_1^2 + x_2^2 -2 = 0\]</div>
<p>En el cual:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\nabla f_o(x) = 
\left [
\begin{array}{c}
1 \\
1
\end{array}
\right ],
\nabla h_1(x) =
\left [
\begin{array}{c}
2x_1 \\
2x_2
\end{array}
\right ]
\end{split}\]</div>
<p>de modo que al evaluar en diferentes puntos los gradientes anteriores se tiene una situación siguiente:</p>
<img src="https://dl.dropboxusercontent.com/s/c3tpza1q05kc5no/ej1_CIEO_problems.png?dl=0" heigth="500" width="500">
<p>Por el dibujo anterior se tiene que el conjunto de factibilidad para este problema es una circunferencia de radio <span class="math notranslate nohighlight">\(\sqrt{2}\)</span> con centro en el origen. Se puede observar además que <span class="math notranslate nohighlight">\(x^* = \left [ \begin{array}{c}-1 \\ -1 \end{array} \right ]\)</span> pues si estuviéramos en cualquier otro punto, por ejemplo en el punto <span class="math notranslate nohighlight">\(x = \left [ \begin{array}{c}\sqrt{2} \\0 \end{array} \right ]\)</span> entonces cualquier movimiento en dirección en sentido de las manecillas del reloj reducirá el valor de <span class="math notranslate nohighlight">\(f_o\)</span>.</p>
<p>También se observa en el dibujo anterior que en la solución <span class="math notranslate nohighlight">\(x^*\)</span>, se cumple que:</p>
<div class="math notranslate nohighlight">
\[\nabla f_o(x^*) = - \nu_1^*\nabla h_1(x^*),\]</div>
<p>esto es, son paralelos, de hecho, <span class="math notranslate nohighlight">\(\nu_1^* = \frac{1}{2}\)</span>.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Recuérdese que si <span class="math notranslate nohighlight">\(x\)</span> es factible entonces <span class="math notranslate nohighlight">\(h_1(x) = 0\)</span> y si  <span class="math notranslate nohighlight">\(\nabla f_o(x) \neq 0\)</span> entonces no es óptimo.</p>
</div>
<p>Usando el teorema de Taylor aplicado a <span class="math notranslate nohighlight">\(h_1\)</span> y asumiendo que <span class="math notranslate nohighlight">\(x\)</span> es un punto factible, <span class="math notranslate nohighlight">\(\nabla f_o(x) \neq 0\)</span> y <span class="math notranslate nohighlight">\(\Delta x\)</span> una dirección de descenso de longitud pequeña tal que mantiene factibilidad se tiene que:</p>
<div class="math notranslate nohighlight">
\[0 = h_1(x + \Delta x) \approx h_1(x) + \nabla h_1(x)^T \Delta x = \nabla h_1(x)^T \Delta x.\]</div>
<p>En resúmen, si el paso <span class="math notranslate nohighlight">\(\Delta x\)</span> mantiene la factibilidad entonces:</p>
<div class="math notranslate nohighlight">
\[\nabla h_1(x)^T \Delta x = 0.\]</div>
<p>Además, como es dirección de descenso:</p>
<div class="math notranslate nohighlight">
\[\nabla f_o (x)^T \Delta x &lt; 0.\]</div>
<p>Si <span class="math notranslate nohighlight">\(x\)</span> no es mínimo local entonces existe tal dirección <span class="math notranslate nohighlight">\(\Delta x\)</span>, análogamente si no existe tal dirección entonces <span class="math notranslate nohighlight">\(x\)</span> es un mínimo local. En el dibujo anterior se verifica visualmente esto pues si ambos gradientes no son paralelos entonces podemos elegir una dirección de descenso que satisfaga ambas condiciones anteriores.</p>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Obsérvese que si <span class="math notranslate nohighlight">\(x^*\)</span> es mínimo local entonces <span class="math notranslate nohighlight">\(\nabla f_o(x^*) = 0\)</span> (condición necesaria de primer orden) por lo que no existen direcciones de descenso.</p>
</div>
</div>
<div class="section" id="la-funcion-lagrangiana">
<h3>La función Lagrangiana<a class="headerlink" href="#la-funcion-lagrangiana" title="Permalink to this headline">¶</a></h3>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>La <strong>función Lagrangiana</strong> asociada al problema de optimización (primal) se define como:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}: \mathbb{R}^n \times \mathbb{R}^m \times \mathbb{R}^p \rightarrow \mathbb{R}\]</div>
<p>con:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(x, \lambda , \nu) = f_o(x) + \displaystyle \sum_{i=1}^m \lambda_i f_i(x) + \sum_{i=1}^p \nu_i h_i(x)\]</div>
<p>y <span class="math notranslate nohighlight">\(\text{dom} \mathcal{L} = \mathcal{D} \times \mathbb{R}^m \times \mathbb{R}^p\)</span> donde: <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> es el dominio del problema de optimización.</p>
<p>En lo que continúa se asume la restricción <span class="math notranslate nohighlight">\(\lambda_i \geq 0 \forall i=1,\dots, m\)</span>.</p>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\lambda _i\)</span> se le nombra <strong>multiplicador de Lagrange</strong> asociado con la <span class="math notranslate nohighlight">\(i\)</span>-ésima restricción de desigualdad <span class="math notranslate nohighlight">\(f_i(x) \leq 0\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\nu_i\)</span> se le nombra <strong>multiplicador de Lagrange</strong> asociado con la <span class="math notranslate nohighlight">\(i\)</span>-ésima restricción de igualdad <span class="math notranslate nohighlight">\(h_i(x)=0\)</span>.</p></li>
<li><p>Los vectores <span class="math notranslate nohighlight">\(\lambda = (\lambda_i)_{i=1}^m\)</span> y  <span class="math notranslate nohighlight">\(\nu = (\nu_i)_{i=1}^p \in \mathbb{R}^p\)</span> se les nombran <strong>variables duales</strong> o <strong>vectores de multiplicadores de Lagrange</strong> asociados con el problema de optimización. El vector <span class="math notranslate nohighlight">\(x \in \mathcal{D}\)</span> se le nombra <strong>variable primal</strong>.</p></li>
</ul>
</div>
<p>Para el ejemplo anterior se tiene:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(x, \lambda_1) = f_o(x) + \nu_1 h_1(x).\]</div>
<p>Obsérvese que <span class="math notranslate nohighlight">\(\nabla_x \mathcal{L}(x, \nu_1) = \nabla f_o(x) + \nu_1 h_1(x)\)</span> y en la solución <span class="math notranslate nohighlight">\(x^*\)</span>, existe <span class="math notranslate nohighlight">\(\nu_1^*\)</span> tal que <span class="math notranslate nohighlight">\(\nabla_x \mathcal{L} (x^*, \nu_1^*)= 0\)</span>.</p>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>La notación <span class="math notranslate nohighlight">\(\nabla_x g(x, y)\)</span> hace referencia al gradiente de <span class="math notranslate nohighlight">\(g(x,y)\)</span> sólo derivando respecto a <span class="math notranslate nohighlight">\(x\)</span>.</p>
</div>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Aunque la condición</p>
<div class="math notranslate nohighlight">
\[\nabla f_o(x^*) = - \nu_1^*\nabla h_1(x^*)\]</div>
<p>es necesaria, ésta no es suficiente pues se satisface en el punto <span class="math notranslate nohighlight">\(x^* = \left [ \begin{array}{c}1 \\ 1 \end{array} \right ]\)</span> para el ejemplo anterior con <span class="math notranslate nohighlight">\(\nu_1 = -\frac{1}{2}\)</span> pero este punto <strong>maximiza</strong> <span class="math notranslate nohighlight">\(f_o\)</span> en la circunferencia. Y no se puede satisfacer suficiencia simplemente colocando una restricción sobre el signo de <span class="math notranslate nohighlight">\(\nu_1\)</span> pues si por ejemplo se pide que <span class="math notranslate nohighlight">\(\nu_1 &lt; 0\)</span> y consideramos la restricción <span class="math notranslate nohighlight">\(2-x_1^2-x_2^2=0\)</span>, la solución <strong>sigue</strong> siendo <span class="math notranslate nohighlight">\((-1, -1)^T\)</span> pero <span class="math notranslate nohighlight">\(\nu_1^*=-\frac{1}{2}\)</span>.</p>
</div>
</div>
<div class="section" id="ejemplo-2">
<h3>Ejemplo 2<a class="headerlink" href="#ejemplo-2" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\min x_1 + x_2\]</div>
<div class="math notranslate nohighlight">
\[\text{sujeto a:}\]</div>
<div class="math notranslate nohighlight">
\[x_1^2 + x_2^2 -2 \leq 0\]</div>
<p>Para este ejemplo el conjunto de factibilidad es el interior y frontera del círculo:</p>
<img src="https://dl.dropboxusercontent.com/s/bsdo84p22y9qgg7/ej2a_CIEO_problems.png?dl=0" heigth="350" width="350">
<p>Obsérvese en el dibujo anterior que <span class="math notranslate nohighlight">\(-\nabla f_1(x)\)</span> apunta al interior del conjunto de factibilidad.</p>
<p>La solución de este problema sigue siendo <span class="math notranslate nohighlight">\(x^* = \left [ \begin{array}{c}-1 \\ -1 \end{array} \right ]\)</span> con <span class="math notranslate nohighlight">\(\lambda_1^* = \frac{1}{2}\)</span> al igual que en el ejemplo 1 con <span class="math notranslate nohighlight">\(x_1^2 + x_2^2 -2 = 0\)</span>. Sin embargo, la diferencia con el ejemplo anterior es que el signo <span class="math notranslate nohighlight">\(\lambda_1\)</span> es importante como se describirá a continuación.</p>
<p>Si <span class="math notranslate nohighlight">\(x\)</span> no es óptimo entonces como en el ejemplo anterior podemos encontrar una dirección <span class="math notranslate nohighlight">\(\Delta x\)</span> que satisfaga factibilidad, <span class="math notranslate nohighlight">\(f_1(x) \leq 0\)</span>, y reduzca <span class="math notranslate nohighlight">\(f_o\)</span>.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Recuérdese que si <span class="math notranslate nohighlight">\(x\)</span> es factible entonces <span class="math notranslate nohighlight">\(f_1(x) \leq 0\)</span> y si  <span class="math notranslate nohighlight">\(\nabla f_o(x) \neq 0\)</span> entonces no es óptimo.</p>
</div>
<p>Usando el teorema de Taylor aplicado a <span class="math notranslate nohighlight">\(f_1\)</span> y asumiendo que <span class="math notranslate nohighlight">\(x\)</span> es un punto factible, <span class="math notranslate nohighlight">\(\nabla f_o(x) \neq 0\)</span> y <span class="math notranslate nohighlight">\(\Delta x\)</span> una dirección de descenso de longitud pequeña tal que mantiene factibilidad se tiene que:</p>
<div class="math notranslate nohighlight">
\[f_1(x) + \nabla f_1(x)^T \Delta x \approx f_1(x + \Delta x) \leq 0\]</div>
<p>En resúmen, si el paso <span class="math notranslate nohighlight">\(\Delta x\)</span> mantiene la factibilidad entonces:</p>
<div class="math notranslate nohighlight">
\[f_1(x) + \nabla f_1(x)^T \Delta x \leq 0.\]</div>
<p>Además, como es dirección de descenso:</p>
<div class="math notranslate nohighlight">
\[\nabla f_o (x)^T \Delta x &lt; 0.\]</div>
<p>Tenemos que analizar dos casos dependiendo si <span class="math notranslate nohighlight">\(f_1\)</span> es o no aciva en <span class="math notranslate nohighlight">\(x\)</span> para la desigualdad <span class="math notranslate nohighlight">\(f_1(x) + \nabla f_1(x)^T \Delta x  \leq 0\)</span>:</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Recuérdese que una restricción de desigualdad <span class="math notranslate nohighlight">\(f_1\)</span> es activa en <span class="math notranslate nohighlight">\(x\)</span> si <span class="math notranslate nohighlight">\(f_1(x) = 0\)</span> e inactiva en <span class="math notranslate nohighlight">\(x\)</span> si <span class="math notranslate nohighlight">\(f_1(x) &lt; 0\)</span>.</p>
</div>
<p><strong>Caso <span class="math notranslate nohighlight">\(f_1\)</span> inactiva en <span class="math notranslate nohighlight">\(x\)</span>: <span class="math notranslate nohighlight">\(f_1(x) &lt; 0\)</span>,</strong> entonces <span class="math notranslate nohighlight">\(x\)</span> está dentro del círculo:</p>
<img src="https://dl.dropboxusercontent.com/s/gmqje4tlp7qnkll/ej2b_CIEO_problems.png?dl=0" heigth="300" width="300">
<p>En este caso <strong>cualquier</strong> dirección <span class="math notranslate nohighlight">\(\Delta x\)</span> cuya longitud sea suficientemente pequeña satisface <span class="math notranslate nohighlight">\(f_1(x) + \nabla f_1(x)^T \Delta x &lt; 0\)</span> si <span class="math notranslate nohighlight">\(\nabla f_o(x) \neq 0\)</span> (por ejemplo tómese <span class="math notranslate nohighlight">\(\Delta x\)</span> como <span class="math notranslate nohighlight">\(-\nabla f_o(x)\)</span> normalizado y suficientemente pequeño). Si <span class="math notranslate nohighlight">\(\nabla f_o(x) = 0\)</span> entonces <span class="math notranslate nohighlight">\(x\)</span> es un punto crítico que podría ser mínimo local (por ejemplo si añadimos una segunda restricción que comparta el interior del círculo y que sea activa).</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Recuérdese que una restricción de desigualdad <span class="math notranslate nohighlight">\(f_1\)</span> es activa en <span class="math notranslate nohighlight">\(x\)</span> si <span class="math notranslate nohighlight">\(f_1(x) = 0\)</span> e inactiva en <span class="math notranslate nohighlight">\(x\)</span> si <span class="math notranslate nohighlight">\(f_1(x) &lt; 0\)</span>.</p>
</div>
<p><strong>Caso <span class="math notranslate nohighlight">\(f_1\)</span> activa en <span class="math notranslate nohighlight">\(x\)</span>: <span class="math notranslate nohighlight">\(f_1(x) = 0\)</span>,</strong> entonces <span class="math notranslate nohighlight">\(x\)</span> está en la frontera del círculo:</p>
<img src="https://dl.dropboxusercontent.com/s/4vb2p814hzkaaz0/ej2c_CIEO_problems.png?dl=0" heigth="300" width="300">
<p>La condición que se debe satisfacer es:</p>
<div class="math notranslate nohighlight">
\[f_1(x) + \nabla f_1(x)^T \Delta x  = \nabla f_1(x)^T \Delta x  \leq 0.\]</div>
<p>la cual junto con la de descenso: <span class="math notranslate nohighlight">\(\nabla f_o(x) ^T \Delta x &lt; 0\)</span> definen un semi-espacio cerrado y uno abierto respectivamente:</p>
<img src="https://dl.dropboxusercontent.com/s/u0c913adjj7et36/ej2d_CIEO_problems.pn?dl=0" heigth="500" width="500">
<p>Si <span class="math notranslate nohighlight">\(\nabla f_o(x)\)</span> y <span class="math notranslate nohighlight">\(\nabla f_1(x)\)</span> apuntan a la misma dirección entonces la intersección entre estas dos regiones es vacía:</p>
<img src="https://dl.dropboxusercontent.com/s/3u9getvoac8ez6c/ej2e_CIEO_problems.png?dl=0" heigth="400" width="400">
<p>siendo paralelos <span class="math notranslate nohighlight">\(\nabla f_o(x)\)</span> y <span class="math notranslate nohighlight">\(\nabla f_1(x)\)</span>: <span class="math notranslate nohighlight">\(\nabla f_o(x) = -\lambda_1 \nabla f_1(x)\)</span> para algún <span class="math notranslate nohighlight">\(\lambda_1 \geq 0\)</span> en la situación que <span class="math notranslate nohighlight">\(x\)</span> <strong>sea mínimo</strong>, esto es: <span class="math notranslate nohighlight">\(x=x^*\)</span>.</p>
<p>En este caso el signo del multiplicador <strong>sí es importante</strong> pues si <span class="math notranslate nohighlight">\(\nabla f_o(x) = -\lambda_1 \nabla f_1(x)\)</span>  con <span class="math notranslate nohighlight">\(\lambda_1 \leq 0\)</span> entonces <span class="math notranslate nohighlight">\(\nabla f_o(x)\)</span> y <span class="math notranslate nohighlight">\(\nabla f_1(x)\)</span> apuntarían en diferentes direcciones y por tanto el conjunto de direcciones que satisfacen:</p>
<div class="math notranslate nohighlight">
\[\nabla f_1(x)^T \Delta x  \leq 0.\]</div>
<div class="math notranslate nohighlight">
\[\nabla f_o(x) ^T \Delta x &lt; 0\]</div>
<p>construirían un semi-espacio abierto. Esto daría la posibilidad a tener una infinidad de direcciones de descenso:</p>
<img src="https://dl.dropboxusercontent.com/s/7ehkg9zg9vkthp4/ej2f_CIEO_problems.png?dl=0" heigth="400" width="400">
<p>lo cual sería una contradicción <strong>para <span class="math notranslate nohighlight">\(x\)</span> mínimo</strong> pues se tendría <span class="math notranslate nohighlight">\(\nabla f_o(x) =0\)</span> por condición necesaria de primer orden y no existiría <span class="math notranslate nohighlight">\(\Delta x\)</span> tal que es dirección de descenso.</p>
<p>Ambas condiciones para los casos anteriores se pueden obtener a partir de la función Lagrangiana:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(x, \lambda_1) = f_o(x) + \lambda_1 f_1(x).\]</div>
<p>Si no existe <span class="math notranslate nohighlight">\(\Delta x\)</span> en un punto <span class="math notranslate nohighlight">\(x^*\)</span> entonces:</p>
<div class="math notranslate nohighlight">
\[\nabla_x \mathcal{L}(x^*, \lambda_1^*) = \nabla f_o(x^*) + \lambda_1^* f_1(x^*) = 0\]</div>
<p>Y de acuerdo a los dos casos anteriores es importante el signo de <span class="math notranslate nohighlight">\(\lambda_1^*\)</span>. Para la condición <span class="math notranslate nohighlight">\(\lambda_1^* \geq 0\)</span> requerimos la condición con nombre <strong>condición de complementariedad u holgura complementaria</strong>:</p>
<div class="math notranslate nohighlight">
\[\lambda_1^* f_1(x^*) = 0\]</div>
<p>pues obsérvese que el caso en el que <span class="math notranslate nohighlight">\(f_1\)</span> es inactiva en <span class="math notranslate nohighlight">\(x^*\)</span> entonces por esta condición <span class="math notranslate nohighlight">\(\lambda_1^* = 0\)</span> y por tanto <span class="math notranslate nohighlight">\(\nabla_x \mathcal{L}(x^*, \lambda_1^*) = \nabla f_o(x^*) = 0\)</span>. En el caso que <span class="math notranslate nohighlight">\(f_1\)</span> es activa en <span class="math notranslate nohighlight">\(x^*\)</span> entonces <span class="math notranslate nohighlight">\(\lambda_1^*\)</span> puede tomar cualquier valor en <span class="math notranslate nohighlight">\(\mathbb{R}\)</span> pero por los dos dibujos anteriores se debe cumplir que <span class="math notranslate nohighlight">\(\lambda_1^* \geq 0\)</span> para consistencia con que <span class="math notranslate nohighlight">\(x^*\)</span> es mínimo.</p>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>La condición de holgura complementaria indica que si <span class="math notranslate nohighlight">\(\lambda_1\)</span> es positivo entonces <span class="math notranslate nohighlight">\(f_1\)</span> es activa:</p>
<div class="math notranslate nohighlight">
\[\lambda_1 &gt;0 \implies f_1(x) = 0\]</div>
<p>o bien:</p>
<div class="math notranslate nohighlight">
\[f_1(x) &lt;0 \implies \lambda_1 =0\]</div>
</div>
</div>
<div class="section" id="ejemplo-3">
<h3>Ejemplo 3<a class="headerlink" href="#ejemplo-3" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\min x_1 + x_2\]</div>
<div class="math notranslate nohighlight">
\[\text{sujeto a:}\]</div>
<div class="math notranslate nohighlight">
\[x_1^2 + x_2^2 -2 \leq 0\]</div>
<div class="math notranslate nohighlight">
\[-x_2 \leq 0\]</div>
<p>Para este ejemplo el conjunto de factibilidad es el interior de la mitad superior del círculo (incluyendo su frontera):</p>
<img src="https://dl.dropboxusercontent.com/s/nrm0hywrxn6rmn0/ej3a_CIEO_problems.png?dl=0" heigth="400" width="400">
<div class="math notranslate nohighlight">
\[\begin{split}\nabla f_1(x) = \left [
\begin{array}{c}
2x_1 \\
2x_2 \\
\end{array}
\right],
\nabla f_2(x) = \left [
\begin{array}{c}
0 \\
-1 \\
\end{array}
\right]
\end{split}\]</div>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p><span class="math notranslate nohighlight">\(f_1(x) = x_1^2 + x_2^2 -2\)</span>, <span class="math notranslate nohighlight">\(f_2(x) = -x_2\)</span></p>
</div>
<p>La solución para este ejemplo es <span class="math notranslate nohighlight">\(x^* = \left [ \begin{array}{c}-\sqrt{2} \\ 0 \end{array} \right ]\)</span>, un punto en el que ambas restricciones <span class="math notranslate nohighlight">\(f_1(x) = x_1^2 + x_2^2 -2\)</span>, <span class="math notranslate nohighlight">\(f_2(x) = -x_2\)</span> son activas.</p>
<p>Siguiendo con el desarrollo del ejemplo 2 de aproximación a primer orden con el teorema de Taylor se tiene que una dirección de descenso <span class="math notranslate nohighlight">\(\Delta x\)</span> debe cumplir:</p>
<div class="math notranslate nohighlight">
\[\nabla f_1(x)^T \Delta x \leq 0\]</div>
<div class="math notranslate nohighlight">
\[\nabla f_2(x)^T \Delta x \leq 0\]</div>
<div class="math notranslate nohighlight">
\[\nabla f_o(x)^T \Delta x &lt; 0\]</div>
<p><strong>No existe</strong> tal dirección <span class="math notranslate nohighlight">\(\Delta x\)</span> en el mínimo <span class="math notranslate nohighlight">\(x^* = \left [ \begin{array}{c}-\sqrt{2} \\ 0 \end{array} \right ]\)</span>:</p>
<img src="https://dl.dropboxusercontent.com/s/9pulmvgd21qmiu3/ej3b_CIEO_problems.png?dl=0" heigth="450" width="450">
<p>En este caso la función Lagrangiana es: <span class="math notranslate nohighlight">\(\mathcal{L}(x, \lambda_1) = f_o(x) + \lambda_1 f_1(x) + \lambda_2 f_2(x)\)</span> y por el ejemplo 2 si no existe <span class="math notranslate nohighlight">\(\Delta x\)</span> en un punto <span class="math notranslate nohighlight">\(x^*\)</span> entonces:</p>
<div class="math notranslate nohighlight">
\[\nabla_x \mathcal{L}(x^*, \lambda^*) = 0\]</div>
<div class="math notranslate nohighlight">
\[\lambda^* \geq 0\]</div>
<p>considerando <span class="math notranslate nohighlight">\(\lambda^*\)</span> al vector de multiplicadores de Lagrange que contiene <span class="math notranslate nohighlight">\(\lambda_1^*, \lambda_2^*\)</span> y la última desigualdad se refiere a que <span class="math notranslate nohighlight">\(\lambda_1^*, \lambda_2^* \geq 0\)</span>. Además la condición de holgura complementaria es:</p>
<div class="math notranslate nohighlight">
\[\lambda_1^*f_1(x^*) = 0\]</div>
<div class="math notranslate nohighlight">
\[\lambda_2^*f_2(x^*) = 0\]</div>
<p>Para el punto <span class="math notranslate nohighlight">\(x^* = \left [ \begin{array}{c}-\sqrt{2} \\ 0 \end{array} \right ]\)</span> se tiene:</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p><span class="math notranslate nohighlight">\(f_1(x) = x_1^2 + x_2^2 -2\)</span>, <span class="math notranslate nohighlight">\(f_2(x) = -x_2\)</span></p>
</div>
<div class="math notranslate nohighlight">
\[\begin{split}\nabla f_o(x^*) = \left [
\begin{array}{c}
1 \\
1 \\
\end{array}
\right],
\nabla f_1(x^*) = \left [
\begin{array}{c}
-2\sqrt{2} \\
0 \\
\end{array}
\right],
\nabla f_2(x^*) = \left [
\begin{array}{c}
0 \\
-1 \\
\end{array}
\right]
\end{split}\]</div>
<p>Y con <span class="math notranslate nohighlight">\(\lambda^* = \left [ \begin{array}{c} \frac{1}{2\sqrt{2}} \\ 1 \end{array} \right ]\)</span> se cumple:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
\nabla_x \mathcal{L}(x^*, \lambda^*) &amp;=&amp; \nabla f_o(x^*) + \lambda^{*T} \left ( \nabla f_1(x^*) \quad \nabla f_2(x^*) \right )\nonumber \\
&amp;=&amp; \nabla f_o(x^*) + \lambda_1^* \nabla f_1(x^*) + \lambda_2^* \nabla f_2(x^*) = 0 \nonumber
\end{eqnarray}
\end{split}\]</div>
<p>Por tanto <span class="math notranslate nohighlight">\(x^*\)</span> es mínimo local y no existe dirección de descenso <span class="math notranslate nohighlight">\(\Delta x\)</span>.</p>
<p>Para un punto diferente a <span class="math notranslate nohighlight">\(x^*\)</span> por ejemplo <span class="math notranslate nohighlight">\(x = \left [ \begin{array}{c}\sqrt{2} \\ 0 \end{array} \right ]\)</span> ambas restricciones <span class="math notranslate nohighlight">\(f_1\)</span> y <span class="math notranslate nohighlight">\(f_2\)</span> son activas:</p>
<img src="https://dl.dropboxusercontent.com/s/vh6xjjwifzgjye9/ej3c_CIEO_problems.png?dl=0" heigth="400" width="400">
<div class="math notranslate nohighlight">
\[\begin{split}\nabla f_o(x) = \left [
\begin{array}{c}
1 \\
1 \\
\end{array}
\right],
\nabla f_1(x) = \left [
\begin{array}{c}
2\sqrt{2} \\
0 \\
\end{array}
\right],
\nabla f_2(x) = \left [
\begin{array}{c}
0 \\
-1 \\
\end{array}
\right]
\end{split}\]</div>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p><span class="math notranslate nohighlight">\(f_1(x) = x_1^2 + x_2^2 -2\)</span>, <span class="math notranslate nohighlight">\(f_2(x) = -x_2\)</span></p>
</div>
<p>Y el vector <span class="math notranslate nohighlight">\(\Delta x = \left [ \begin{array}{c}-1 \\ 0 \end{array} \right ]\)</span> satisface las restricciones:</p>
<div class="math notranslate nohighlight">
\[\nabla f_1(x)^T \Delta x \leq 0\]</div>
<div class="math notranslate nohighlight">
\[\nabla f_2(x)^T \Delta x \leq 0\]</div>
<div class="math notranslate nohighlight">
\[\nabla f_o(x)^T \Delta x &lt; 0\]</div>
<img src="https://dl.dropboxusercontent.com/s/gfcfk8bzoej9hff/ej3d_CIEO_problems.png?dl=0" heigth="450" width="450"><p>Revisando si tal punto satisface:</p>
<div class="math notranslate nohighlight">
\[\nabla_x \mathcal{L}(x, \lambda) = 0\]</div>
<div class="math notranslate nohighlight">
\[\lambda \geq 0\]</div>
<div class="math notranslate nohighlight">
\[\lambda_1f_1(x) = 0\]</div>
<div class="math notranslate nohighlight">
\[\lambda_2f_2(x) = 0\]</div>
<p>Si <span class="math notranslate nohighlight">\(\lambda = \left [ \begin{array}{c}\frac{-1}{2\sqrt{2}} \\ 1 \end{array} \right ]\)</span> entonces <span class="math notranslate nohighlight">\(\nabla_x \mathcal{L}(x, \lambda) = 0\)</span> pero <span class="math notranslate nohighlight">\(\lambda_1 &lt;0\)</span>.</p>
<p>Por lo tanto sí existe <span class="math notranslate nohighlight">\(\Delta x\)</span> de descenso y <span class="math notranslate nohighlight">\(x\)</span> no es mínimo.</p>
<p>Para un punto diferente a <span class="math notranslate nohighlight">\(x^*\)</span> en el interior del conjunto de factibilidad por ejemplo <span class="math notranslate nohighlight">\(x = \left [ \begin{array}{c}1 \\ 0 \end{array} \right ]\)</span> sólo la restricción <span class="math notranslate nohighlight">\(f_2\)</span> es activa:</p>
<img src="https://dl.dropboxusercontent.com/s/9e7vhbvsc0253yp/ej3f_CIEO_problems.png?dl=0" heigth="400" width="400"><div class="math notranslate nohighlight">
\[\begin{split}\nabla f_o(x) = \left [
\begin{array}{c}
1 \\
1 \\
\end{array}
\right],
\nabla f_1(x) = \left [
\begin{array}{c}
2\\
0 \\
\end{array}
\right],
\nabla f_2(x) = \left [
\begin{array}{c}
0 \\
-1 \\
\end{array}
\right]
\end{split}\]</div>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p><span class="math notranslate nohighlight">\(f_1(x) = x_1^2 + x_2^2 -2\)</span>, <span class="math notranslate nohighlight">\(f_2(x) = -x_2\)</span></p>
</div>
<p>Dado que <span class="math notranslate nohighlight">\(f_1\)</span> sólo restringe a estar en el interior del círculo, el vector <span class="math notranslate nohighlight">\(\Delta x\)</span> en este caso debe cumplir con mantener la factibilidad dada por la restricción <span class="math notranslate nohighlight">\(f_2\)</span> que representa la parte superior del círculo (incluyendo la frontera). Una dirección <span class="math notranslate nohighlight">\(\Delta x\)</span> suficientemente pequeña cumplirá <span class="math notranslate nohighlight">\(f_1\)</span>. Entonces <span class="math notranslate nohighlight">\(\Delta x\)</span> debe satisfacer:</p>
<div class="math notranslate nohighlight">
\[\nabla f_2(x)^T \Delta x \leq 0\]</div>
<div class="math notranslate nohighlight">
\[\nabla f_o(x)^T \Delta x &lt; 0\]</div>
<p>para ser de descenso. El vector <span class="math notranslate nohighlight">\(\Delta x = \left [ \begin{array}{c}-\frac{1}{2} \\ \frac{1}{4} \end{array} \right ]\)</span> satisface lo anterior y por tanto es de descenso.</p>
<img src="https://dl.dropboxusercontent.com/s/xy0sn8up4ixuf09/ej3e_CIEO_problems.png?dl=0" heigth="400" width="400"><p>Revisando si tal punto satisface:</p>
<div class="math notranslate nohighlight">
\[\nabla_x \mathcal{L}(x, \lambda) = 0\]</div>
<div class="math notranslate nohighlight">
\[\lambda \geq 0\]</div>
<div class="math notranslate nohighlight">
\[\lambda_1f_1(x) = 0\]</div>
<div class="math notranslate nohighlight">
\[\lambda_2f_2(x) = 0\]</div>
<p>Para este punto como <span class="math notranslate nohighlight">\(f_1\)</span> es inactiva entonces <span class="math notranslate nohighlight">\(\lambda_1 = 0\)</span> por holgura complementaria. Si deseamos que <span class="math notranslate nohighlight">\(\nabla_x \mathcal{L}(x, \lambda)=0\)</span> entonces debemos encontrar <span class="math notranslate nohighlight">\(\lambda\)</span> tal que:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{eqnarray}
\nabla f_o(x) + \lambda_1 \nabla f_1(x) + \lambda_2 \nabla f_2(x) &amp;=&amp;  \left [
\begin{array}{c}
1 \\
1 \\
\end{array}
\right] + 
0 \cdot
\left [
\begin{array}{c}
2\\
0 \\
\end{array}
\right] + 
\lambda_2 \left [
\begin{array}{c}
0 \\
-1 \\
\end{array}
\right] \nonumber \\
&amp;=&amp;\left [
\begin{array}{c}
1 \\
1 - \lambda_2
\end{array}
\right ]
=0
\end{eqnarray}
\end{split}\]</div>
<p>No existe <span class="math notranslate nohighlight">\(\lambda_2\)</span> y por tanto <span class="math notranslate nohighlight">\(\lambda\)</span> que satisfaga la ecuación anterior. Por lo tanto sí existe <span class="math notranslate nohighlight">\(\Delta x\)</span> de descenso y <span class="math notranslate nohighlight">\(x\)</span> no es mínimo.</p>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>En resúmen de los 3 ejemplos anteriores: si <span class="math notranslate nohighlight">\(x^*\)</span> es una solución local del <a class="reference internal" href="../3.1/Definicion_de_problema_optimizacion_conjuntos_y_funciones_convexas.html#pestopt"><span class="std std-ref">problema estándar de optimización</span></a> entonces existen vectores multiplicadores de Lagrange <span class="math notranslate nohighlight">\(\nu^*, \lambda^*\)</span> para las restricciones de igualdad y desigualdad respectivamente tales que:</p>
<div class="math notranslate nohighlight">
\[\nabla_x\mathcal{L}(x^*, \nu^*, \lambda^*) = 0\]</div>
<div class="math notranslate nohighlight">
\[h_i(x^*) = 0 \quad \forall i = 1, \dots, p\]</div>
<div class="math notranslate nohighlight">
\[f_i(x^*) = 0 \quad \forall i = 1, \dots, m\]</div>
<div class="math notranslate nohighlight">
\[\lambda_i^* \geq 0 \quad \forall i = 1, \dots, m\]</div>
<div class="math notranslate nohighlight">
\[\lambda_i^* f_i(x^*) = 0 \quad \forall i = 1, \dots, m\]</div>
<p><strong>faltan considerar suposiciones importantes para tener completo el resultado</strong> pero los ejemplos anteriores abren camino hacia las <strong>condiciones de <a class="reference external" href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions">Karush-Kuhn-Tucker</a> (KKT) de optimalidad</strong>.</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Obsérvese que las condiciones KKT de optimalidad son condiciones <strong>necesarias</strong> e involucran información de primer orden.</p>
</div>
</div>
</div>
<div class="section" id="ejemplo-constrained-inequality-convex-optimization-cico-maquina-de-soporte-vectorial-svm-para-datos-linealmente-separables">
<h2>Ejemplo <em>Constrained Inequality Convex Optimization</em> (CICO): Máquina de Soporte Vectorial (SVM) para datos linealmente separables<a class="headerlink" href="#ejemplo-constrained-inequality-convex-optimization-cico-maquina-de-soporte-vectorial-svm-para-datos-linealmente-separables" title="Permalink to this headline">¶</a></h2>
<div class="section" id="clasificador-lineal">
<h3>Clasificador lineal<a class="headerlink" href="#clasificador-lineal" title="Permalink to this headline">¶</a></h3>
<p>Considérese dos conjuntos de puntos en <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span> dados por <span class="math notranslate nohighlight">\(\{x_1, x_2, \dots, x_N\}\)</span>, <span class="math notranslate nohighlight">\(\{y_1, y_2, \dots, y_M\}\)</span> y el objetivo de encontrar una función <span class="math notranslate nohighlight">\(f: \mathbb{R}^n \rightarrow \mathbb{R}\)</span> que sea positiva en el primer conjunto de puntos y negativa en el segundo conjunto de puntos:</p>
<div class="math notranslate nohighlight">
\[f(x_i) &gt; 0 \quad \forall i = 1, \dots, N\]</div>
<div class="math notranslate nohighlight">
\[f(y_i) &lt; 0 \quad \forall i = 1, \dots, M\]</div>
<p>Si existe tal función entonces <span class="math notranslate nohighlight">\(f\)</span> o el conjunto <span class="math notranslate nohighlight">\(\{x : f(x) = 0\}\)</span> separa o clasifica los <span class="math notranslate nohighlight">\(2\)</span> conjuntos de puntos.</p>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>La clasificación puede ser débil que significa: <span class="math notranslate nohighlight">\(f(x_i) \geq 0\)</span>, <span class="math notranslate nohighlight">\(f(y_i) \leq 0\)</span>.</p>
</div>
<p>Para el caso en el que los datos son linealmente separables se busca una función afín de la forma <span class="math notranslate nohighlight">\(f(x) = a^Tx - b\)</span> que clasifique los puntos, esto es:</p>
<div class="math notranslate nohighlight">
\[a^Tx_i - b &gt; 0, \quad \forall i=1, \dots, N\]</div>
<div class="math notranslate nohighlight">
\[a^Ty_i - b &lt; 0, \quad \forall i=1, \dots, M\]</div>
<p>Geométricamente se busca un hiperplano de dimensión <span class="math notranslate nohighlight">\(n-1\)</span> que separe ambos conjuntos:</p>
<img src="https://dl.dropboxusercontent.com/s/qvrqz6ciyutzdkf/CIECO_SVM_1.png?dl=0" heigth="300" width="300"><p>Si <span class="math notranslate nohighlight">\(x, y\)</span> son puntos en el hiperplano entonces <span class="math notranslate nohighlight">\(f(x) = f(y) = 0\)</span> y además <span class="math notranslate nohighlight">\(a^T(x-y) = b - b = 0\)</span>, así <span class="math notranslate nohighlight">\(a\)</span> es ortogonal a todo punto en el hiperplano y determina la orientación de este:</p>
<img src="https://dl.dropboxusercontent.com/s/rswe1hzpxxgt88n/CIECO_SVM_2.png?dl=0" heigth="350" width="350"><p>Si <span class="math notranslate nohighlight">\(x\)</span> es un punto en el hiperplano tenemos <span class="math notranslate nohighlight">\(f(x) = 0\)</span> por lo tanto la distancia perpendicular del origen al hiperplano está dada por: <span class="math notranslate nohighlight">\(\frac{|a^Tx|}{||a||_2} = \frac{|-b|}{||a||_2} = \frac{|b|}{||a||_2}\)</span> y el parámetro <span class="math notranslate nohighlight">\(b\)</span> determina la localización del hiperplano:</p>
<img src="https://dl.dropboxusercontent.com/s/5uyp1d75ovl6sm9/CIECO_SVM_3.png?dl=0" heigth="450" width="450"><p>Sean <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span> y <span class="math notranslate nohighlight">\(x_{\perp} \in \mathbb{R}^n\)</span> la proyección ortogonal en el hiperplano:</p>
<img src="https://dl.dropboxusercontent.com/s/u4pruk4ss53m8oz/CIECO_SVM_4.png?dl=0" heigth="550" width="550"><p>tenemos: <span class="math notranslate nohighlight">\(a^Tx = a^Tx_{\perp} + k||a||_2 = b + k ||a||_2\)</span> por lo que <span class="math notranslate nohighlight">\(a^Tx - b = k||a||_2\)</span> y:</p>
<div class="math notranslate nohighlight">
\[k = \frac{a^Tx-b}{||a||_2} = \frac{f(x)}{||a||_2},\]</div>
<p>esto es, <span class="math notranslate nohighlight">\(|f(x)|\)</span> da una medida de distancia perpendicular de <span class="math notranslate nohighlight">\(x\)</span> al hiperplano.</p>
</div>
<div class="section" id="modelo-de-svm">
<h3>Modelo de SVM<a class="headerlink" href="#modelo-de-svm" title="Permalink to this headline">¶</a></h3>
<p>En este modelo se desea obtener:</p>
<div class="math notranslate nohighlight">
\[a^Tx_i - b \geq 1, \quad \forall i=1, \dots, N\]</div>
<div class="math notranslate nohighlight">
\[a^Ty_i - b \leq -1, \quad \forall i=1, \dots, M\]</div>
<p>para clasificar a datos linealmente separables:</p>
<img src="https://dl.dropboxusercontent.com/s/3rxwwrgsudjqv9j/CIECO_SVM_5.png?dl=0" heigth="350" width="350"><p>Obsérvese que existen una infinidad de hiperplanos que separan a los datos anteriores:</p>
<img src="https://dl.dropboxusercontent.com/s/hetnb5objatjb8y/CIECO_SVM_6.png?dl=0" heigth="350" width="350"><p>En la SVM buscamos un hiperplano que tenga la máxima separación de cada una de las distancias de los datos al mismo:</p>
<img src="https://dl.dropboxusercontent.com/s/arq3kx1rzozjtbv/CIECO_SVM_7.png?dl=0" heigth="400" width="400"><p>Una distancia al hiperplano para los datos <span class="math notranslate nohighlight">\(x_i, \forall i=1, \dots, N\)</span> y otra distancia para los datos <span class="math notranslate nohighlight">\(y_i \forall i=1, \dots, M\)</span>.</p>
<p>Por la sección anterior, la distancia al hiperplano para cada conjunto de datos está dada por:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min_{i=1,\dots, N} \frac{|f(x_i)|}{||a||_2}\]</div>
<div class="math notranslate nohighlight">
\[\displaystyle \min_{i=1,\dots, M} \frac{|f(y_i)|}{||a||_2}\]</div>
<p>Entonces encontrar un hiperplano que tenga la máxima separación de cada una de las distancias de los datos al hiperplano se puede escribir como el problema:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \max_{a,b} \left \{  \min_{i=1,\dots, N} \frac{|f(x_i)|}{||a||_2}  + \min_{i=1,\dots, M} \frac{|f(y_i)|}{||a||_2} \right \}\]</div>
<p>Obsérvese que el cociente <span class="math notranslate nohighlight">\(\frac{|f(x_i)|}{||a||_2}\)</span> es invariante ante reescalamientos por ejemplo:</p>
<div class="math notranslate nohighlight">
\[\frac{ka^Tx + kb}{||ka||_2} = \frac{a^Tx + b}{||a||_2} \forall k \neq 0\]</div>
<p>Por tanto, si los índices <span class="math notranslate nohighlight">\(i_1, i_2\)</span> cumplen:</p>
<div class="math notranslate nohighlight">
\[i_1 = \text{argmin}_{i=1,\dots, N} \left \{\frac{|f(x_i)|}{||a||_2} \right \}\]</div>
<div class="math notranslate nohighlight">
\[i_2 = \text{argmin}_{i=1,\dots, M} \left \{\frac{|f(y_i)|}{||a||_2} \right \}\]</div>
<p>se puede hacer un reescalamiento para obtener:</p>
<div class="math notranslate nohighlight">
\[|f(x_{i_1})| = 1, \quad |f(x_i)| &gt; 1 \quad \forall i=1, \dots, N, i \neq i_1\]</div>
<div class="math notranslate nohighlight">
\[|f(y_{i_2})| = 1, \quad |f(y_i)| &gt; 1 \quad \forall i=1, \dots, M, i \neq i_2\]</div>
<p>Esto es, <span class="math notranslate nohighlight">\(|f(x_i)| \geq 1, \forall i=1, \dots, N\)</span>, <span class="math notranslate nohighlight">\(|f(y_i)| \geq 1, \forall i=1, \dots, M\)</span>.</p>
</div>
<div class="section" id="problema-de-optimizacion-en-svm">
<h3>Problema de optimización en SVM<a class="headerlink" href="#problema-de-optimizacion-en-svm" title="Permalink to this headline">¶</a></h3>
<p>El problema canónico o estándar de la máquina de soporte vectorial es:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \max_{a,b} \frac{2}{||a||_2}\]</div>
<div class="math notranslate nohighlight">
\[\text{sujeto a:}\]</div>
<div class="math notranslate nohighlight">
\[f(x_i) \geq 1, \quad \forall i=1, \dots, N\]</div>
<div class="math notranslate nohighlight">
\[f(y_i) \leq -1, \quad \forall i=1, \dots, M\]</div>
<p>El cual es equivalente a:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min_{a,b} \frac{||a||^2_2}{2}\]</div>
<div class="math notranslate nohighlight">
\[\text{sujeto a:}\]</div>
<div class="math notranslate nohighlight">
\[a^Tx_i - b \geq 1, \quad \forall i=1, \dots, N\]</div>
<div class="math notranslate nohighlight">
\[a^Ty_i -b \leq -1, \quad \forall i=1, \dots, M\]</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Se ha quitado el valor absoluto <span class="math notranslate nohighlight">\(|f(x_i)|, |f(y_i)|\)</span> pues <span class="math notranslate nohighlight">\(x_i, y_i\)</span> se asumen cumplen <span class="math notranslate nohighlight">\(a^Tx_i-b \geq 1\)</span>, <span class="math notranslate nohighlight">\(a^Ty_i-b \leq -1\)</span>, esto es, <span class="math notranslate nohighlight">\(x_i, y_i\)</span> son clasificados correctamente.</p></li>
<li><p>Este problema es de optimización convexa con restricciones de desigualdad.</p></li>
</ul>
</div>
</div>
<div class="section" id="vectores-de-soporte">
<h3>Vectores de soporte<a class="headerlink" href="#vectores-de-soporte" title="Permalink to this headline">¶</a></h3>
<p>Al encontrar este hiperplano tenemos otros dos hiperplanos paralelos ortogonales al vector <span class="math notranslate nohighlight">\(a\)</span> sin ningún dato entre ellos a una distancia de <span class="math notranslate nohighlight">\(\frac{1}{||a||_2}\)</span>:</p>
<img src="https://dl.dropboxusercontent.com/s/xvgsf8nsl9oakw6/CIECO_SVM_8.png?dl=0" heigth="350" width="350"><div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Aquellas restricciones activas son originadas por puntos con el nombre de vectores de soporte.</p>
</div>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Al resolver el problema de optimización siempre existirán al menos <span class="math notranslate nohighlight">\(2\)</span> restricciones activas pues siempre hay una distancia mínima para cada conjunto de puntos.</p>
</div>
</div>
</div>
<div class="section" id="problemas-de-programacion-lineal">
<h2>Problemas de programación lineal<a class="headerlink" href="#problemas-de-programacion-lineal" title="Permalink to this headline">¶</a></h2>
<p>Una gran cantidad de aplicaciones utilizan formulaciones de problemas de programación lineal que involucran igualdades y desigualdades cuya forma <strong>estándar</strong> está dada por:</p>
<div class="math notranslate nohighlight">
\[\min c^Tx\]</div>
<div class="math notranslate nohighlight">
\[\text{sujeto a:}\]</div>
<div class="math notranslate nohighlight">
\[Ax=b\]</div>
<div class="math notranslate nohighlight">
\[x \geq 0\]</div>
<p>donde: <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{m \times n}\)</span> y se <strong>asume</strong> <span class="math notranslate nohighlight">\(m \leq n\)</span> y tiene <em>rank</em> completo por renglones.</p>
<div class="admonition-observacion admonition">
<p class="admonition-title">Observación</p>
<p>Obsérvese que la función objetivo <span class="math notranslate nohighlight">\(f_o(x) = c^Tx\)</span> y tanto las restricciones de igualdad como desigualdad son funciones lineales.</p>
</div>
<div class="section" id="ejemplo-problema-de-transporte">
<h3>Ejemplo: problema de transporte<a class="headerlink" href="#ejemplo-problema-de-transporte" title="Permalink to this headline">¶</a></h3>
<p>Considérese que</p>
<p>las cantidades <span class="math notranslate nohighlight">\(a_1, a_2, \dots, a_m\)</span> respectivamente de un cierto producto que serán transportadas de <span class="math notranslate nohighlight">\(m\)</span> locaciones a</p>
</div>
<div class="section" id="ejemplo-problema-de-flujo-maximo">
<h3>Ejemplo: problema de flujo máximo<a class="headerlink" href="#ejemplo-problema-de-flujo-maximo" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="metodo-de-puntos-interiores">
<h2>Método de <a class="reference external" href="https://en.wikipedia.org/wiki/Interior-point_method">puntos interiores</a><a class="headerlink" href="#metodo-de-puntos-interiores" title="Permalink to this headline">¶</a></h2>
<div class="sidebar">
<p class="sidebar-title">Un poco de historia</p>
<p>El desarrollo por Dantzig del <a class="reference external" href="https://en.wikipedia.org/wiki/Simplex_algorithm">método simplex</a> en los <span class="math notranslate nohighlight">\(40\)</span>’s marcó el inicio de la era moderna en optimización. Tal método hizo posible que economistas formularan y analizaran modelos grandes en una forma sistemática y eficiente.</p>
<p>Hoy en día continúa siendo uno de los métodos más utilizados para resolver programas lineales. Pertenece a una clase general de algoritmos de optimización con restricciones conocida como <a class="reference external" href="https://en.wikipedia.org/wiki/Active-set_method">métodos de conjuntos activos</a> en los que la tarea fundamental es determinar cuáles restricciones son activas y cuáles inactivas en la solución. Mantiene estimaciones de conjuntos de índices de restricciones activas e inactivas que son actualizadas y realiza cambios modestos a tales conjuntos en cada paso del algoritmo.</p>
<p>No obstante puede ser ineficiente en problemas lineales “patológicos” pues el tiempo para resolver tales problemas es exponencial respecto al tamaño del problema (medido como el número de variables y la cantidad de almacenamiento para los datos del problema). Para la mayoría de problemas prácticos el método simplex es mucho más eficiente que estos casos “patológicos” pero esto motivó la investigación y desarrollo de nuevos algoritmos con mejor desempeño.</p>
<p>En 1984 Karmakar publicó el <a class="reference external" href="https://en.wikipedia.org/wiki/Karmarkar%27s_algorithm">algoritmo</a> que lleva su mismo nombre que tiene una complejidad polinomial y en la práctica resulto ser eficiente.</p>
</div>
<p>En los <span class="math notranslate nohighlight">\(80\)</span>’s se descubrió que muchos problemas lineales <em>large scale</em> podían ser resueltos eficientemente utilizando formulaciones y algoritmos de programación no lineal y de ecuaciones no lineales. Una característica de tales métodos era que requerían que todas las iteraciones satisfacieran las restricciones de desigualdad de forma <strong>estricta</strong> con lo que se conocieron con el nombre de <strong>puntos interiores</strong>. A inicios de los <span class="math notranslate nohighlight">\(90\)</span>’s una subclase de métodos de puntos interiores conocidos con el nombre de <strong>primal-dual</strong> se distinguieron como las metodologías más eficientes en la práctica y probaron ser fuertes compeditores con el método simples en problemas <em>large scale</em>.</p>
<p><strong>Referencias:</strong></p>
<ol class="simple">
<li><p>S. P. Boyd, L. Vandenberghe, Convex Optimization, Cambridge University Press, 2009.</p></li>
<li><p>J. Dennis, R. B. Schnabel, Numerical Methods for Unconstrained Optimization and Nonlinear Equations, SIAM, 1996.</p></li>
<li><p>J. Nocedal, S. J. Wright, Numerical Optimization, Springer, 2006.</p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "palmoreck/dockerfiles-for-binder",
            ref: "jupyterlab_optimizacion",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./III.optimizacion_convexa/3.3"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../3.2/Algoritmos_de_descenso_y_busqueda_de_linea_en_uco.html" title="previous page">3.2 Algoritmos de descenso y búsqueda de línea en <em>Unconstrained Convex Optimization</em> (UCO)</a>
    <a class='right-next' id="next-link" href="../3.4/Ecuaciones_no_lineales.html" title="next page">3.4 Ecuaciones no lineales</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Erick Palacios Moreno<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../../_static/js/index.js"></script>
    
  </body>
</html>