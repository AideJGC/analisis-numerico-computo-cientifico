
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>5.5 Cómputo en paralelo usando GPUs en un sistema de memoria compartida (SMC)</title>
    
  <link rel="stylesheet" href="../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="6.1 Problemas tipo Unconstrained Convex Optimization (UCO)" href="../../VI.algoritmos_optimizacion_convexa/6.1/Problemas_UCO.html" />
    <link rel="prev" title="5.4 Cómputo en paralelo usando CPUs en un sistema de memoria compartida (SMC)" href="../5.4/Computo_en_paralelo_usando_CPUS_en_SMC.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../README.html">
   Optimización
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  I. Cómputo científico
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.1/Analisis_numerico_y_computo_cientifico.html">
   1.1 Análisis numérico y cómputo científico
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.2/Sistema_de_punto_flotante.html">
   1.2 Sistema de punto flotante
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.3/Normas_vectoriales_y_matriciales.html">
   1.3 Normas vectoriales y matriciales
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.4/Condicion_de_un_problema_y_estabilidad_de_un_algoritmo.html">
   1.4 Condición de un problema y estabilidad de un algoritmo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.5/Definicion_de_funcion_continuidad_derivada.html">
   1.5 Definición de función, continuidad y derivada
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.6/Polinomios_de_Taylor_y_diferenciacion_numerica.html">
   1.6 Polinomios de Taylor y diferenciación numérica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.7/Integracion_numerica.html">
   1.7 Integración Numérica
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  II. Cómputo matricial
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.1/Operaciones_y_transformaciones_basicas_del_Algebra_Lineal_Numerica.html">
   2.1 Operaciones y transformaciones básicas del Álgebra Lineal Numérica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.2/Eigenvalores_y_eigenvectores.html">
   2.2 Eigenvalores y eigenvectores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.3/Algoritmos_y_aplicaciones_de_eigenvalores_eigenvectores_de_una_matriz.html">
   2.3 Algoritmos y aplicaciones de eigenvalores y eigenvectores de una matriz
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.4/Valores_vectores_singulares_y_algoritmos_para_calcular_la_SVD.html">
   2.4 Valores, vectores singulares y algoritmos para calcular la SVD
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  III. Optimización convexa y ecuaciones no lineales
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../III.optimizacion_convexa/3.1/Definicion_de_problema_optimizacion_conjuntos_y_funciones_convexas.html">
   3.1 Definición de problemas de optimización, conjuntos y funciones convexas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../III.optimizacion_convexa/3.2/Algoritmos_de_descenso_y_busqueda_de_linea_en_uco.html">
   3.2 Algoritmos de descenso y búsqueda de línea en
   <em>
    Unconstrained Convex Optimization
   </em>
   (UCO)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../III.optimizacion_convexa/3.3/Ejemplos_problemas_UCO_e_intro_CIEO_y_PI.html">
   3.3 Ejemplos de problemas UCO, introducción a
   <em>
    Constrained Inequality and Equality Optimization
   </em>
   (CIEO) y puntos interiores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../III.optimizacion_convexa/3.4/Ecuaciones_no_lineales.html">
   3.4 Ecuaciones no lineales
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  IV. Optimización en redes y programación lineal
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../IV.optimizacion_en_redes_y_prog_lineal/4.1/Definiciones_generales_de_flujo_en_redes.html">
   4.1 Definiciones generales de flujo en redes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../IV.optimizacion_en_redes_y_prog_lineal/4.2/Programacion_lineal_y_metodo_simplex.html">
   4.2 Programación lineal (PL) y método símplex
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../IV.optimizacion_en_redes_y_prog_lineal/4.3/Ejemplo_metodo_simplex_de_redes.html">
   4.3 Ejemplo del método símplex de redes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../IV.optimizacion_en_redes_y_prog_lineal/4.4/Dualidad_lema_de_Farkas_condiciones_KKT_de_optimalidad.html">
   4.4 Dualidad, lema de Farkas y condiciones de Karush-Kuhn-Tucker (KKT) de optimalidad
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../IV.optimizacion_en_redes_y_prog_lineal/4.5/Metodo_primal_dual_de_BL.html">
   4.5 Método primal-dual de barrera logarítmica (BL)
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  V. Optimización de código
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../5.1/introduccion_optimizacion_de_codigo.html">
   5.1 Introducción a optimización de código
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.2/Herramientas_de_lenguajes_y_del_SO_para_perfilamiento_e_implementaciones_de_BLAS.html">
   5.2 Herramientas de lenguajes de programación y del sistema operativo para perfilamiento e implementaciones de BLAS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.3/Compilacion_a_C.html">
   5.3 Compilación a C
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.4/Computo_en_paralelo_usando_CPUS_en_SMC.html">
   5.4 Cómputo en paralelo usando CPUs en un sistema de memoria compartida (SMC)
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   5.5 Cómputo en paralelo usando GPUs en un sistema de memoria compartida (SMC)
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  VI. Algoritmos de optimización convexa
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../VI.algoritmos_optimizacion_convexa/6.1/Problemas_UCO.html">
   6.1 Problemas tipo
   <em>
    Unconstrained Convex Optimization
   </em>
   (UCO)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../VI.algoritmos_optimizacion_convexa/6.2/Problemas_CECO.html">
   6.2 Problemas tipo
   <em>
    Constrained Equality Convex Optimization
   </em>
   (CECO)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../VI.algoritmos_optimizacion_convexa/6.3/Problemas_CIECO.html">
   6.3 Problemas tipo
   <em>
    Constrained Equality and Inequality Convex Optimization
   </em>
   (CIECO)
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/V.optimizacion_de_codigo/5.5/Computo_en_paralelo_usando_GPUS_en_SMC.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/palmoreck/dockerfiles-for-binder/jupyterlab_optimizacion_2?urlpath=lab/tree/analisis-numerico-computo-cientifico/libro_optimizacion/temas/V.optimizacion_de_codigo/5.5/Computo_en_paralelo_usando_GPUS_en_SMC.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#compute-unified-device-architecture-cuda">
   <em>
    Compute Unified Device Architecture
   </em>
   (CUDA)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#un-poco-de-historia">
     Un poco de historia…
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#diferencia-con-la-cpu-multicore">
   ¿Diferencia con la CPU multicore?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#otras-companias-producen-tarjetas-graficas">
   ¿Otras compañías producen tarjetas gráficas?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#si-tengo-una-tarjeta-grafica-de-amd-puedo-correr-un-programa-de-cuda">
   ¿Si tengo una tarjeta gráfica de AMD puedo correr un programa de CUDA?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#si-tengo-una-tarjeta-grafica-de-nvidia-un-poco-antigua-puedo-correr-un-programa-de-cuda">
   ¿Si tengo una tarjeta gráfica de NVIDIA un poco antigua puedo correr un programa de CUDA?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#que-es-cuda-c">
   ¿Qué es
   <em>
    CUDA C
   </em>
   ?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-que-se-refiere-la-terminologia-de-host-y-device">
   ¿A qué se refiere la terminología de host y device?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tengo-una-tarjeta-nvidia-cuda-capable-que-debo-realizar-primero">
   Tengo una tarjeta NVIDIA CUDA
   <em>
    capable
   </em>
   ¿qué debo realizar primero?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#instale-lo-necesario-y-al-ejecutar-en-la-terminal-nvcc-v-obtengo-la-version-como-puedo-probar-mi-instalacion">
   Instalé lo necesario y al ejecutar en la terminal
   <code class="docutils literal notranslate">
    <span class="pre">
     nvcc
    </span>
    <span class="pre">
     -V
    </span>
   </code>
   obtengo la versión… ¿cómo puedo probar mi instalación?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#por-que-usar-cuda-y-cuda-c-o-mas-general-computo-en-la-gpu">
   ¿Por qué usar CUDA y
   <em>
    CUDA-C
   </em>
   o más general cómputo en la GPU?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cuda-c">
   CUDA-C
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cupy">
   CuPy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gputools">
   Gputools
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#referencias-de-interes">
   Referencias de interés
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="computo-en-paralelo-usando-gpus-en-un-sistema-de-memoria-compartida-smc">
<span id="compparalelogpussmc"></span><h1>5.5 Cómputo en paralelo usando GPUs en un sistema de memoria compartida (SMC)<a class="headerlink" href="#computo-en-paralelo-usando-gpus-en-un-sistema-de-memoria-compartida-smc" title="Permalink to this headline">¶</a></h1>
<div class="admonition-notas-para-contenedor-de-docker admonition">
<p class="admonition-title">Notas para contenedor de docker:</p>
<p>Comando de docker para ejecución de la nota de forma local:</p>
<p>nota: cambiar <code class="docutils literal notranslate"><span class="pre">&lt;ruta</span> <span class="pre">a</span> <span class="pre">mi</span> <span class="pre">directorio&gt;</span></code> por la ruta de directorio que se desea mapear a <code class="docutils literal notranslate"><span class="pre">/datos</span></code> dentro del contenedor de docker.</p>
<p><code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">run</span> <span class="pre">--rm</span> <span class="pre">-v</span> <span class="pre">&lt;ruta</span> <span class="pre">a</span> <span class="pre">mi</span> <span class="pre">directorio&gt;:/datos</span> <span class="pre">--name</span> <span class="pre">jupyterlab_optimizacion_2</span> <span class="pre">-p</span> <span class="pre">8888:8888</span> <span class="pre">-p</span> <span class="pre">8787:8787</span> <span class="pre">-d</span> <span class="pre">palmoreck/jupyterlab_optimizacion_2:3.0.0</span></code></p>
<p>password para jupyterlab: <code class="docutils literal notranslate"><span class="pre">qwerty</span></code></p>
<p>Detener el contenedor de docker:</p>
<p><code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">stop</span> <span class="pre">jupyterlab_optimizacion_2</span></code></p>
<p>Documentación de la imagen de docker <code class="docutils literal notranslate"><span class="pre">palmoreck/jupyterlab_optimizacion_2:3.0.0</span></code> en <a class="reference external" href="https://github.com/palmoreck/dockerfiles/tree/master/jupyterlab/optimizacion_2">liga</a>.</p>
</div>
<hr class="docutils" />
<p>Nota generada a partir de <a class="reference external" href="https://www.dropbox.com/s/yjijtfuky3s5dfz/2.5.Compute_Unified_Device_Architecture.pdf?dl=0">liga</a></p>
<div class="tip admonition">
<p class="admonition-title">Al final de esta nota el y la lectora:</p>
<ul class="simple">
<li></li>
</ul>
</div>
<p>Se presentan códigos y sus ejecuciones en una máquina <code class="docutils literal notranslate"><span class="pre">&lt;falta</span> <span class="pre">colocar&gt;</span></code> de la nube de <a class="reference external" href="https://aws.amazon.com/">AWS</a>. Se utilizó la AMI <code class="docutils literal notranslate"><span class="pre">opt2-aws-educate-openblas-04-04-2021</span></code> de la región <code class="docutils literal notranslate"><span class="pre">us-east-1</span></code> (Virginia) para reproducibilidad de resultados. Tal AMI se construyó a partir de una AMI <code class="docutils literal notranslate"><span class="pre">ubuntu</span> <span class="pre">20.04</span> <span class="pre">-</span> <span class="pre">ami-042e8287309f5df03</span></code> con el <a class="reference external" href="https://github.com/palmoreck/scripts_for_useful_tools_installations/blob/main/AWS/ubuntu_20.04/optimizacion_2/script_profiling_and_BLAS.sh">script_profiling_and_BLAS.sh</a></p>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Si se utiliza la <em>AMI</em> <code class="docutils literal notranslate"><span class="pre">opt2-aws-educate-openblas-04-04-2021</span></code> colocar en <code class="docutils literal notranslate"><span class="pre">User</span> <span class="pre">data</span></code> el siguiente <em>script</em>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">##variables:</span>
<span class="nv">region</span><span class="o">=</span>us-east-1 <span class="c1">#make sure instance is in Virginia</span>
<span class="nv">name_instance</span><span class="o">=</span>OpenBLAS
<span class="nv">USER</span><span class="o">=</span>ubuntu
<span class="c1">##System update</span>
apt-get update -yq
<span class="c1">##Tag instance</span>
<span class="nv">INSTANCE_ID</span><span class="o">=</span><span class="k">$(</span>curl -s http://instance-data/latest/meta-data/instance-id<span class="k">)</span>
<span class="nv">PUBLIC_IP</span><span class="o">=</span><span class="k">$(</span>curl -s http://instance-data/latest/meta-data/public-ipv4<span class="k">)</span>
sudo -H -u <span class="nv">$USER</span> bash -c <span class="s2">&quot;/home/</span><span class="nv">$USER</span><span class="s2">/.local/bin/aws ec2 create-tags --resources </span><span class="nv">$INSTANCE_ID</span><span class="s2"> --tag Key=Name,Value=</span><span class="nv">$name_instance</span><span class="s2">-</span><span class="nv">$PUBLIC_IP</span><span class="s2"> --region=</span><span class="nv">$region</span><span class="s2">&quot;</span>
sudo -H -u <span class="nv">$USER</span> bash -c <span class="s2">&quot;cd / &amp;&amp; /home/</span><span class="nv">$USER</span><span class="s2">/.local/bin/jupyter lab --ip=0.0.0.0 --no-browser --config=/home/</span><span class="nv">$USER</span><span class="s2">/.jupyter/jupyter_notebook_config.py &amp;&quot;</span>
</pre></div>
</div>
</div>
<p>La máquina <code class="docutils literal notranslate"><span class="pre">&lt;falta</span> <span class="pre">colocar&gt;</span></code> tiene las siguientes características:</p>
<p><strong>Falta ejecutar de acuerdo a la máquina elegida</strong></p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
lscpu
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Architecture:                    x86_64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian
Address sizes:                   46 bits physical, 48 bits virtual
CPU(s):                          64
On-line CPU(s) list:             0-63
Thread(s) per core:              2
Core(s) per socket:              16
Socket(s):                       2
NUMA node(s):                    2
Vendor ID:                       GenuineIntel
CPU family:                      6
Model:                           79
Model name:                      Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz
Stepping:                        1
CPU MHz:                         2290.913
CPU max MHz:                     3000.0000
CPU min MHz:                     1200.0000
BogoMIPS:                        4600.03
Hypervisor vendor:               Xen
Virtualization type:             full
L1d cache:                       1 MiB
L1i cache:                       1 MiB
L2 cache:                        8 MiB
L3 cache:                        90 MiB
NUMA node0 CPU(s):               0-15,32-47
NUMA node1 CPU(s):               16-31,48-63
Vulnerability Itlb multihit:     KVM: Vulnerable
Vulnerability L1tf:              Mitigation; PTE Inversion
Vulnerability Mds:               Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unknown
Vulnerability Meltdown:          Mitigation; PTI
Vulnerability Spec store bypass: Vulnerable
Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:        Mitigation; Full generic retpoline, STIBP disabled, RSB filling
Vulnerability Srbds:             Not affected
Vulnerability Tsx async abort:   Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unknown
Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq monitor est ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm cpuid_fault invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm xsaveopt ida
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
sudo lshw -C memory
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  *-firmware
       description: BIOS
       vendor: Xen
       physical id: 0
       version: 4.11.amazon
       date: 08/24/2006
       size: 96KiB
       capabilities: pci edd
  *-memory
       description: System Memory
       physical id: 1000
       size: 256GiB
       capabilities: ecc
       configuration: errordetection=multi-bit-ecc
     *-bank:0
          description: DIMM RAM
          physical id: 0
          slot: DIMM 0
          size: 16GiB
          width: 64 bits
     *-bank:1
          description: DIMM RAM
          physical id: 1
          slot: DIMM 1
          size: 16GiB
          width: 64 bits
     *-bank:2
          description: DIMM RAM
          physical id: 2
          slot: DIMM 2
          size: 16GiB
          width: 64 bits
     *-bank:3
          description: DIMM RAM
          physical id: 3
          slot: DIMM 3
          size: 16GiB
          width: 64 bits
     *-bank:4
          description: DIMM RAM
          physical id: 4
          slot: DIMM 4
          size: 16GiB
          width: 64 bits
     *-bank:5
          description: DIMM RAM
          physical id: 5
          slot: DIMM 5
          size: 16GiB
          width: 64 bits
     *-bank:6
          description: DIMM RAM
          physical id: 6
          slot: DIMM 6
          size: 16GiB
          width: 64 bits
     *-bank:7
          description: DIMM RAM
          physical id: 7
          slot: DIMM 7
          size: 16GiB
          width: 64 bits
     *-bank:8
          description: DIMM RAM
          physical id: 8
          slot: DIMM 8
          size: 16GiB
          width: 64 bits
     *-bank:9
          description: DIMM RAM
          physical id: 9
          slot: DIMM 9
          size: 16GiB
          width: 64 bits
     *-bank:10
          description: DIMM RAM
          physical id: a
          slot: DIMM 10
          size: 16GiB
          width: 64 bits
     *-bank:11
          description: DIMM RAM
          physical id: b
          slot: DIMM 11
          size: 16GiB
          width: 64 bits
     *-bank:12
          description: DIMM RAM
          physical id: c
          slot: DIMM 12
          size: 16GiB
          width: 64 bits
     *-bank:13
          description: DIMM RAM
          physical id: d
          slot: DIMM 13
          size: 16GiB
          width: 64 bits
     *-bank:14
          description: DIMM RAM
          physical id: e
          slot: DIMM 14
          size: 16GiB
          width: 64 bits
     *-bank:15
          description: DIMM RAM
          physical id: f
          slot: DIMM 15
          size: 16GiB
          width: 64 bits
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
uname -ar #r for kernel, a for all
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Linux ip-10-0-0-140 5.4.0-1038-aws #40-Ubuntu SMP Fri Feb 5 23:50:40 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>En la celda anterior se utilizó el comando de <em>magic</em> <code class="docutils literal notranslate"><span class="pre">%%bash</span></code>. Algunos comandos de <em>magic</em> los podemos utilizar también con <code class="docutils literal notranslate"><span class="pre">import</span></code>. Ver <a class="reference external" href="https://ipython.readthedocs.io/en/stable/interactive/magics.html">ipython-magics</a></p>
</div>
<div class="section" id="compute-unified-device-architecture-cuda">
<h2><em>Compute Unified Device Architecture</em> (CUDA)<a class="headerlink" href="#compute-unified-device-architecture-cuda" title="Permalink to this headline">¶</a></h2>
<div class="section" id="un-poco-de-historia">
<h3>Un poco de historia…<a class="headerlink" href="#un-poco-de-historia" title="Permalink to this headline">¶</a></h3>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>GPGPU es un término que se utilizó para referirse a la programación general en unidades de procesamiento gráfico, hoy en día se conoce simplemente como <em>GPU programming</em>. Ver <a class="reference external" href="https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units">General-purpose computing on graphics processing units</a>.</p>
</div>
<p>La industria de videojuegos impulsó el desarrollo de las tarjetas gráficas a una velocidad sin precedente a partir del año 1999 para incrementar el nivel de detalle visual en los juegos de video. Alrededor del 2003 se planteó la posibilidad de utilizar las unidades de procesamiento gráfico para procesamiento en paralelo relacionado con aplicaciones distintas al ambiente de gráficas. A partir del 2006 la empresa <a class="reference external" href="https://www.nvidia.com/en-us/about-nvidia/">NVIDIA</a> introdujo CUDA, una plataforma GPGPU y un modelo de programación que facilita el procesamiento en paralelo en las GPU’s.</p>
<p>Desde entonces las tarjetas gráficas han creado una brecha significativa con las unidades de procesamiento, CPU’s. Ver por ejemplo las gráficas que <em>NVIDIA</em> publica año tras año y que están relacionadas con el número de operaciones en punto flotante por segundo (FLOPS) y la transferencia de datos en la memoria RAM de la GPU: <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#from-graphics-processing-to-general-purpose-parallel-computing">from-graphics-processing-to-general-purpose-parallel-computing</a></p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>La GPU y la CPU están conectadas por una interconexión de nombre <a class="reference external" href="https://en.wikipedia.org/wiki/Conventional_PCI">PCI</a>.</p>
</div>
<p>Hoy en día se continúa el desarrollo de GPU’s con mayor RAM, con mayor capacidad de cómputo y mejor conectividad con la CPU. Estos avances han permitido resolver problemas con mejor exactitud que los resueltos con las CPU’s, por ejemplo en el terreno de <em>deep learning</em> en reconocimiento de imágenes. Ver <a class="reference external" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">ImageNet Classification with Deep Convolutional Neural Networks</a>, <a class="reference external" href="https://medium.com/limitlessai/2012-a-breakthrough-year-for-deep-learning-2a31a6796e73">2012: A Breakthrough Year for Deep Learning</a>.</p>
<div class="admonition-observacion admonition">
<p class="admonition-title">Observación</p>
<p>Para avances al día de hoy ver <a class="reference external" href="https://devblogs.nvidia.com/nvidia-turing-architecture-in-depth/">NVIDIA Turing Architecture In-Depth</a>, <a class="reference external" href="https://wccftech.com/samsung-amd-rdna-gpu-2021/">samsung-amd-rdna-gpu-2021</a>, <a class="reference external" href="https://www.theguardian.com/games/2020/mar/19/playstation-5-specifications-revealed-but-design-is-still-a-mystery">playstation-5-specifications-revealed-but-design-is-still-a-mystery</a>, <a class="reference external" href="https://news.xbox.com/en-us/2020/03/16/xbox-series-x-tech/">xbox-series-x-tech</a> y recientemente <a class="reference external" href="https://www.ibm.com/blogs/nordic-msp/ibm-supercomputer-summit-attacks-coronavirus/">IBM Supercomputer Summit Attacks Coronavirus…</a>.</p>
</div>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Recuérdese la <a class="reference external" href="https://en.wikipedia.org/wiki/Flynn%27s_taxonomy">taxonomía de Flynn</a>.</p>
</div>
<p>La arquitectura en la que podemos ubicar a las GPU’s es en la de un sistema MIMD y SIMD. De hecho es <a class="reference external" href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_threads">SIMT: Simple Instruction Multiple Thread</a> en un modelo de sistema de memoria compartida pues “los <em>threads</em> en un <em>warp</em> cargan la misma instrucción para ser ejecutada”.</p>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Un <em>warp</em> en el contexto de GPU <em>programming</em> es un conjunto de <em>threads</em> y que equivale a <span class="math notranslate nohighlight">\(32\)</span>, esto es, un <em>warp</em> equivale a <span class="math notranslate nohighlight">\(32\)</span> <em>threads</em>.</p>
</div>
</div>
</div>
<div class="section" id="diferencia-con-la-cpu-multicore">
<h2>¿Diferencia con la CPU multicore?<a class="headerlink" href="#diferencia-con-la-cpu-multicore" title="Permalink to this headline">¶</a></h2>
<img src="https://dl.dropboxusercontent.com/s/k11qub01w4nvksi/CPU_multicore.png?dl=0" heigth="500" width="500">
<p><strong>GPU</strong></p>
<img src="https://dl.dropboxusercontent.com/s/lw9kia12qhwp95r/GPU.png?dl=0" heigth="500" width="500"><div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Obsérvese en el dibujo anterior la diferencia en tamaño del caché en la CPU y GPU. También la unidad de control es más pequeña en la GPU.</p>
</div>
<p>A diferencia de una máquina <em>multicore</em> o multi CPU’s con la habilidad de lanzar en un instante de tiempo unos cuantos <em>threads</em>, por ejemplo cuatro threads en una máquina <em>quad core</em>, la GPU puede lanzar cientos o miles de threads en un instante siendo cada core <em>heavily multithreaded</em>. Sí hay restricciones en el número de threads que se pueden lanzar en un instante pues las tarjetas gráficas tienen diferentes características (modelo) y arquitecturas (ver <a class="reference external" href="https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units">List of NVIDIA GPU’s</a>) pero la diferencia es grande. Por ejemplo, el modelo <strong>GT 200</strong> (2009) en un instante puede lanzar 30,720 threads.</p>
<p>Ver <a class="reference external" href="https://computer.howstuffworks.com/graphics-card1.htm">How Graphics Cards Work</a> y <a class="reference external" href="https://computer.howstuffworks.com/microprocessor.htm">How Microprocessors Work</a> para más información.</p>
</div>
<div class="section" id="otras-companias-producen-tarjetas-graficas">
<h2>¿Otras compañías producen tarjetas gráficas?<a class="headerlink" href="#otras-companias-producen-tarjetas-graficas" title="Permalink to this headline">¶</a></h2>
<p>Ver por ejemplo la lista de GPU’s de <a class="reference external" href="https://en.wikipedia.org/wiki/List_of_AMD_graphics_processing_units">Advanced Micro Devices</a></p>
</div>
<div class="section" id="si-tengo-una-tarjeta-grafica-de-amd-puedo-correr-un-programa-de-cuda">
<h2>¿Si tengo una tarjeta gráfica de AMD puedo correr un programa de CUDA?<a class="headerlink" href="#si-tengo-una-tarjeta-grafica-de-amd-puedo-correr-un-programa-de-cuda" title="Permalink to this headline">¶</a></h2>
<p>No es posible pero entre las alternativas están:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.khronos.org/opencl/">OpenCl</a></p></li>
<li><p><a class="reference external" href="https://www.openacc.org/about">OpenACC</a></p></li>
</ul>
</div>
<div class="section" id="si-tengo-una-tarjeta-grafica-de-nvidia-un-poco-antigua-puedo-correr-un-programa-de-cuda">
<h2>¿Si tengo una tarjeta gráfica de NVIDIA un poco antigua puedo correr un programa de CUDA?<a class="headerlink" href="#si-tengo-una-tarjeta-grafica-de-nvidia-un-poco-antigua-puedo-correr-un-programa-de-cuda" title="Permalink to this headline">¶</a></h2>
<p>Las GPU’s producidas por NVIDIA desde 2006 son capaces de correr programas basados en <strong>CUDA C</strong>. La cuestión sería revisar qué <em>compute capability</em> tiene tu tarjeta. Ver <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities">Compute Capabilities</a> para las características que tienen las tarjetas más actuales.</p>
</div>
<div class="section" id="que-es-cuda-c">
<h2>¿Qué es <em>CUDA C</em>?<a class="headerlink" href="#que-es-cuda-c" title="Permalink to this headline">¶</a></h2>
<p>Es una extensión al lenguaje <em>C</em> de programación en el que se utiliza una nueva sintaxis para procesamiento en la GPU. Contiene también una librería <em>runtime</em> que define funciones que se ejecutan desde el <em><strong>host</strong></em> por ejemplo para alojar y desalojar memoria en el <em><strong>device</strong></em>, transferir datos entre la memoria <em>host</em> y la memoria <em>device</em> o manejar múltiples devices. La librería <em>runtime</em> está hecha encima de una API de C de bajo nivel llamada <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-driver-api/index.html">NVIDIA CUDA Driver API</a> la cual es accesible desde el código. Para información de la API de la librería runtime ver <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/index.html">NVIDIA CUDA Runtime API</a>.</p>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>La transferencia de datos entre la memoria del <em>host</em> a <em>device</em> o viceversa es un <em>bottleneck</em> fuerte.</p>
</div>
</div>
<div class="section" id="a-que-se-refiere-la-terminologia-de-host-y-device">
<h2>¿A qué se refiere la terminología de host y device?<a class="headerlink" href="#a-que-se-refiere-la-terminologia-de-host-y-device" title="Permalink to this headline">¶</a></h2>
<p>Host es la máquina multicore o multi CPU’s y device es la GPU. Una máquina puede tener múltiples GPU’s por lo que tendrá múltiples <em>devices</em>.</p>
</div>
<div class="section" id="tengo-una-tarjeta-nvidia-cuda-capable-que-debo-realizar-primero">
<h2>Tengo una tarjeta NVIDIA CUDA <em>capable</em> ¿qué debo realizar primero?<a class="headerlink" href="#tengo-una-tarjeta-nvidia-cuda-capable-que-debo-realizar-primero" title="Permalink to this headline">¶</a></h2>
<p>Realizar instalaciones dependiendo de tu sistema operativo. Ver <a class="reference external" href="https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/tree/master/C/extensiones_a_C/CUDA/instalacion">Instalación</a> donde además se encontrará información para instalación de <a class="reference external" href="https://github.com/NVIDIA/nvidia-docker">nvidia-docker</a>.</p>
</div>
<div class="section" id="instale-lo-necesario-y-al-ejecutar-en-la-terminal-nvcc-v-obtengo-la-version-como-puedo-probar-mi-instalacion">
<h2>Instalé lo necesario y al ejecutar en la terminal <code class="docutils literal notranslate"><span class="pre">nvcc</span> <span class="pre">-V</span></code> obtengo la versión… ¿cómo puedo probar mi instalación?<a class="headerlink" href="#instale-lo-necesario-y-al-ejecutar-en-la-terminal-nvcc-v-obtengo-la-version-como-puedo-probar-mi-instalacion" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p>Obteniendo información del NVIDIA driver ejecutando en la terminal:</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$nvidia-smi

+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.26       Driver Version: 440.26       CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 750     Off  | 00000000:01:00.0 Off |                  N/A |
| 40%   29C    P8     1W /  38W |     55MiB /   978MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
+-----------------------------------------------------------------------------+
</pre></div>
</div>
<ol class="simple">
<li><p>Compilando y ejecutando el siguiente programa de <em>CUDA C</em>:</p></li>
</ol>
<p><strong>Programa de hello world:</strong> <code class="docutils literal notranslate"><span class="pre">hello_world.cu</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#include&lt;stdio.h&gt;</span>
<span class="n">__global__</span> <span class="n">void</span> <span class="n">func</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Hello world del bloque </span><span class="si">%d</span><span class="s2"> del thread </span><span class="si">%d</span><span class="s2">!</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">);</span>
<span class="p">}</span>
<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="n">func</span><span class="o">&lt;&lt;&lt;</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span> <span class="o">//</span><span class="mi">2</span> <span class="n">bloques</span> <span class="n">de</span> <span class="mi">3</span> <span class="n">threads</span> <span class="n">cada</span> <span class="n">uno</span>
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Hola del cpu thread</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Compilación: <code class="docutils literal notranslate"><span class="pre">$nvcc</span> <span class="pre">hello_world.cu</span> <span class="pre">-o</span> <span class="pre">hello_world.out</span></code></p>
<p>Ejecución: <code class="docutils literal notranslate"><span class="pre">$./hello_world.out</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Hello world del bloque 1 del thread 0!
Hello world del bloque 1 del thread 1!
Hello world del bloque 1 del thread 2!
Hello world del bloque 0 del thread 0!
Hello world del bloque 0 del thread 1!
Hello world del bloque 0 del thread 2!
Hola del cpu thread
</pre></div>
</div>
<ol class="simple">
<li><p>Haciendo un query a la GPU para ver qué características tiene (lo siguiente es posible ejecutar sólo si se instaló el <em>CUDA toolkit</em>):</p></li>
</ol>
<p>/usr/local/cuda/samples/1_Utilities/deviceQuery/deviceQuery</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">cuda</span><span class="o">/</span><span class="n">samples</span><span class="o">/</span><span class="mi">1</span><span class="n">_Utilities</span><span class="o">/</span><span class="n">deviceQuery</span><span class="o">/</span><span class="n">deviceQuery</span> <span class="n">Starting</span><span class="o">...</span>

 <span class="n">CUDA</span> <span class="n">Device</span> <span class="n">Query</span> <span class="p">(</span><span class="n">Runtime</span> <span class="n">API</span><span class="p">)</span> <span class="n">version</span> <span class="p">(</span><span class="n">CUDART</span> <span class="n">static</span> <span class="n">linking</span><span class="p">)</span>


<span class="n">Detected</span> <span class="mi">1</span> <span class="n">CUDA</span> <span class="n">Capable</span> <span class="n">device</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>

<span class="n">Device</span> <span class="mi">0</span><span class="p">:</span> <span class="s2">&quot;Tesla K80&quot;</span>
  <span class="n">CUDA</span> <span class="n">Driver</span> <span class="n">Version</span> <span class="o">/</span> <span class="n">Runtime</span> <span class="n">Version</span>          <span class="mf">9.1</span> <span class="o">/</span> <span class="mf">9.1</span>
  <span class="n">CUDA</span> <span class="n">Capability</span> <span class="n">Major</span><span class="o">/</span><span class="n">Minor</span> <span class="n">version</span> <span class="n">number</span><span class="p">:</span>    <span class="mf">3.7</span>
  <span class="n">Total</span> <span class="n">amount</span> <span class="n">of</span> <span class="k">global</span> <span class="n">memory</span><span class="p">:</span>                 <span class="mi">11441</span> <span class="n">MBytes</span> <span class="p">(</span><span class="mi">11996954624</span> <span class="nb">bytes</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">13</span><span class="p">)</span> <span class="n">Multiprocessors</span><span class="p">,</span> <span class="p">(</span><span class="mi">192</span><span class="p">)</span> <span class="n">CUDA</span> <span class="n">Cores</span><span class="o">/</span><span class="n">MP</span><span class="p">:</span>     <span class="mi">2496</span> <span class="n">CUDA</span> <span class="n">Cores</span>
  <span class="n">GPU</span> <span class="n">Max</span> <span class="n">Clock</span> <span class="n">rate</span><span class="p">:</span>                            <span class="mi">824</span> <span class="n">MHz</span> <span class="p">(</span><span class="mf">0.82</span> <span class="n">GHz</span><span class="p">)</span>
  <span class="n">Memory</span> <span class="n">Clock</span> <span class="n">rate</span><span class="p">:</span>                             <span class="mi">2505</span> <span class="n">Mhz</span>
  <span class="n">Memory</span> <span class="n">Bus</span> <span class="n">Width</span><span class="p">:</span>                              <span class="mi">384</span><span class="o">-</span><span class="n">bit</span>
  <span class="n">L2</span> <span class="n">Cache</span> <span class="n">Size</span><span class="p">:</span>                                 <span class="mi">1572864</span> <span class="nb">bytes</span>
  <span class="n">Maximum</span> <span class="n">Texture</span> <span class="n">Dimension</span> <span class="n">Size</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">z</span><span class="p">)</span>         <span class="mi">1</span><span class="n">D</span><span class="o">=</span><span class="p">(</span><span class="mi">65536</span><span class="p">),</span> <span class="mi">2</span><span class="n">D</span><span class="o">=</span><span class="p">(</span><span class="mi">65536</span><span class="p">,</span> <span class="mi">65536</span><span class="p">),</span> <span class="mi">3</span><span class="n">D</span><span class="o">=</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
  <span class="n">Maximum</span> <span class="n">Layered</span> <span class="mi">1</span><span class="n">D</span> <span class="n">Texture</span> <span class="n">Size</span><span class="p">,</span> <span class="p">(</span><span class="n">num</span><span class="p">)</span> <span class="n">layers</span>  <span class="mi">1</span><span class="n">D</span><span class="o">=</span><span class="p">(</span><span class="mi">16384</span><span class="p">),</span> <span class="mi">2048</span> <span class="n">layers</span>
  <span class="n">Maximum</span> <span class="n">Layered</span> <span class="mi">2</span><span class="n">D</span> <span class="n">Texture</span> <span class="n">Size</span><span class="p">,</span> <span class="p">(</span><span class="n">num</span><span class="p">)</span> <span class="n">layers</span>  <span class="mi">2</span><span class="n">D</span><span class="o">=</span><span class="p">(</span><span class="mi">16384</span><span class="p">,</span> <span class="mi">16384</span><span class="p">),</span> <span class="mi">2048</span> <span class="n">layers</span>
  <span class="n">Total</span> <span class="n">amount</span> <span class="n">of</span> <span class="n">constant</span> <span class="n">memory</span><span class="p">:</span>               <span class="mi">65536</span> <span class="nb">bytes</span>
  <span class="n">Total</span> <span class="n">amount</span> <span class="n">of</span> <span class="n">shared</span> <span class="n">memory</span> <span class="n">per</span> <span class="n">block</span><span class="p">:</span>       <span class="mi">49152</span> <span class="nb">bytes</span>
  <span class="n">Total</span> <span class="n">number</span> <span class="n">of</span> <span class="n">registers</span> <span class="n">available</span> <span class="n">per</span> <span class="n">block</span><span class="p">:</span> <span class="mi">65536</span>
  <span class="n">Warp</span> <span class="n">size</span><span class="p">:</span>                                     <span class="mi">32</span>
  <span class="n">Maximum</span> <span class="n">number</span> <span class="n">of</span> <span class="n">threads</span> <span class="n">per</span> <span class="n">multiprocessor</span><span class="p">:</span>  <span class="mi">2048</span>
  <span class="n">Maximum</span> <span class="n">number</span> <span class="n">of</span> <span class="n">threads</span> <span class="n">per</span> <span class="n">block</span><span class="p">:</span>           <span class="mi">1024</span>
  <span class="n">Max</span> <span class="n">dimension</span> <span class="n">size</span> <span class="n">of</span> <span class="n">a</span> <span class="n">thread</span> <span class="n">block</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">z</span><span class="p">):</span> <span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
  <span class="n">Max</span> <span class="n">dimension</span> <span class="n">size</span> <span class="n">of</span> <span class="n">a</span> <span class="n">grid</span> <span class="n">size</span>    <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">z</span><span class="p">):</span> <span class="p">(</span><span class="mi">2147483647</span><span class="p">,</span> <span class="mi">65535</span><span class="p">,</span> <span class="mi">65535</span><span class="p">)</span>
  <span class="n">Maximum</span> <span class="n">memory</span> <span class="n">pitch</span><span class="p">:</span>                          <span class="mi">2147483647</span> <span class="nb">bytes</span>
  <span class="n">Texture</span> <span class="n">alignment</span><span class="p">:</span>                             <span class="mi">512</span> <span class="nb">bytes</span>
  <span class="n">Concurrent</span> <span class="n">copy</span> <span class="ow">and</span> <span class="n">kernel</span> <span class="n">execution</span><span class="p">:</span>          <span class="n">Yes</span> <span class="k">with</span> <span class="mi">2</span> <span class="n">copy</span> <span class="n">engine</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
  <span class="n">Run</span> <span class="n">time</span> <span class="n">limit</span> <span class="n">on</span> <span class="n">kernels</span><span class="p">:</span>                     <span class="n">No</span>
  <span class="n">Integrated</span> <span class="n">GPU</span> <span class="n">sharing</span> <span class="n">Host</span> <span class="n">Memory</span><span class="p">:</span>            <span class="n">No</span>
  <span class="n">Support</span> <span class="n">host</span> <span class="n">page</span><span class="o">-</span><span class="n">locked</span> <span class="n">memory</span> <span class="n">mapping</span><span class="p">:</span>       <span class="n">Yes</span>
  <span class="n">Alignment</span> <span class="n">requirement</span> <span class="k">for</span> <span class="n">Surfaces</span><span class="p">:</span>            <span class="n">Yes</span>
  <span class="n">Device</span> <span class="n">has</span> <span class="n">ECC</span> <span class="n">support</span><span class="p">:</span>                        <span class="n">Enabled</span>
  <span class="n">Device</span> <span class="n">supports</span> <span class="n">Unified</span> <span class="n">Addressing</span> <span class="p">(</span><span class="n">UVA</span><span class="p">):</span>      <span class="n">Yes</span>
  <span class="n">Supports</span> <span class="n">Cooperative</span> <span class="n">Kernel</span> <span class="n">Launch</span><span class="p">:</span>            <span class="n">No</span>
  <span class="n">Supports</span> <span class="n">MultiDevice</span> <span class="n">Co</span><span class="o">-</span><span class="n">op</span> <span class="n">Kernel</span> <span class="n">Launch</span><span class="p">:</span>      <span class="n">No</span>
  <span class="n">Device</span> <span class="n">PCI</span> <span class="n">Domain</span> <span class="n">ID</span> <span class="o">/</span> <span class="n">Bus</span> <span class="n">ID</span> <span class="o">/</span> <span class="n">location</span> <span class="n">ID</span><span class="p">:</span>   <span class="mi">0</span> <span class="o">/</span> <span class="mi">0</span> <span class="o">/</span> <span class="mi">30</span>
  <span class="n">Compute</span> <span class="n">Mode</span><span class="p">:</span>
     <span class="o">&lt;</span> <span class="n">Default</span> <span class="p">(</span><span class="n">multiple</span> <span class="n">host</span> <span class="n">threads</span> <span class="n">can</span> <span class="n">use</span> <span class="p">::</span><span class="n">cudaSetDevice</span><span class="p">()</span> <span class="k">with</span> <span class="n">device</span> <span class="n">simultaneously</span><span class="p">)</span> <span class="o">&gt;</span>

<span class="n">deviceQuery</span><span class="p">,</span> <span class="n">CUDA</span> <span class="n">Driver</span> <span class="o">=</span> <span class="n">CUDART</span><span class="p">,</span> <span class="n">CUDA</span> <span class="n">Driver</span> <span class="n">Version</span> <span class="o">=</span> <span class="mf">9.1</span><span class="p">,</span> <span class="n">CUDA</span> <span class="n">Runtime</span> <span class="n">Version</span> <span class="o">=</span> <span class="mf">9.1</span><span class="p">,</span> <span class="n">NumDevs</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">Result</span> <span class="o">=</span> <span class="n">PASS</span>
</pre></div>
</div>
</div>
<div class="section" id="por-que-usar-cuda-y-cuda-c-o-mas-general-computo-en-la-gpu">
<h2>¿Por qué usar CUDA y <em>CUDA-C</em> o más general cómputo en la GPU?<a class="headerlink" href="#por-que-usar-cuda-y-cuda-c-o-mas-general-computo-en-la-gpu" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>NVIDIA como se mencionó al inicio de la nota fue de las primeras compañías en utilizar la GPU para tareas no relacionadas con el área de gráficos y ha colaborado en el avance del conocimiento de las GPU’s y desarrollo de algoritmos y tarjetas gráficas. Otra compañía es <a class="reference external" href="https://en.wikipedia.org/wiki/Khronos_Group">Khronos_Group</a> por ejemplo, quien actualmente desarrolla <a class="reference external" href="https://www.khronos.org/opencl/">OpenCl</a>.</p></li>
</ul>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p><em>Deep learning</em> se ha utilizado para resolver problemas en <em>machine learning</em> típicos. Ejemplos de esto son la clasificación de imágenes, de sonidos o análisis de textos, ver por ejemplo <a class="reference external" href="https://medium.com/&#64;michael.fire/practical-text-analysis-using-deep-learning-5fb0744efdf9">Practical text analysis using deep learning</a>.</p>
</div>
<ul class="simple">
<li><p>El cómputo en la GPU constituye hoy en día (2020) una alternativa fuerte a la implementación de modelos de machine learning ampliamente utilizada por la comunidad científica. En el terreno de cómputo matricial y <em>deep learning</em> se encuentran <a class="reference external" href="https://github.com/tensorflow">tensorflow</a>, <a class="reference external" href="https://github.com/BVLC/caffe">caffe</a>, <a class="reference external" href="https://github.com/Theano/Theano">Theano</a> (aunque ya no es soportado pero está retomado en <a class="reference external" href="https://github.com/pymc-devs/aesara">pymc-devs/aesara</a>), <a class="reference external" href="https://github.com/pytorch/pytorch">Pytorch</a> y <a class="reference external" href="https://github.com/keras-team/keras">keras</a> como ejemplos de lo anterior.</p></li>
<li><p>Sí hay publicaciones científicas para la implementación de <em>deep learning</em> en las CPU’s, ver por ejemplo el paper reciente de <a class="reference external" href="https://www.cs.rice.edu/~as143/Papers/SLIDE_MLSys.pdf">SLIDE</a>, <a class="reference external" href="https://github.com/keroro824/HashingDeepLearning">HashingDeepLearning</a> y las entradas <a class="reference external" href="https://www.engadget.com/2020/03/03/rice-university-slide-cpu-gpu-machine-learning/">An algorithm could make CPUs a cheap way to train AI</a> y <a class="reference external" href="https://www.sciencedaily.com/releases/2020/03/200305135041.htm">Deep learning rethink overcomes major obstacle in AI industry</a> . Sin embargo, esta área se encuentra en activa investigación por lo que se han adoptado el uso de implementaciones del <em>deep learning</em> utilizando GPU’s.</p></li>
</ul>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>El paper plantea una discusión a realizar con la frase <em>…change in the state-of-the-art algorithms can render specialized hardware less effective in the future</em>. Ver por ejemplo <a class="reference external" href="https://developer.nvidia.com/tensor-cores">Tensor Cores</a>, <a class="reference external" href="https://www.nvidia.com/en-us/data-center/tensorcore/">NVIDIA TENSOR CORES, The Next Generation of Deep Learning</a>, <a class="reference external" href="https://www.ibm.com/thought-leadership/summit-supercomputer/">The most powerful computers on the planet: SUMMIT</a> como ejemplos de hardware especializado en aprendizaje automático con Tensorflow.</p>
<p><em>Summit powered by 9,126 IBM Power9 CPUs and over 27,000 NVIDIA V100 Tensor Core GPUS, is able to do 200 quadrillion calculations per second…</em> <a class="reference external" href="https://www.ibm.com/blogs/nordic-msp/ibm-supercomputer-summit-attacks-coronavirus/">IBM Supercomputer Summit Attacks Coronavirus…</a>.</p>
</div>
</div>
<div class="section" id="cuda-c">
<h2><a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/">CUDA-C</a><a class="headerlink" href="#cuda-c" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="cupy">
<h2><a class="reference external" href="https://github.com/cupy/cupy">CuPy</a><a class="headerlink" href="#cupy" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="gputools">
<h2><a class="reference external" href="https://github.com/nullsatz/gputools">Gputools</a><a class="headerlink" href="#gputools" title="Permalink to this headline">¶</a></h2>
<p>Ver <a class="reference external" href="https://rdrr.io/cran/gputools/">gputools: cran</a></p>
</div>
<div class="section" id="referencias-de-interes">
<h2>Referencias de interés<a class="headerlink" href="#referencias-de-interes" title="Permalink to this headline">¶</a></h2>
<p>Para más sobre <em>Unified Memory</em> revisar:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://devblogs.nvidia.com/even-easier-introduction-cuda/">Even easier introduction to cuda</a></p></li>
<li><p><a class="reference external" href="https://devblogs.nvidia.com/unified-memory-cuda-beginners/">Unified memory cuda beginners</a></p></li>
</ul>
<p>Es importante el manejo de errores por ejemplo en el alojamiento de memoria en la GPU. En este caso es útil revisar:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://devblogs.nvidia.com/how-query-device-properties-and-handle-errors-cuda-cc/">How to Query Device Properties and Handle Errors in CUDA C/C++</a></p></li>
</ul>
<p>En las siguientes preguntas encontramos a personas desarrolladoras de CUDA que las resuelven y resultan muy útiles para continuar con el aprendizaje de CUDA C. Por ejemplo:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://stackoverflow.com/questions/51526082/cuda-parallel-reduction-over-one-axis">Parallel reduction over one axis</a></p></li>
</ul>
<p>Otros sistemas de software para el <a class="reference external" href="https://en.wikipedia.org/wiki/Heterogeneous_computing">Heterogeneous computing</a> son:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/OpenCL">OpenCl</a>. Ver <a class="reference external" href="https://developer.nvidia.com/opencl">NVIDIA OpenCL SDK Code Samples</a> para ejemplos con NVIDIA GPU’s.</p></li>
<li><p><a class="reference external" href="https://github.com/Rth-org/Rth">Rth-org/Rth</a> y más reciente <a class="reference external" href="https://github.com/matloff/Rth">matloff/Rth</a>. Ver también <a class="reference external" href="https://rdrr.io/github/matloff/Rth/f/README.md">rdrr.io matloff/Rth</a>.</p></li>
</ul>
<p>Es posible escribir <a class="reference external" href="https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.3.CUDA_C.ipynb">kernels</a> con CuPy. Ver por ejemplo: <a class="reference external" href="https://docs-cupy.chainer.org/en/stable/tutorial/kernel.html">User-Defined Kernels</a>.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs-cupy.chainer.org/en/stable/index.html">CuPy – NumPy-like API accelerated with CUDA</a></p></li>
<li><p><a class="reference external" href="https://github.com/cupy/cupy">CuPy : NumPy-like API accelerated with CUDA github</a></p></li>
</ul>
<p>Otro paquete para uso de Python+GPU para cómputo matricial es:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/inducer/pycuda/">PyCUDA</a> y ver <a class="reference external" href="https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/tree/master/Python/PyCUDA">PyCUDA en el repo de la clase</a> para más información.</p></li>
</ul>
<p>Un paquete para uso de pandas+GPU:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/rapidsai">Rapids</a>, <a class="reference external" href="https://github.com/rapidsai/cudf">cudf</a></p></li>
</ul>
<p>Ver <a class="reference external" href="https://docs-cupy.chainer.org/en/stable/install.html#optional-libraries">optional-libraries</a> para librerías que pueden ser utilizadas con CuPy.</p>
<div class="tip admonition">
<p class="admonition-title">Ejercicios</p>
<p>1.Resuelve los ejercicios y preguntas de la nota.</p>
</div>
<p><strong>Preguntas de comprehensión:</strong></p>
<p>1)¿Qué factores han determinado un mejor <em>performance</em> de una GPU vs una CPU? (contrasta los diseños de una CPU vs una GPU).</p>
<p>2)¿Dentro de qué modelo de arquitectura de máquinas se ubica a la GPU dentro de la taxonomía de Flynn? (tip: tal modelo se le puede comparar con el modelo <strong>Single Program Multiple Data (SPMD)</strong>)</p>
<p>3)¿Qué significan las siglas CUDA y detalla qué es CUDA?.</p>
<p>4)¿Qué es y en qué consiste CUDA C?</p>
<p>5)¿Qué es un <em>kernel</em>?</p>
<p>6)¿Qué pieza de CUDA se encarga de asignar los bloques de <em>cuda-threads</em> a las SM’s?</p>
<p>7)¿Qué características (recursos compartidos, dimensiones, forma de agendar la ejecución en <em>threads</em>) tienen los bloques que se asignan a una SM al lanzarse y ejecutarse un <em>kernel</em>?</p>
<p>8)¿Qué es un <em>warp</em>?</p>
<p>9)Menciona los tipos de memorias que existen en las GPU’s.</p>
<p>10)Supón que tienes una tarjeta GT200 cuyas características son:</p>
<ul class="simple">
<li><p>Máximo número de <em>threads</em> que soporta una SM en un mismo instante en el tiempo: 1024</p></li>
<li><p>Máximo número de <em>threads</em> en un bloque: 512</p></li>
<li><p>Máximo número de bloques por SM: 8</p></li>
<li><p>Número de SM’s que tiene esta GPU: 30</p></li>
</ul>
<p>Responde:</p>
<p>a)¿Cuál es la máxima cantidad de <em>threads</em> que puede soportar esta GPU en un mismo instante en el tiempo?</p>
<p>b)¿Cuál es la máxima cantidad de <em>warps</em> por SM que puede soportar esta GPU en un mismo instante en el tiempo?</p>
<p>c)¿Cuáles configuraciones de bloques y <em>threads</em> siguientes aprovechan la máxima cantidad de <em>warps</em> en una SM de esta GPU para un mismo instante en el tiempo?</p>
<p>1.Una configuración del tipo: bloques de 64 <em>threads</em> y 16 bloques.</p>
<p>2.Una configuración del tipo: bloques de 1024 <em>threads</em> y 1 bloque.</p>
<p>3.Una configuración del tipo: bloques de 256 <em>threads</em> y 4 bloques.</p>
<p>4.Una configuración del tipo: bloques de 512 <em>threads</em> y 8 bloques.</p>
<p>*Debes considerar las restricciones/características de la GPU dadas para responder pues algunas configuraciones infringen las mismas. No estamos considerando <em>registers</em> o <em>shared memory</em>.</p>
<p><strong>Referencias:</strong></p>
<ol class="simple">
<li><p>N. Matloff, Parallel Computing for Data Science. With Examples in R, C++ and CUDA, 2014.</p></li>
<li><p>D. B. Kirk, W. W. Hwu, Programming Massively Parallel Processors: A Hands-on Approach, Morgan Kaufmann, 2010.</p></li>
<li><p>NVIDIA,CUDA Programming Guide, NVIDIA Corporation, 2007.</p></li>
<li><p>B. W. Kernighan, D. M. Ritchie, The C Programming Language, Prentice Hall Software Series, 1988</p></li>
<li><p><a class="reference external" href="https://github.com/palmoreck/programming-languages/tree/master/C/extensiones_a_C/CUDA">C/extensiones_a_C/CUDA/</a></p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "palmoreck/dockerfiles-for-binder",
            ref: "jupyterlab_optimizacion_2",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./V.optimizacion_de_codigo/5.5"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../5.4/Computo_en_paralelo_usando_CPUS_en_SMC.html" title="previous page">5.4 Cómputo en paralelo usando CPUs en un sistema de memoria compartida (SMC)</a>
    <a class='right-next' id="next-link" href="../../VI.algoritmos_optimizacion_convexa/6.1/Problemas_UCO.html" title="next page">6.1 Problemas tipo <em>Unconstrained Convex Optimization</em> (UCO)</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Erick Palacios Moreno<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>