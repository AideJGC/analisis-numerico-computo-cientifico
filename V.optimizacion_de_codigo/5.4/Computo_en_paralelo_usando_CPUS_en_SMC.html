
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>5.4 Cómputo en paralelo usando CPUs en un sistema de memoria compartida (SMC)</title>
    
  <link rel="stylesheet" href="../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="5.5 Cómputo en paralelo usando GPUs en un sistema de memoria compartida (SMC)" href="../5.5/Computo_en_paralelo_usando_GPUS_en_SMC.html" />
    <link rel="prev" title="5.3 Compilación a C" href="../5.3/Compilacion_a_C.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../README.html">
   Optimización
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  I. Cómputo científico
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.1/Analisis_numerico_y_computo_cientifico.html">
   1.1 Análisis numérico y cómputo científico
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.2/Sistema_de_punto_flotante.html">
   1.2 Sistema de punto flotante
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.3/Normas_vectoriales_y_matriciales.html">
   1.3 Normas vectoriales y matriciales
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.4/Condicion_de_un_problema_y_estabilidad_de_un_algoritmo.html">
   1.4 Condición de un problema y estabilidad de un algoritmo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.5/Definicion_de_funcion_continuidad_derivada.html">
   1.5 Definición de función, continuidad y derivada
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.6/Polinomios_de_Taylor_y_diferenciacion_numerica.html">
   1.6 Polinomios de Taylor y diferenciación numérica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.7/Integracion_numerica.html">
   1.7 Integración Numérica
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  II. Cómputo matricial
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.1/Operaciones_y_transformaciones_basicas_del_Algebra_Lineal_Numerica.html">
   2.1 Operaciones y transformaciones básicas del Álgebra Lineal Numérica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.2/Eigenvalores_y_eigenvectores.html">
   2.2 Eigenvalores y eigenvectores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.3/Algoritmos_y_aplicaciones_de_eigenvalores_eigenvectores_de_una_matriz.html">
   2.3 Algoritmos y aplicaciones de eigenvalores y eigenvectores de una matriz
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.4/Valores_vectores_singulares_y_algoritmos_para_calcular_la_SVD.html">
   2.4 Valores, vectores singulares y algoritmos para calcular la SVD
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  III. Optimización convexa y ecuaciones no lineales
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../III.optimizacion_convexa/3.1/Definicion_de_problema_optimizacion_conjuntos_y_funciones_convexas.html">
   3.1 Definición de problemas de optimización, conjuntos y funciones convexas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../III.optimizacion_convexa/3.2/Algoritmos_de_descenso_y_busqueda_de_linea_en_uco.html">
   3.2 Algoritmos de descenso y búsqueda de línea en
   <em>
    Unconstrained Convex Optimization
   </em>
   (UCO)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../III.optimizacion_convexa/3.3/Ejemplos_problemas_UCO_e_intro_CIEO_y_PI.html">
   3.3 Ejemplos de problemas UCO, introducción a
   <em>
    Constrained Inequality and Equality Optimization
   </em>
   (CIEO) y puntos interiores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../III.optimizacion_convexa/3.4/Ecuaciones_no_lineales.html">
   3.4 Ecuaciones no lineales
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  IV. Optimización en redes y programación lineal
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../IV.optimizacion_en_redes_y_prog_lineal/4.1/Definiciones_generales_de_flujo_en_redes.html">
   4.1 Definiciones generales de flujo en redes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../IV.optimizacion_en_redes_y_prog_lineal/4.2/Programacion_lineal_y_metodo_simplex.html">
   4.2 Programación lineal (PL) y método símplex
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../IV.optimizacion_en_redes_y_prog_lineal/4.3/Ejemplo_metodo_simplex_de_redes.html">
   4.3 Ejemplo del método símplex de redes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../IV.optimizacion_en_redes_y_prog_lineal/4.4/Dualidad_lema_de_Farkas_condiciones_KKT_de_optimalidad.html">
   4.4 Dualidad, lema de Farkas y condiciones de Karush-Kuhn-Tucker (KKT) de optimalidad
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../IV.optimizacion_en_redes_y_prog_lineal/4.5/Metodo_primal_dual_de_BL.html">
   4.5 Método primal-dual de barrera logarítmica (BL)
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  V. Optimización de código
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../5.1/introduccion_optimizacion_de_codigo.html">
   5.1 Introducción a optimización de código
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.2/Herramientas_de_lenguajes_y_del_SO_para_perfilamiento_e_implementaciones_de_BLAS.html">
   5.2 Herramientas de lenguajes de programación y del sistema operativo para perfilamiento e implementaciones de BLAS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.3/Compilacion_a_C.html">
   5.3 Compilación a C
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   5.4 Cómputo en paralelo usando CPUs en un sistema de memoria compartida (SMC)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.5/Computo_en_paralelo_usando_GPUS_en_SMC.html">
   5.5 Cómputo en paralelo usando GPUs en un sistema de memoria compartida (SMC)
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  VI. Algoritmos de optimización convexa
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../VI.algoritmos_optimizacion_convexa/6.1/Problemas_UCO.html">
   6.1 Problemas tipo
   <em>
    Unconstrained Convex Optimization
   </em>
   (UCO)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../VI.algoritmos_optimizacion_convexa/6.2/Problemas_CECO.html">
   6.2 Problemas tipo
   <em>
    Constrained Equality Convex Optimization
   </em>
   (CECO)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../VI.algoritmos_optimizacion_convexa/6.3/Problemas_CIECO.html">
   6.3 Problemas tipo
   <em>
    Constrained Equality and Inequality Convex Optimization
   </em>
   (CIECO)
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/V.optimizacion_de_codigo/5.4/Computo_en_paralelo_usando_CPUS_en_SMC.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/palmoreck/dockerfiles-for-binder/jupyterlab_optimizacion_2?urlpath=lab/tree/analisis-numerico-computo-cientifico/libro_optimizacion/temas/V.optimizacion_de_codigo/5.4/Computo_en_paralelo_usando_CPUS_en_SMC.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sistemas-de-memoria-compartida-smc">
   Sistemas de memoria compartida (SMC)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#openmp">
   OpenMP
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#directiva-parallel">
     Directiva parallel
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo-hello-world">
     Ejemplo:
     <em>
      Hello world
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clause-num-threads">
     <em>
      Clause
     </em>
     <code class="docutils literal notranslate">
      <span class="pre">
       num_threads
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Ejemplo:
     <em>
      Hello world
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reduction-clause">
     <em>
      Reduction clause
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo-de-uso-de-nombres-de-variables-al-definir-variables-privadas-y-compartidas-en-reduction-clause">
     Ejemplo de uso de nombres de variables al definir variables privadas y compartidas en
     <em>
      reduction clause
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo-regla-compuesta-del-rectangulo">
     Ejemplo regla compuesta del rectángulo
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multiprocessing">
   Multiprocessing
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dask">
   Dask
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parallel">
   Parallel
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#referencias-de-interes">
   Referencias de interés
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="computo-en-paralelo-usando-cpus-en-un-sistema-de-memoria-compartida-smc">
<span id="compparalelocpussmc"></span><h1>5.4 Cómputo en paralelo usando CPUs en un sistema de memoria compartida (SMC)<a class="headerlink" href="#computo-en-paralelo-usando-cpus-en-un-sistema-de-memoria-compartida-smc" title="Permalink to this headline">¶</a></h1>
<div class="admonition-notas-para-contenedor-de-docker admonition">
<p class="admonition-title">Notas para contenedor de docker:</p>
<p>Comando de docker para ejecución de la nota de forma local:</p>
<p>nota: cambiar <code class="docutils literal notranslate"><span class="pre">&lt;ruta</span> <span class="pre">a</span> <span class="pre">mi</span> <span class="pre">directorio&gt;</span></code> por la ruta de directorio que se desea mapear a <code class="docutils literal notranslate"><span class="pre">/datos</span></code> dentro del contenedor de docker.</p>
<p><code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">run</span> <span class="pre">--rm</span> <span class="pre">-v</span> <span class="pre">&lt;ruta</span> <span class="pre">a</span> <span class="pre">mi</span> <span class="pre">directorio&gt;:/datos</span> <span class="pre">--name</span> <span class="pre">jupyterlab_optimizacion_2</span> <span class="pre">-p</span> <span class="pre">8888:8888</span> <span class="pre">-p</span> <span class="pre">8787:8787</span> <span class="pre">-d</span> <span class="pre">palmoreck/jupyterlab_optimizacion_2:3.0.0</span></code></p>
<p>password para jupyterlab: <code class="docutils literal notranslate"><span class="pre">qwerty</span></code></p>
<p>Detener el contenedor de docker:</p>
<p><code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">stop</span> <span class="pre">jupyterlab_optimizacion_2</span></code></p>
<p>Documentación de la imagen de docker <code class="docutils literal notranslate"><span class="pre">palmoreck/jupyterlab_optimizacion_2:3.0.0</span></code> en <a class="reference external" href="https://github.com/palmoreck/dockerfiles/tree/master/jupyterlab/optimizacion_2">liga</a>.</p>
</div>
<hr class="docutils" />
<p>Nota generada a partir de <a class="reference external" href="https://www.dropbox.com/s/oauifmx3e19ofyq/2.3.Sistemas_de_memoria_compartida_Pthreads.pdf?dl=0">liga1</a>, <a class="reference external" href="https://www.dropbox.com/s/vcxbrqkk6x946d7/2.4.Sistemas_de_memoria_compartida_openMP.pdf?dl=0">liga2</a>, <a class="reference external" href="https://www.dropbox.com/s/v4ub0p3ndf7w1p0/2.2.Sistemas_de_memoria_distribuida_MPI.pdf?dl=0">liga3</a></p>
<div class="tip admonition">
<p class="admonition-title">Al final de esta nota el y la lectora:</p>
<ul class="simple">
<li></li>
</ul>
</div>
<p>Se presentan códigos y sus ejecuciones en una máquina <code class="docutils literal notranslate"><span class="pre">&lt;falta</span> <span class="pre">colocar&gt;</span></code> de la nube de <a class="reference external" href="https://aws.amazon.com/">AWS</a>. Se utilizó la AMI <code class="docutils literal notranslate"><span class="pre">opt2-aws-educate-openblas-04-04-2021</span></code> de la región <code class="docutils literal notranslate"><span class="pre">us-east-1</span></code> (Virginia) para reproducibilidad de resultados. Tal AMI se construyó a partir de una AMI <code class="docutils literal notranslate"><span class="pre">ubuntu</span> <span class="pre">20.04</span> <span class="pre">-</span> <span class="pre">ami-042e8287309f5df03</span></code> con el <a class="reference external" href="https://github.com/palmoreck/scripts_for_useful_tools_installations/blob/main/AWS/ubuntu_20.04/optimizacion_2/script_profiling_and_BLAS.sh">script_profiling_and_BLAS.sh</a></p>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Si se utiliza la <em>AMI</em> <code class="docutils literal notranslate"><span class="pre">opt2-aws-educate-openblas-04-04-2021</span></code> colocar en <code class="docutils literal notranslate"><span class="pre">User</span> <span class="pre">data</span></code> el siguiente <em>script</em>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">##variables:</span>
<span class="nv">region</span><span class="o">=</span>us-east-1 <span class="c1">#make sure instance is in Virginia</span>
<span class="nv">name_instance</span><span class="o">=</span>OpenBLAS
<span class="nv">USER</span><span class="o">=</span>ubuntu
<span class="c1">##System update</span>
apt-get update -yq
<span class="c1">##Tag instance</span>
<span class="nv">INSTANCE_ID</span><span class="o">=</span><span class="k">$(</span>curl -s http://instance-data/latest/meta-data/instance-id<span class="k">)</span>
<span class="nv">PUBLIC_IP</span><span class="o">=</span><span class="k">$(</span>curl -s http://instance-data/latest/meta-data/public-ipv4<span class="k">)</span>
sudo -H -u <span class="nv">$USER</span> bash -c <span class="s2">&quot;/home/</span><span class="nv">$USER</span><span class="s2">/.local/bin/aws ec2 create-tags --resources </span><span class="nv">$INSTANCE_ID</span><span class="s2"> --tag Key=Name,Value=</span><span class="nv">$name_instance</span><span class="s2">-</span><span class="nv">$PUBLIC_IP</span><span class="s2"> --region=</span><span class="nv">$region</span><span class="s2">&quot;</span>
sudo -H -u <span class="nv">$USER</span> bash -c <span class="s2">&quot;cd / &amp;&amp; /home/</span><span class="nv">$USER</span><span class="s2">/.local/bin/jupyter lab --ip=0.0.0.0 --no-browser --config=/home/</span><span class="nv">$USER</span><span class="s2">/.jupyter/jupyter_notebook_config.py &amp;&quot;</span>
</pre></div>
</div>
</div>
<p>La máquina <code class="docutils literal notranslate"><span class="pre">&lt;falta</span> <span class="pre">colocar&gt;</span></code> tiene las siguientes características:</p>
<p><strong>Falta ejecutar de acuerdo a la máquina elegida</strong></p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
lscpu
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Architecture:                    x86_64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian
Address sizes:                   46 bits physical, 48 bits virtual
CPU(s):                          64
On-line CPU(s) list:             0-63
Thread(s) per core:              2
Core(s) per socket:              16
Socket(s):                       2
NUMA node(s):                    2
Vendor ID:                       GenuineIntel
CPU family:                      6
Model:                           79
Model name:                      Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz
Stepping:                        1
CPU MHz:                         2290.913
CPU max MHz:                     3000.0000
CPU min MHz:                     1200.0000
BogoMIPS:                        4600.03
Hypervisor vendor:               Xen
Virtualization type:             full
L1d cache:                       1 MiB
L1i cache:                       1 MiB
L2 cache:                        8 MiB
L3 cache:                        90 MiB
NUMA node0 CPU(s):               0-15,32-47
NUMA node1 CPU(s):               16-31,48-63
Vulnerability Itlb multihit:     KVM: Vulnerable
Vulnerability L1tf:              Mitigation; PTE Inversion
Vulnerability Mds:               Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unknown
Vulnerability Meltdown:          Mitigation; PTI
Vulnerability Spec store bypass: Vulnerable
Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:        Mitigation; Full generic retpoline, STIBP disabled, RSB filling
Vulnerability Srbds:             Not affected
Vulnerability Tsx async abort:   Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unknown
Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq monitor est ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm cpuid_fault invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm xsaveopt ida
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
sudo lshw -C memory
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  *-firmware
       description: BIOS
       vendor: Xen
       physical id: 0
       version: 4.11.amazon
       date: 08/24/2006
       size: 96KiB
       capabilities: pci edd
  *-memory
       description: System Memory
       physical id: 1000
       size: 256GiB
       capabilities: ecc
       configuration: errordetection=multi-bit-ecc
     *-bank:0
          description: DIMM RAM
          physical id: 0
          slot: DIMM 0
          size: 16GiB
          width: 64 bits
     *-bank:1
          description: DIMM RAM
          physical id: 1
          slot: DIMM 1
          size: 16GiB
          width: 64 bits
     *-bank:2
          description: DIMM RAM
          physical id: 2
          slot: DIMM 2
          size: 16GiB
          width: 64 bits
     *-bank:3
          description: DIMM RAM
          physical id: 3
          slot: DIMM 3
          size: 16GiB
          width: 64 bits
     *-bank:4
          description: DIMM RAM
          physical id: 4
          slot: DIMM 4
          size: 16GiB
          width: 64 bits
     *-bank:5
          description: DIMM RAM
          physical id: 5
          slot: DIMM 5
          size: 16GiB
          width: 64 bits
     *-bank:6
          description: DIMM RAM
          physical id: 6
          slot: DIMM 6
          size: 16GiB
          width: 64 bits
     *-bank:7
          description: DIMM RAM
          physical id: 7
          slot: DIMM 7
          size: 16GiB
          width: 64 bits
     *-bank:8
          description: DIMM RAM
          physical id: 8
          slot: DIMM 8
          size: 16GiB
          width: 64 bits
     *-bank:9
          description: DIMM RAM
          physical id: 9
          slot: DIMM 9
          size: 16GiB
          width: 64 bits
     *-bank:10
          description: DIMM RAM
          physical id: a
          slot: DIMM 10
          size: 16GiB
          width: 64 bits
     *-bank:11
          description: DIMM RAM
          physical id: b
          slot: DIMM 11
          size: 16GiB
          width: 64 bits
     *-bank:12
          description: DIMM RAM
          physical id: c
          slot: DIMM 12
          size: 16GiB
          width: 64 bits
     *-bank:13
          description: DIMM RAM
          physical id: d
          slot: DIMM 13
          size: 16GiB
          width: 64 bits
     *-bank:14
          description: DIMM RAM
          physical id: e
          slot: DIMM 14
          size: 16GiB
          width: 64 bits
     *-bank:15
          description: DIMM RAM
          physical id: f
          slot: DIMM 15
          size: 16GiB
          width: 64 bits
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
uname -ar #r for kernel, a for all
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Linux ip-10-0-0-140 5.4.0-1038-aws #40-Ubuntu SMP Fri Feb 5 23:50:40 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>En la celda anterior se utilizó el comando de <em>magic</em> <code class="docutils literal notranslate"><span class="pre">%%bash</span></code>. Algunos comandos de <em>magic</em> los podemos utilizar también con <code class="docutils literal notranslate"><span class="pre">import</span></code>. Ver <a class="reference external" href="https://ipython.readthedocs.io/en/stable/interactive/magics.html">ipython-magics</a></p>
</div>
<div class="section" id="sistemas-de-memoria-compartida-smc">
<h2>Sistemas de memoria compartida (SMC)<a class="headerlink" href="#sistemas-de-memoria-compartida-smc" title="Permalink to this headline">¶</a></h2>
<p>Un SMC en general se ve como el siguiente dibujo:</p>
<img src="https://dl.dropboxusercontent.com/s/ao3if8tzwsvzfi7/shared_memory_sistems.png?dl=0" heigth="500" width="500"><p>El dibujo anterior es un SMC con acceso uniforme a la memoria (<a class="reference external" href="https://en.wikipedia.org/wiki/Uniform_memory_access">UMA</a>), esto es, cada proceso o <em>thread</em> creado en el procesador o <em>core</em> accede con las mismas velocidades a la memoria.</p>
<p>La <strong>comunicación</strong> en este tipo de sistemas depende si se utilizan procesos o <em>threads</em> ya que aunque los procesos generados por un proceso principal tienen acceso a la memoria, los cambios/actualizaciones que haga uno de ellos a una variable no lo llegan a ver los otros procesos. Esto es distinto con los <em>threads</em> dado que un cambio que realice un <em>thread</em> en una variable sí lo pueden ver los otros <em>threads</em>. Lo anterior se debe a las distintas direcciones de memoria que utilizan los procesos vs la misma dirección de memoria que utilizan los <em>threads</em>.</p>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Las variables que pueden ser accesadas por todos los <em>threads</em> en un SMC se les nombra <strong>variables compartidas</strong>.</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Hay paqueterías que crean subprocesos a partir de un proceso principal en lugar de <em>threads</em>. En este caso en lugar de un <em>fork</em> se realiza un <em>spawn</em>. Los subprocesos pueden ver cambios a variables hechos por otros.</p>
<p>Ver <a class="reference external" href="https://docs.python.org/3.9/library/multiprocessing.html#contexts-and-start-methods">Contexts and start methods</a> y <a class="reference external" href="https://stackoverflow.com/questions/46045956/whats-the-difference-between-threadpool-vs-pool-in-python-multiprocessing-modul">stackoverflow: difference between threadpool vs pool in python multiprocessing</a> para diferencias entre <em>fork</em> y <em>spawn</em>.</p>
</div>
<p>Trabajar sobre SMC tiene ventajas y desventajas. Una ventaja es facilidad de comunicación y una desventaja es la <strong>coordinación</strong> para ejecutar instrucciones. Por ejemplo, con variables compartidas se puede realizar la comunicación entre los <em>threads</em>, sin embargo, para el uso de tales variables por diferentes <em>threads</em> debemos crear candados, <em>locks</em>. Lo anterior surge pues si un <em>thread</em> con etiqueta <span class="math notranslate nohighlight">\(1\)</span> accede a una variable compartida, otro <em>thread</em> con etiqueta <span class="math notranslate nohighlight">\(2\)</span>, no podrá utilizarla hasta que el thread <span class="math notranslate nohighlight">\(1\)</span> finalice de usarla. Ver <a class="reference external" href="https://en.wikipedia.org/wiki/Thread_safety">Thread Safety</a> y <a class="reference external" href="https://en.wikipedia.org/wiki/Race_condition#Computing">Race Condition</a>.</p>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>En una <em>race condition</em> múltiples <em>threads</em> intentan acceder a un recurso compartido, al menos uno de los accesos resulta en una modificación al recurso y posteriormente los siguientes accesos pueden no ver la modificación. A la sección del código que causa la <em>race condition</em> se le nombra <em>critical section</em>. Las <em>critical sections</em> se ejecutan con código secuencial o con <em>locks</em> para evitar las <em>race conditions</em>.</p>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Para crear procesos o <em>threads</em> en los lenguajes de programación de <em>C, Python</em> o <em>R</em>, utilizamos las librerías, API’s o extensiones vía paquetes a tales lenguajes. Lo anterior se debe a que <em>C, Python</em> y <em>R</em> en sus implementaciones más utilizadas o estándar, fueron diseñados con el propósito de utilizarse sobre sistemas con un sólo procesador. En distintas implementaciones de los lenguajes hay soporte para SMC.</p></li>
<li><p>Ejemplos de máquinas con SMC son las laptops, los celulares, máquinas de escritorio con más de un <em>core</em>.</p></li>
<li><p>Otro tipo de SMC se puede representar con el siguiente dibujo:</p></li>
</ul>
<img src="https://dl.dropboxusercontent.com/s/dqwdqdxiecj91vy/shared_memory_systems_2.png?dl=0" heigth="500" width="500">
<p>en el que los procesos o <em>threads</em> pueden acceder a la memoria en una forma no uniforme <a class="reference external" href="https://en.wikipedia.org/wiki/Non-uniform_memory_access">(NUMA)</a>. Una de las diferencias que se tienen entre un NUMA y un UMA es la tasa de transferencia de datos para <em>cores</em> que están más cercanos a una memoria.</p>
<ul class="simple">
<li><p>Un sistema de memoria distribuida (SMD) tiene una conexión, por ejemplo vía una <em>network</em>, entre pares de <em>core-memoria</em> y en general se ve como el siguiente dibujo:</p></li>
</ul>
<img src="https://dl.dropboxusercontent.com/s/iky7af1m3dcj3e0/distributed_memory_systems.png?dl=0" heigth="600" width="600">
<p>La memoria en un SMD asociada al <em>core</em> sólo puede ser accesada por éste y es inaccesible a los demás <em>cores</em>, esto es, se tiene una memoria “privada”. Lo anterior contrasta con los SMC en los que todos los <em>cores</em> accesan a una memoria compartida. En un SMD el cómputo distribuido crea múltiples procesos a partir de un proceso principal. En un SMC el cómputo paralelo crea múltiples procesos o <em>threads</em>. Un ejemplo de un SMD es un clúster de máquinas. Cada máquina en el clúster puede ser un SMC y por tanto los procesos en cada máquina tienen la capacidad de crear procesos o <em>threads</em>. En este caso se tiene un sistema híbrido SMD y SMC. Un programa diseñado para ejecutarse en un SMD puede ejecutarse en un SMC pues se divide su memoria de forma lógica en espacios de memoria privados para los <em>threads</em>.</p>
</div>
</div>
<div class="section" id="openmp">
<h2><a class="reference external" href="http://www.openmp.org/">OpenMP</a><a class="headerlink" href="#openmp" title="Permalink to this headline">¶</a></h2>
<p>Es una extensión al lenguaje <em>C</em> y es una API para cómputo en paralelo en un sistema de memoria compartida, <em>aka, shared memory parallel programming</em> con CPUs. Lo anterior <em>OpenMP</em> lo posibilita con el <em>threading</em>: <em>fork</em> y <em>join</em> de <em>threads</em> a partir de un proceso principal.</p>
<img src="https://dl.dropboxusercontent.com/s/0vnjfdk7fo62m8h/threading.png?dl=0" heigth="400" width="400"><p>Ver <a class="reference internal" href="../5.1/introduccion_optimizacion_de_codigo.html#threadinghyper"><span class="std std-ref">Threading o Hyperthreading</span></a>.</p>
<ul class="simple">
<li><p>Las siglas <em>MP</em> se refieren a <em>multiprocessing</em>, un sinónimo de <em>shared memory parallel computing</em>. <em>OpenMP</em> se utiliza en un SMC por lo que cada <em>thread</em> tiene acceso a la memoria.</p></li>
<li><p>Algunas características de <em>OpenMP</em> son:</p>
<ul>
<li><p>Paralelización de ciclos <em>for</em> secuenciales en los que las iteraciones son independientes una de la otra de forma simple.</p></li>
<li><p>Paralelización de tareas y sincronización explícita de <em>threads</em>.</p></li>
</ul>
</li>
</ul>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Las directivas son instrucciones que indican al <a class="reference external" href="https://en.wikipedia.org/wiki/Preprocessor">preprocesador</a> (vía la compilación) que ejecutaremos una instrucción que no se encuentra en la especificación básica del lenguaje C. Ver <a class="reference external" href="https://en.wikipedia.org/wiki/C_preprocessor">C preprocessor</a>.</p>
</div>
<ul class="simple">
<li><p>Provee <strong>directivas</strong> vía <code class="docutils literal notranslate"><span class="pre">#pragma</span> <span class="pre">omp</span></code> para el cómputo en paralelo en un SMC.</p></li>
</ul>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Los <code class="docutils literal notranslate"><span class="pre">pragma</span></code> se utilizan para extender la funcionalidad de <em>C</em> pues no son parte de su especificación básica. Las versiones más recientes del compilador <code class="docutils literal notranslate"><span class="pre">gcc</span></code> soportan a los <code class="docutils literal notranslate"><span class="pre">pragma</span></code> y todas las <em>preprocessor directives</em> son por <em>default</em> de longitud una línea.</p>
<p>Ver <a class="reference external" href="https://gcc.gnu.org/onlinedocs/cpp/Pragmas.html">pragmas</a>.</p>
</div>
<div class="section" id="directiva-parallel">
<h3>Directiva parallel<a class="headerlink" href="#directiva-parallel" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="ejemplo-hello-world">
<h3>Ejemplo: <em>Hello world</em><a class="headerlink" href="#ejemplo-hello-world" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">hello_world_omp.c</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">//%</span><span class="k">cflags</span>:-fopenmp
<span class="o">//%</span><span class="k">cflags</span>:-Wall
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="c1">#include&lt;stdlib.h&gt;</span>
<span class="c1">#include&lt;omp.h&gt; </span>

<span class="n">void</span> <span class="n">Hello</span><span class="p">(</span><span class="n">void</span><span class="p">);</span>
<span class="nb">int</span> <span class="n">main</span><span class="p">(){</span>

    <span class="c1">#pragma omp parallel</span>
        <span class="n">Hello</span><span class="p">();</span>
    
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">void</span> <span class="n">Hello</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="nb">int</span> <span class="n">my_rank</span> <span class="o">=</span> <span class="n">omp_get_thread_num</span><span class="p">();</span> 
    <span class="nb">int</span> <span class="n">num_th</span> <span class="o">=</span> <span class="n">omp_get_num_threads</span><span class="p">();</span> 
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Hola del thread: </span><span class="si">%d</span><span class="s2"> de </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">my_rank</span><span class="p">,</span> <span class="n">num_th</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Hola del thread: 1 de 2
Hola del thread: 0 de 2
</pre></div>
</div>
</div>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">omp.h</span></code> es un <em>header file</em> con prototipos y definiciones de macros para uso de la librería de funciones y macros de <em>OpenMP</em>.</p></li>
<li><p>La función <code class="docutils literal notranslate"><span class="pre">Hello</span></code> será ejecutada por los <em>threads</em>.</p></li>
<li><p>La función <code class="docutils literal notranslate"><span class="pre">omp_get_thread_num</span></code> da el <em>rank</em> asignado por el <em>run time system</em> a cada <em>thread</em>.</p></li>
<li><p>Con la función <code class="docutils literal notranslate"><span class="pre">omp_get_num_threads</span></code> se obtiene el número de <em>threads</em> que realizaron un <em>fork</em> del <em>thread</em> principal.</p></li>
<li><p>Para compilar el archivo anterior hay que añadir la <em>flag</em> <code class="docutils literal notranslate"><span class="pre">-fopenmp</span></code> para soporte de <em>OpenMP</em>. De modo que la compilación se realiza:</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">gcc</span> <span class="pre">-Wall</span> <span class="pre">-fopenmp</span> <span class="pre">hello_world_omp.c</span> <span class="pre">-o</span> <span class="pre">hello_world_omp.out</span></code></p>
<ul class="simple">
<li><p>Dependiendo del número de cores de nuestro sistema tendremos diferentes número de <code class="docutils literal notranslate"><span class="pre">printf</span></code>’s.</p></li>
<li><p>Lo que continúa a la línea de <code class="docutils literal notranslate"><span class="pre">#pragma</span> <span class="pre">omp</span> <span class="pre">parallel</span></code> es un <em>structured block</em>, esto es, un <em>statement</em> o conjunto de <em>statements</em> que tienen un punto de entrada y un punto de salida. En el caso anterior sólo se llama a la función <code class="docutils literal notranslate"><span class="pre">Hello</span></code>, no se permiten statements como el siguiente:</p></li>
</ul>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma omp parallel</span>

<span class="k">if</span><span class="p">(...)</span> <span class="k">break</span><span class="p">;</span>
</pre></div>
</div>
<p>ni tampoco:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma omp parallel</span>

    <span class="p">{</span>
        <span class="k">if</span><span class="p">(</span><span class="n">variable</span> <span class="o">==</span> <span class="n">valor</span><span class="p">)</span> <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
        <span class="k">return</span> <span class="mi">-1</span><span class="p">;</span>
    <span class="p">}</span>
</pre></div>
</div>
</div>
<p>A continuación de la directiva <code class="docutils literal notranslate"><span class="pre">parallel</span></code> podemos usar diferentes tipos de <em>clauses</em>. Una <em>clause</em> en <em>OpenMP</em> es un texto que modifica una directiva. Por ejemplo, podemos usar la <em>clause</em> <code class="docutils literal notranslate"><span class="pre">num_threads</span></code> para especificar el número de threads que ejecutarán el <em>structured block</em>.</p>
</div>
<div class="section" id="clause-num-threads">
<h3><em>Clause</em> <code class="docutils literal notranslate"><span class="pre">num_threads</span></code><a class="headerlink" href="#clause-num-threads" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="id1">
<h3>Ejemplo: <em>Hello world</em><a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">hello_world_omp_num_threads.c</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">//%</span><span class="k">cflags</span>:-fopenmp
<span class="o">//%</span><span class="k">cflags</span>:-Wall
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="c1">#include&lt;stdlib.h&gt;</span>
<span class="c1">#include&lt;omp.h&gt; </span>

<span class="n">void</span> <span class="n">Hello</span><span class="p">(</span><span class="n">void</span><span class="p">);</span> 
<span class="nb">int</span> <span class="n">main</span><span class="p">(){</span>
    <span class="nb">int</span> <span class="n">n_threads</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
    <span class="c1">#pragma omp parallel num_threads(n_threads) </span>
        <span class="n">Hello</span><span class="p">();</span>
    
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">void</span> <span class="n">Hello</span><span class="p">(</span><span class="n">void</span><span class="p">){</span>
    <span class="nb">int</span> <span class="n">my_rank</span> <span class="o">=</span> <span class="n">omp_get_thread_num</span><span class="p">();</span> 
    <span class="nb">int</span> <span class="n">num_th</span> <span class="o">=</span> <span class="n">omp_get_num_threads</span><span class="p">();</span> 
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Hola del thread: </span><span class="si">%d</span><span class="s2"> de </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">my_rank</span><span class="p">,</span> <span class="n">num_th</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Hola del thread: 0 de 5
Hola del thread: 4 de 5
Hola del thread: 3 de 5
Hola del thread: 2 de 5
Hola del thread: 1 de 5
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="reduction-clause">
<h3><em>Reduction clause</em><a class="headerlink" href="#reduction-clause" title="Permalink to this headline">¶</a></h3>
<p><em>OpenMP</em> provee la <em>reduction clause</em> para aplicar la operación de suma (operador binario) a cada resultado calculado de un <em>thread</em> de forma repetida y almacenar en una variable la respuesta.</p>
<p>Nombramos <em>reduction variable</em> a la variable que almacenará los resultados intermedios calculados por cada <em>thread</em> y <em>reduction operator</em> a la operación binaria (por ejemplo una suma o multiplicación) que se aplica repetidamente a una secuencia de operandos para obtener un resultado, en un proceso que se le nombra <em>reduction</em>.</p>
<p>Por ejemplo, si <code class="docutils literal notranslate"><span class="pre">A</span></code> es un arreglo de <code class="docutils literal notranslate"><span class="pre">n</span></code> enteros, el cálculo:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span> <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">n</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="n">sum</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</pre></div>
</div>
<p>es un proceso de <em>reduction</em> en el que el <em>reduction operator</em> es la suma.</p>
<p>En openMP utilizamos la <em>reduction clause</em> en la <em>parallel directive</em>.</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">suma_global</span><span class="o">=</span><span class="mf">0.0</span>
<span class="cp">#pragma omp parallel num_threads(conteo_threads) reduction(+: sum_shared)</span>
    <span class="n">sum_shared</span> <span class="o">+=</span> <span class="n">Rcf_parallel</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">h_hat</span><span class="p">,</span><span class="n">n_subintervals_per_core</span><span class="p">);</span>
</pre></div>
</div>
<p>Con la <em>reduction clause</em> openMP crea una variable privada por cada <em>thread</em> y el <em>run time system</em> almacena el resultado de cada <em>thread</em> en esta variable. <em>openMP</em> también crea una <em>critical section</em> y los valores almacenados en las variables privadas son sumadas en esta <em>critical section</em> y almacenados en la <em>reduction variable</em> <code class="docutils literal notranslate"><span class="pre">sum_shared</span></code>. El <em>reduction operator</em> es: <code class="docutils literal notranslate"><span class="pre">+</span></code>.</p>
<p>La sintaxis de la <em>reduction clause</em> es:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">reduction</span><span class="p">(</span> <span class="o">&lt;</span><span class="n">operator</span><span class="o">&gt;:</span> <span class="o">&lt;</span><span class="n">variable</span> <span class="n">list</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
<p>El <em>reduction operator</em> puede ser cualquiera de los operadores: <code class="docutils literal notranslate"><span class="pre">+,*,-,&amp;,|,^,&amp;&amp;,||</span></code>. Cabe señalar que el proceso de <em>reduction</em> asume que los operadores utilizados cumplen con la propiedad asociativa (por ejemplo, el operador de resta no cumple con esto).</p>
<p>La variable que está en la <em>reduction clause</em> es compartida. Sin embargo una variable privada es creada por cada <em>thread</em> en el <em>team</em> (<strong>con el mismo nombre</strong> que aparece en la <em>reduction clause</em>) y si un <em>thread</em> ejecuta un statement en el <em>parallel block</em> que involucra a la variable, entonces se utiliza la variable privada y al finalizar el <em>parallel block</em>, los valores calculados en las variables privadas son combinados en la variable compartida.</p>
</div>
<div class="section" id="ejemplo-de-uso-de-nombres-de-variables-al-definir-variables-privadas-y-compartidas-en-reduction-clause">
<h3>Ejemplo de uso de nombres de variables al definir variables privadas y compartidas en <em>reduction clause</em><a class="headerlink" href="#ejemplo-de-uso-de-nombres-de-variables-al-definir-variables-privadas-y-compartidas-en-reduction-clause" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">ejemplo_nombre_variable_privada_compartida_reduction_clause.c</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>#include&lt;stdio.h&gt;
#include&lt;stdlib.h&gt;
#include&lt;omp.h&gt;

int main(int argc, char *argv[]){
    long n_threads;
    int private_variable;
    int sum_shared = 7;
        
    n_threads = strtol(argv[1], NULL, 10);
    
    printf(&quot;variable sum_shared al inicio : %d\n&quot;, sum_shared);
    
    #pragma omp parallel num_threads(n_threads) reduction(+: sum_shared)
    {
        int my_rank = omp_get_thread_num();
        if(my_rank==0)
                    printf(&quot;sum_shared, printf 1 del thread 0: %d\n&quot;, sum_shared);
            else
                    printf(&quot;sum_shared, prinftf 1 thread 1: %d\n&quot;, sum_shared);
        sum_shared = (my_rank==0)?10:20;
        private_variable = (my_rank==0)?1:2;
        if(my_rank==0)
            printf(&quot;sum_shared, printf 2 del thread 0: %d\n&quot;, sum_shared);
        else
            printf(&quot;sum_shared, printf 2 del thread 1: %d\n&quot;, sum_shared);
        sum_shared += private_variable;
            if(my_rank==0)
                    printf(&quot;sum_shared, printf 3 del thread 0: %d\n&quot;, sum_shared);
            else
                    printf(&quot;sum_shared, printf 3 del thread 1: %d\n&quot;, sum_shared);
    
    }
    printf(&quot;sum_shared al final de la directive parallel %d\n&quot;, sum_shared);
    
    return 0;
}
</pre></div>
</div>
</div>
</div>
<p>Compilamos:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
gcc -Wall -fopenmp ejemplo_nombre_variable_privada_compartida_reduction_clause.c ejemplo_nombre_variable_privada_compartida_reduction_clause.out 
</pre></div>
</div>
</div>
</div>
<p>Ejecutamos:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
./ejemplo_nombre_variable_privada_compartida_reduction_clause.out 2
</pre></div>
</div>
</div>
</div>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>La variable <code class="docutils literal notranslate"><span class="pre">sum_shared</span></code> se inicializa en 0. En general, las variables privadas creadas para una <em>reduction clause</em> son inicializadas al <em>identity value</em> para el <em>operator</em>. Por ejemplo, si el <em>operator</em> es la multiplicación, entonces las variables privadas son inicializadas en 1.</p>
</div>
</div>
<div class="section" id="ejemplo-regla-compuesta-del-rectangulo">
<h3>Ejemplo regla compuesta del rectángulo<a class="headerlink" href="#ejemplo-regla-compuesta-del-rectangulo" title="Permalink to this headline">¶</a></h3>
<p>Para la medición de tiempos se utilizaron las ligas: <a class="reference external" href="https://stackoverflow.com/questions/16764276/measuring-time-in-millisecond-precision">liga</a> y <a class="reference external" href="https://www.techiedelight.com/find-execution-time-c-program/">liga2</a></p>
<p><code class="docutils literal notranslate"><span class="pre">Rcf_openmp.c</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">//%</span><span class="k">cflags</span>:-fopenmp
<span class="o">//%</span><span class="k">cflags</span>:-lm
<span class="o">//%</span><span class="k">cflags</span>:-Wall
<span class="c1">#include&lt;stdio.h&gt;</span>
<span class="c1">#include&lt;stdlib.h&gt;</span>
<span class="c1">#include&lt;omp.h&gt;</span>
<span class="c1">#include&lt;math.h&gt; </span>
<span class="c1">#include&lt;time.h&gt;</span>
<span class="c1">#include &lt;sys/time.h&gt;</span>

<span class="n">double</span> <span class="n">Rcf_parallel</span><span class="p">(</span><span class="n">double</span> <span class="n">a</span><span class="p">,</span> <span class="n">double</span> <span class="n">h_hat</span><span class="p">,</span> <span class="nb">int</span> <span class="n">ns_p</span><span class="p">);</span>

<span class="n">double</span> <span class="n">f</span><span class="p">(</span><span class="n">double</span> <span class="n">node</span><span class="p">);</span>

<span class="nb">int</span> <span class="n">main</span><span class="p">(){</span>
    <span class="n">double</span> <span class="n">sum_shared</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">;</span> <span class="o">//</span><span class="n">shared</span> <span class="n">variable</span> <span class="k">for</span> <span class="n">threads</span>
    <span class="n">double</span> <span class="n">a</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">n</span> <span class="o">=</span> <span class="mf">1e7</span><span class="p">;</span> <span class="o">//</span><span class="n">number</span> <span class="n">of</span> <span class="n">subintervals</span>
    <span class="n">double</span> <span class="n">h_hat</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">n</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">n_subintervals_per_core</span><span class="p">;</span> <span class="o">//</span><span class="n">number</span> <span class="n">of</span> <span class="n">subintervals</span> <span class="n">assigned</span> <span class="n">to</span> <span class="n">each</span> <span class="n">core</span>
    <span class="nb">int</span> <span class="n">n_threads</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">};</span><span class="o">//</span><span class="n">n_threads</span> <span class="n">must</span> <span class="n">divide</span> <span class="n">exactly</span> <span class="n">n</span> <span class="n">variable</span>
    <span class="nb">int</span> <span class="n">len_n_threads_array</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">obj</span> <span class="o">=</span> <span class="mf">0.7468241328124271</span><span class="p">;</span>
    <span class="n">struct</span> <span class="n">timeval</span> <span class="n">start</span><span class="p">;</span>
    <span class="n">struct</span> <span class="n">timeval</span> <span class="n">end</span><span class="p">;</span>
    <span class="n">long</span> <span class="n">seconds</span><span class="p">;</span>
    <span class="n">long</span> <span class="n">long</span> <span class="n">mili</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">i</span><span class="p">;</span>
    <span class="n">n_threads</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">n_threads</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="n">n_threads</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
    <span class="n">n_threads</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
    <span class="n">n_threads</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>
    <span class="n">len_n_threads_array</span> <span class="o">=</span> <span class="n">sizeof</span><span class="p">(</span><span class="n">n_threads</span><span class="p">)</span><span class="o">/</span><span class="n">sizeof</span><span class="p">(</span><span class="n">n_threads</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
    <span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">len_n_threads_array</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">){</span>
        <span class="n">n_subintervals_per_core</span> <span class="o">=</span> <span class="n">n</span><span class="o">/</span><span class="n">n_threads</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
        <span class="n">gettimeofday</span><span class="p">(</span><span class="o">&amp;</span><span class="n">start</span><span class="p">,</span> <span class="n">NULL</span><span class="p">);</span>
        <span class="c1">#pragma omp parallel num_threads(n_threads[i]) reduction(+: sum_shared)</span>
            <span class="n">sum_shared</span> <span class="o">+=</span> <span class="n">Rcf_parallel</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">h_hat</span><span class="p">,</span><span class="n">n_subintervals_per_core</span><span class="p">);</span>
        <span class="n">sum_shared</span> <span class="o">=</span> <span class="n">h_hat</span><span class="o">*</span><span class="n">sum_shared</span><span class="p">;</span>
        <span class="n">gettimeofday</span><span class="p">(</span><span class="o">&amp;</span><span class="n">end</span><span class="p">,</span> <span class="n">NULL</span><span class="p">);</span>
        <span class="n">seconds</span> <span class="o">=</span> <span class="p">(</span><span class="n">end</span><span class="o">.</span><span class="n">tv_sec</span> <span class="o">-</span> <span class="n">start</span><span class="o">.</span><span class="n">tv_sec</span><span class="p">);</span>
        <span class="n">mili</span> <span class="o">=</span> <span class="mi">1000</span><span class="o">*</span><span class="p">(</span><span class="n">seconds</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">end</span><span class="o">.</span><span class="n">tv_usec</span> <span class="o">-</span> <span class="n">start</span><span class="o">.</span><span class="n">tv_usec</span><span class="p">)</span><span class="o">/</span><span class="mi">1000</span><span class="p">;</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Integral de </span><span class="si">%f</span><span class="s2"> a </span><span class="si">%f</span><span class="s2"> = </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">sum_shared</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Error relativo de la solución: </span><span class="si">%1.15e</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fabs</span><span class="p">(</span><span class="n">sum_shared</span><span class="o">-</span><span class="n">obj</span><span class="p">)</span><span class="o">/</span><span class="n">fabs</span><span class="p">(</span><span class="n">obj</span><span class="p">));</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Tiempo de ejecución con </span><span class="si">%d</span><span class="s2"> threads: %lld miliseconds</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">n_threads</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">mili</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;----------------------</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">);</span>
        <span class="n">sum_shared</span><span class="o">=</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">double</span> <span class="n">Rcf_parallel</span><span class="p">(</span><span class="n">double</span> <span class="n">a</span><span class="p">,</span> <span class="n">double</span> <span class="n">h_hat</span><span class="p">,</span> <span class="nb">int</span> <span class="n">n_s_c</span><span class="p">){</span>
    <span class="nb">int</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">my_rank</span> <span class="o">=</span> <span class="n">omp_get_thread_num</span><span class="p">();</span>
    <span class="n">double</span> <span class="n">local_int</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>
    <span class="nb">int</span> <span class="n">i</span><span class="p">;</span>
    <span class="n">double</span> <span class="n">x</span><span class="p">;</span>
    <span class="n">begin</span> <span class="o">=</span> <span class="n">my_rank</span><span class="o">*</span><span class="n">n_s_c</span><span class="p">;</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">begin</span> <span class="o">+</span> <span class="n">n_s_c</span><span class="p">;</span> 
    <span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="n">begin</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;=</span><span class="n">end</span><span class="o">-</span><span class="mi">1</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">){</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">a</span><span class="o">+</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mf">2.0</span><span class="p">)</span><span class="o">*</span><span class="n">h_hat</span><span class="p">;</span>
        <span class="n">local_int</span> <span class="o">+=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">);</span>
    <span class="p">}</span>   
    <span class="k">return</span> <span class="n">local_int</span><span class="p">;</span>
<span class="p">}</span>
        
<span class="n">double</span> <span class="n">f</span><span class="p">(</span><span class="n">double</span> <span class="n">node</span><span class="p">){</span>
    <span class="n">double</span> <span class="n">f_value</span><span class="p">;</span>
    <span class="n">f_value</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="nb">pow</span><span class="p">(</span><span class="n">nodo</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
    <span class="k">return</span> <span class="n">f_value</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Integral de 0.000000 a 1.000000 = 7.468241328124773e-01
Error relativo de la solución: 6.719397313003120e-14
Tiempo de ejecución con 1 threads: 32 miliseconds
----------------------
Integral de 0.000000 a 1.000000 = 7.468241328124707e-01
Error relativo de la solución: 5.842307840730588e-14
Tiempo de ejecución con 2 threads: 17 miliseconds
----------------------
Integral de 0.000000 a 1.000000 = 7.468241328124631e-01
Error relativo de la solución: 4.816559135869493e-14
Tiempo de ejecución con 4 threads: 12 miliseconds
----------------------
Integral de 0.000000 a 1.000000 = 7.468241328124646e-01
Error relativo de la solución: 5.024682061493483e-14
Tiempo de ejecución con 5 threads: 11 miliseconds
----------------------
Integral de 0.000000 a 1.000000 = 7.468241328124514e-01
Error relativo de la solución: 3.255637193689565e-14
Tiempo de ejecución con 8 threads: 19 miliseconds
----------------------
</pre></div>
</div>
</div>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Dividimos el número de subintervalos  <strong>n</strong> entre el número de <em>threads</em> que deseamos lanzar, por esto, <strong>n</strong> debe ser <strong>divisible</strong> entre las entradas del <em>array</em> <code class="docutils literal notranslate"><span class="pre">n_threads</span></code>. Esta cantidad es el número de subintervalos contiguos que le corresponden a cada <em>thread</em>.</p></li>
<li><p>Además, se debe de agregar el resultado de la suma de cada <em>thread</em>. Esto es posible realizar de forma sencilla definiendo una variable que sea compartida. Al definir tal variable en la función <em>main</em> y antes de un <em>parallel block</em> el <em>default</em> es que sea considerada como compartida.</p></li>
<li><p>Las variables que son privadas se definen en la función <code class="docutils literal notranslate"><span class="pre">Rcf_parallel</span></code>.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="multiprocessing">
<h2><a class="reference external" href="https://docs.python.org/3.1/library/multiprocessing.html">Multiprocessing</a><a class="headerlink" href="#multiprocessing" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="dask">
<h2><a class="reference external" href="https://docs.dask.org/en/latest/">Dask</a><a class="headerlink" href="#dask" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="parallel">
<h2><a class="reference external" href="https://www.rdocumentation.org/packages/parallel/versions/3.6.2">Parallel</a><a class="headerlink" href="#parallel" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="referencias-de-interes">
<h2>Referencias de interés<a class="headerlink" href="#referencias-de-interes" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://stories.dask.org/en/latest/">Use cases with dask</a></p></li>
<li><p><a class="reference external" href="https://github.com/dask/dask-tutorial">dask-tutorial</a></p></li>
</ul>
<p>En <em>dask</em> se hace referencia al uso de funciones <em>pure</em>. Ver: <a class="reference external" href="https://distributed.dask.org/en/latest/client.html#pure-functions-by-default">Pure Functions by Default</a> y <a class="reference external" href="https://toolz.readthedocs.io/en/latest/purity.html">Function Purity</a> para ejemplos de funciones <em>pure</em>.</p>
<p>En <a class="reference external" href="https://www.youtube.com/watch?v=EX_voquHdk0">Dask JupyterLab Extension</a> se muestra cómo instalar la extensión en jupyterlab para dask.</p>
<ul class="simple">
<li><p><a class="reference external" href="http://www.sfu.ca/~sblay/R/snow.html">snow Simplified</a></p></li>
<li><p><a class="reference external" href="https://docs.microsoft.com/en-us/machine-learning-server/r/how-to-revoscaler-distributed-computing-foreach">Using foreach and iterators for manual parallel execution</a></p></li>
</ul>
<p>Paquete de <em>R</em>: <a class="reference external" href="https://www.rdocumentation.org/packages/future/versions/1.21.0">future</a></p>
<div class="tip admonition">
<p class="admonition-title">Ejercicios</p>
<p>1.Resuelve los ejercicios y preguntas de la nota.</p>
</div>
<p><strong>Preguntas de comprehensión:</strong></p>
<p>1)Menciona diferencias que surgen en un programa que se ejecuta en un sistema de memoria compartida contra los que se ejecutan en un sistema de memoria distribuida.</p>
<p>2)¿A qué se le llama no determinismo y da un ejemplo en el que esto surge en un sistema de memoria compartida?</p>
<p>3)¿Qué es una <em>critical section</em>? ¿qué es una <em>race condition</em>? ¿cómo se puede lidiar con las <em>critical sections</em>?</p>
<p>4)¿Cuál es la terminología para nombrar a las variables que pueden ser accesadas por todos los <em>threads</em> y para las variables que sólo pueden ser accesadas por un <em>thread</em>?</p>
<p><strong>Referencias:</strong></p>
<ol class="simple">
<li><p>P. Pacheco, An Introduction to Parallel Programming, Morgan Kaufmann, 2011.</p></li>
<li><p>M. Gorelick, I. Ozsvald, High Performance Python, O’Reilly Media, 2014.</p></li>
<li><p>N. Matloff, Parallel Computing for Data Science. With Examples in R, C++ and CUDA, 2014.</p></li>
<li><p>B. W. Kernighan, D. M. Ritchie, The C Programming Language, Prentice Hall Software Series, 1988</p></li>
<li><p><a class="reference external" href="https://github.com/palmoreck/programming-languages/tree/master/C/extensiones_a_C/openMP">C/extensiones_a_C/openMP</a></p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "palmoreck/dockerfiles-for-binder",
            ref: "jupyterlab_optimizacion_2",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./V.optimizacion_de_codigo/5.4"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../5.3/Compilacion_a_C.html" title="previous page">5.3 Compilación a C</a>
    <a class='right-next' id="next-link" href="../5.5/Computo_en_paralelo_usando_GPUS_en_SMC.html" title="next page">5.5 Cómputo en paralelo usando GPUs en un sistema de memoria compartida (SMC)</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Erick Palacios Moreno<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>