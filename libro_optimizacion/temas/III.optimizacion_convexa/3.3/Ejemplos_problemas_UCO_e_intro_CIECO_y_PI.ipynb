{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(EJUCOINTCIECOPI)="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Ejemplos de problemas UCO e introducción a *Constrained Inequality and Equality Convex Optimization* (CIECO) y puntos interiores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Notas para contenedor de docker:\n",
    "\n",
    "Comando de docker para ejecución de la nota de forma local:\n",
    "\n",
    "nota: cambiar `<ruta a mi directorio>` por la ruta de directorio que se desea mapear a `/datos` dentro del contenedor de docker.\n",
    "\n",
    "`docker run --rm -v <ruta a mi directorio>:/datos --name jupyterlab_optimizacion -p 8888:8888 -d palmoreck/jupyterlab_optimizacion:2.1.4`\n",
    "\n",
    "password para jupyterlab: `qwerty`\n",
    "\n",
    "Detener el contenedor de docker:\n",
    "\n",
    "`docker stop jupyterlab_optimizacion`\n",
    "\n",
    "Documentación de la imagen de docker `palmoreck/jupyterlab_optimizacion:2.1.4` en [liga](https://github.com/palmoreck/dockerfiles/tree/master/jupyterlab/optimizacion).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota generada a partir de [liga1](https://www.dropbox.com/s/6isby5h1e5f2yzs/4.2.Problemas_de_optimizacion_convexa.pdf?dl=0), [liga2](https://drive.google.com/file/d/1zCIHNAxe5Shc36Qo0XjehHgwrafKSJ_t/view), [liga3](https://drive.google.com/file/d/12L7rOCgW7NEKl_xJbIGZz05XXVrOaPBz/view), [liga4](https://drive.google.com/file/d/1RMwUXEN_SOHKue-J9Cx3Ldvj9bejLjiM/view)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Al final de esta nota el y la lectora:\n",
    ":class: tip\n",
    "\n",
    "* \n",
    "\n",
    "* \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos problemas UCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mínimos cuadrados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obsérvese que hay una gran cantidad de modelos por mínimos cuadrados, por ejemplo:\n",
    "\n",
    "* [Lineales](https://en.wikipedia.org/wiki/Linear_least_squares) u [ordinarios](https://en.wikipedia.org/wiki/Ordinary_least_squares) (nombre más usado en Estadística y Econometría).\n",
    "\n",
    "* [Generalizados](https://en.wikipedia.org/wiki/Generalized_least_squares), [ponderados](https://en.wikipedia.org/wiki/Weighted_least_squares).\n",
    "\n",
    "* [No lineales](https://en.wikipedia.org/wiki/Non-linear_least_squares).\n",
    "\n",
    "* [Totales](https://en.wikipedia.org/wiki/Total_least_squares) y [parciales](https://en.wikipedia.org/wiki/Partial_least_squares_regression).\n",
    "\n",
    "* [No negativos](https://en.wikipedia.org/wiki/Non-negative_least_squares).\n",
    "\n",
    "* [Rango reducido](https://epubs.siam.org/doi/abs/10.1137/1.9780898718867.ch7).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mínimos cuadrados lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se **asume** en esta sección que $A \\in \\mathbb{R}^{m \\times n}$ con $m \\geq n$ (más renglones que columnas en $A$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada uno de los modelos anteriores tienen diversas aplicaciones y propósitos. Los lineales son un caso particular del problema más general de **aproximación por normas**:\n",
    "\n",
    "$$\\displaystyle \\min_{x \\in \\mathbb{R}^n} ||Ax-b||$$\n",
    "\n",
    "donde: $A \\in \\mathbb{R}^{m \\times n}$, $b \\in \\mathbb{R}^m$ son datos del problema, $x \\in \\mathbb{R}^n$ es la variable de optimización y $|| \\cdot||$ es una norma en $\\mathbb{R}^m$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Definiciones\n",
    "\n",
    "$x^* = \\text{argmin}_{x \\in \\mathbb{R}^n} ||Ax-b||$ se le nombra **solución aproximada** de $Ax \\approx b$ en la norma $|| \\cdot ||$.\n",
    "\n",
    "El vector: $r(x) = Ax -b$ se le nombra **residual** del problema.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentario\n",
    "\n",
    "El problema de aproximación por normas también se le nombra **problema de regresión**. En este contexto, las componentes de $x$ son nombradas variables regresoras, las columnas de $A$ es un vector de *features* y el vector $\\displaystyle \\sum_{j=1}^n x_j^*a_j$ con $x^*$ óptimo del problema es nombrado la **regresión de $b$ sobre las regresoras**, $b$ es la **respuesta.**\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si en el problema de aproximación de normas anterior se utiliza la norma Euclidiana o norma $2$, $|| \\cdot ||_2$, y se eleva al cuadrado la función objetivo se tiene:\n",
    "\n",
    "$$\\displaystyle \\min_{x \\in \\mathbb{R}^n} ||Ax-b||^2_2$$\n",
    "\n",
    "que es el modelo por mínimos cuadrados lineales cuyo objetivo es minimizar la suma de cuadrados de las componentes del residual $r(x)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A partir de aquí, la variable de optimización será $\\beta$ y no $x$**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supóngase que se han realizado mediciones de un fenómeno de interés en diferentes puntos $x_i$'s resultando en cantidades $y_i$'s $\\forall i=0,1,\\dots, m$ (se tienen $m+1$ puntos) y además las $y_i$'s contienen un ruido aleatorio causado por errores de medición:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/iydpi0m8ndqzb0s/mcuadrados_1.jpg?dl=0\" heigth=\"350\" width=\"350\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de los mínimos cuadrados es construir una curva, $f(x|\\beta)$ que \"mejor\" se ajuste a los datos $(x_i,y_i)$, $\\forall i=0,1,\\dots,m$. El término de \"mejor\" se refiere a que la suma: \n",
    "\n",
    "$$\\displaystyle \\sum_{i=0}^m (y_i -f(x_i|\\beta))^2$$ \n",
    "\n",
    "\n",
    "sea lo \"más pequeña posible\", esto es, a que la suma de las distancias verticales entre $y_i$ y $f(x_i|\\beta)$ $\\forall i=0,1,\\dots,m$ al cuadrado sea mínima. Por ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/0dhzv336jj6ep4z/mcuadrados_2.jpg?dl=0\" heigth=\"350\" width=\"350\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Observación\n",
    ":class: tip\n",
    "\n",
    "La notación $f(x|\\beta)$ se utiliza para denotar que $\\beta$ es un vector de parámetros a estimar, en específico $\\beta_0, \\beta_1, \\dots \\beta_n$, esto es: $n+1$ parámetros a estimar.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo en mínimos cuadrados lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los mínimos cuadrados lineales se asume un modelo:  \n",
    "\n",
    "$$f(x|\\beta) = \\displaystyle \\sum_{j=0}^n\\beta_j\\phi_j(x)$$\n",
    "\n",
    "con $\\phi_j: \\mathbb{R} \\rightarrow \\mathbb{R}$ funciones conocidas por lo que se tiene una gran flexibilidad para el proceso de ajuste. Con las funciones $\\phi_j (\\cdot)$ se construye a la matriz $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Observación\n",
    ":class: tip\n",
    "\n",
    "Si $n=m$ entonces se tiene un problema de interpolación.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $m=3$ y $A \\in \\mathbb{R}^{3 \\times 2}$ geométricamente el problema de **mínimos cuadrados lineales** se puede visualizar con el siguiente dibujo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/a6pjx0pdqa3cp60/mc_beta.png?dl=0\" heigth=\"400\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dibujo anterior:\n",
    "\n",
    "* $r(\\beta) = y-A\\beta$,\n",
    "\n",
    "* el vector $y \\in \\mathbb{R}^m$ contiene las entradas $y_i$'s,\n",
    "\n",
    "* la matriz $A \\in \\mathbb{R}^{m \\times n}$ contiene a las entradas $x_i$'s o funciones de éstas $\\forall i=0,1,\\dots,m$.\n",
    "\n",
    "Por el dibujo se tiene que cumplir que $A^Tr(\\beta)=0$, esto es: las columnas de $A$ son ortogonales a $r(\\beta)$. La condición anterior conduce a las **ecuaciones normales**: \n",
    "\n",
    "$$0=A^Tr(\\beta)=A^T(y-A\\beta)=A^Ty-A^TA\\beta.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde: $A$ se construye con las $\\phi_j$'s evaluadas en los puntos $x_i$'s, el vector $\\beta$ contiene a los parámetros $\\beta_j$'s a estimar y el vector $y$, la variable **respuesta**, se construye con los puntos $y_i$'s:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A = \\left[\\begin{array}{cccc}\n",
    "\\phi_0(x_0) &\\phi_1(x_0)&\\dots&\\phi_n(x_0)\\\\\n",
    "\\phi_0(x_1) &\\phi_1(x_1)&\\dots&\\phi_n(x_1)\\\\\n",
    "\\vdots &\\vdots& \\vdots&\\vdots\\\\\n",
    "\\phi_0(x_n) &\\phi_1(x_n)&\\dots&\\phi_n(x_n)\\\\\n",
    "\\vdots &\\vdots& \\vdots&\\vdots\\\\\n",
    "\\phi_0(x_{m-1}) &\\phi_1(x_{m-1})&\\dots&\\phi_n(x_{m-1})\\\\\n",
    "\\phi_0(x_m) &\\phi_1(x_m)&\\dots&\\phi_n(x_m)\n",
    "\\end{array}\n",
    "\\right] \\in \\mathbb{R}^{(m+1)x(n+1)},\n",
    "\\beta=\n",
    "\\left[\\begin{array}{c}\n",
    "\\beta_0\\\\\n",
    "\\beta_1\\\\\n",
    "\\vdots \\\\\n",
    "\\beta_n\n",
    "\\end{array}\n",
    "\\right] \\in \\mathbb{R}^n,\n",
    "y=\n",
    "\\left[\\begin{array}{c}\n",
    "y_0\\\\\n",
    "y_1\\\\\n",
    "\\vdots \\\\\n",
    "y_m\n",
    "\\end{array}\n",
    "\\right] \\in \\mathbb{R}^{m + 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, considerando la variable de optimización $\\beta$ y al vector $y$ tenemos: $A^TA \\beta = A^Ty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentario\n",
    "\n",
    "Si $A$ es de $rank$ completo (tiene $n+1$ columnas linealmente independientes) una opción para resolver el sistema anterior es calculando la factorización $QR$ de $A$: $A = QR$ y entonces: \n",
    "\n",
    "\n",
    "$$A^TA\\beta = A^Ty$$. \n",
    "\n",
    "\n",
    "Dado que $A=QR$ se tiene: $A^TA = (R^TQ^T)(QR)$ y $A^T = R^TQ^T$ por lo que:\n",
    "\n",
    "$$(R^TQ^T)(QR) \\beta =  R^TQ^T y$$\n",
    "\n",
    "y usando que $Q$ tiene columnas ortonormales:\n",
    "\n",
    "$$R^TR\\beta = R^TQ^Ty$$\n",
    "\n",
    "Como $A$ tiene $n+1$ columnas linealmente independientes, la matriz $R$ es invertible por lo que $R^T$ también lo es y finalmente se tiene el **sistema de ecuaciones lineales** por resolver:\n",
    "\n",
    "$$R\\beta = Q^Ty$$\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enfoque de optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función objetivo en los mínimos cuadrados lineales puede escribirse de las siguientes formas:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{eqnarray}\n",
    "f_o(\\beta)=\\displaystyle \\sum_{i=1}^{m} (y_i -f_o(x_i|\\beta))^2 &=&  \\displaystyle \\sum_{i=1}^{m} (y_i - A[i,:]^T\\beta)^2 \\\\\n",
    "&=& ||y - A \\beta||_2^2 \\\\\n",
    "&=& (y-A\\beta)^T(y-A\\beta) \\\\\n",
    "&=& y^Ty-2\\beta^TA^Ty + \\beta^TA^TA\\beta\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "con $A[i,:]$ $i$-ésimo renglón de $A$ visto como un vector en $\\mathbb{R}^n$. Es común dividir por $2$ la función objetivo para finalmente tener el problema:\n",
    "\n",
    "$$\\displaystyle \\min_{\\beta \\in \\mathbb{R}^n} \\frac{1}{2}\\beta^TA^TA\\beta - \\beta^TA^Ty + \\frac{1}{2}y^Ty.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Observación\n",
    ":class: tip\n",
    "\n",
    "En cualquier reescritura de la función $f_o$, el problema de aproximación con normas, o bien en su caso particular de mínimos cuadrados, es un problema de **optimización convexa**.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision = 2) #just two decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1989) #for reproducibility\n",
    "mpoints = 20\n",
    "x = np.random.randn(mpoints) \n",
    "y = -3*x + np.random.normal(2,1,mpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Los datos ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y, 'r*')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Puntos ejemplo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos el paquete [cvxpy](https://github.com/cvxgrp/cvxpy) para resolver el problema de mínimos cuadrados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Construímos a la matriz $A$.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.ones((mpoints,2)) #step 1 to build matrix A\n",
    "A[:,1] = x #step 2 to build matrix A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Definición de variables y función objetivo: $\\frac{1}{2}\\beta^TA^TA\\beta - \\beta^TA^Ty + \\frac{1}{2}y^Ty$.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2 # number of variables\n",
    "beta = cp.Variable(n) #optimization variable\n",
    "fo_cvxpy = (1/2)*cp.quad_form(beta, A.T@A) - cp.sum(cp.multiply(A.T@y, beta)) + 1/2*y.dot(y) #objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.217738419387963\n"
     ]
    }
   ],
   "source": [
    "prob = cp.Problem(cp.Minimize(fo_cvxpy))\n",
    "print(prob.solve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal value is 10.217738419387963\n",
      "The optimal beta is\n",
      "[ 2.03 -2.65]\n",
      "The norm of the residual is  4.520561562325624\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nThe optimal value is\", prob.value)\n",
    "print(\"The optimal beta is\")\n",
    "print(beta.value)\n",
    "print(\"The norm of the residual is \", cp.norm(A @ beta - y, p=2).value) #also works: cp.norm2(A @ beta - y).value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paquete *CVXPY* ya tiene una función para resolver el problema anterior, ver [least_squares](https://www.cvxpy.org/examples/basic/least_squares.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo_cvxpy = 1/2*cp.sum_squares(A@beta -y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.217738419387944\n"
     ]
    }
   ],
   "source": [
    "prob = cp.Problem(cp.Minimize(fo_cvxpy))\n",
    "print(prob.solve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal value is 10.217738419387944\n",
      "The optimal beta is\n",
      "[ 2.03 -2.65]\n",
      "The norm of the residual is  4.520561562325624\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nThe optimal value is\", prob.value)\n",
    "print(\"The optimal beta is\")\n",
    "print(beta.value)\n",
    "print(\"The norm of the residual is \", cp.norm(A @ beta - y, p=2).value) #also works: cp.norm2(A @ beta - y).value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción a CIECO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Componentes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Máquina de Soporte Vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puntos Interiores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias:**\n",
    "\n",
    "1. S. P. Boyd, L. Vandenberghe, Convex Optimization, Cambridge University Press, 2009.\n",
    "\n",
    "2. J. Dennis, R. B. Schnabel, Numerical Methods for Unconstrained Optimization and Nonlinear Equations, SIAM, 1996.\n",
    "\n",
    "3. J. Nocedal, S. J. Wright, Numerical Optimization, Springer, 2006."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
