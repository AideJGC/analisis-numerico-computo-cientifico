{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(COMPPARALELOCPUSSMC)="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4 Cómputo en paralelo usando CPUs en un sistema de memoria compartida (SMC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Notas para contenedor de docker:\n",
    "\n",
    "Comando de docker para ejecución de la nota de forma local:\n",
    "\n",
    "nota: cambiar `<ruta a mi directorio>` por la ruta de directorio que se desea mapear a `/datos` dentro del contenedor de docker.\n",
    "\n",
    "`docker run --rm -v <ruta a mi directorio>:/datos --name jupyterlab_optimizacion_2 -p 8888:8888 -p 8787:8787 -d palmoreck/jupyterlab_optimizacion_2:3.0.0`\n",
    "\n",
    "password para jupyterlab: `qwerty`\n",
    "\n",
    "Detener el contenedor de docker:\n",
    "\n",
    "`docker stop jupyterlab_optimizacion_2`\n",
    "\n",
    "Documentación de la imagen de docker `palmoreck/jupyterlab_optimizacion_2:3.0.0` en [liga](https://github.com/palmoreck/dockerfiles/tree/master/jupyterlab/optimizacion_2).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota generada a partir de [liga1](https://www.dropbox.com/s/oauifmx3e19ofyq/2.3.Sistemas_de_memoria_compartida_Pthreads.pdf?dl=0), [liga2](https://www.dropbox.com/s/vcxbrqkk6x946d7/2.4.Sistemas_de_memoria_compartida_openMP.pdf?dl=0), [liga3](https://www.dropbox.com/s/v4ub0p3ndf7w1p0/2.2.Sistemas_de_memoria_distribuida_MPI.pdf?dl=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Al final de esta nota el y la lectora:\n",
    ":class: tip\n",
    "\n",
    "*\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se presentan códigos y sus ejecuciones en una máquina `m4.16xlarge` de la nube de [AWS](https://aws.amazon.com/). Se utilizó la AMI `opt2-aws-educate-openblas-04-04-2021` de la región `us-east-1` (Virginia) para reproducibilidad de resultados. Tal AMI se construyó a partir de una AMI `ubuntu 20.04 - ami-042e8287309f5df03` con el [script_profiling_and_BLAS.sh](https://github.com/palmoreck/scripts_for_useful_tools_installations/blob/main/AWS/ubuntu_20.04/optimizacion_2/script_profiling_and_BLAS.sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{admonition} Comentario\n",
    "\n",
    "Si se utiliza la *AMI* `opt2-aws-educate-openblas-04-04-2021` colocar en `User data` el siguiente *script*:\n",
    "\n",
    "```bash\n",
    "\n",
    "#!/bin/bash\n",
    "##variables:\n",
    "region=us-east-1 #make sure instance is in Virginia\n",
    "name_instance=OpenBLAS\n",
    "USER=ubuntu\n",
    "##System update\n",
    "apt-get update -yq\n",
    "##Tag instance\n",
    "INSTANCE_ID=$(curl -s http://instance-data/latest/meta-data/instance-id)\n",
    "PUBLIC_IP=$(curl -s http://instance-data/latest/meta-data/public-ipv4)\n",
    "sudo -H -u $USER bash -c \"/home/$USER/.local/bin/aws ec2 create-tags --resources $INSTANCE_ID --tag Key=Name,Value=$name_instance-$PUBLIC_IP --region=$region\"\n",
    "sudo -H -u $USER bash -c \"cd / && /home/$USER/.local/bin/jupyter lab --ip=0.0.0.0 --no-browser --config=/home/$USER/.jupyter/jupyter_notebook_config.py &\"\n",
    "\n",
    "```\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La máquina `m4.16xlarge` tiene las siguientes características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:                    x86_64\n",
      "CPU op-mode(s):                  32-bit, 64-bit\n",
      "Byte Order:                      Little Endian\n",
      "Address sizes:                   46 bits physical, 48 bits virtual\n",
      "CPU(s):                          64\n",
      "On-line CPU(s) list:             0-63\n",
      "Thread(s) per core:              2\n",
      "Core(s) per socket:              16\n",
      "Socket(s):                       2\n",
      "NUMA node(s):                    2\n",
      "Vendor ID:                       GenuineIntel\n",
      "CPU family:                      6\n",
      "Model:                           79\n",
      "Model name:                      Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n",
      "Stepping:                        1\n",
      "CPU MHz:                         2290.913\n",
      "CPU max MHz:                     3000.0000\n",
      "CPU min MHz:                     1200.0000\n",
      "BogoMIPS:                        4600.03\n",
      "Hypervisor vendor:               Xen\n",
      "Virtualization type:             full\n",
      "L1d cache:                       1 MiB\n",
      "L1i cache:                       1 MiB\n",
      "L2 cache:                        8 MiB\n",
      "L3 cache:                        90 MiB\n",
      "NUMA node0 CPU(s):               0-15,32-47\n",
      "NUMA node1 CPU(s):               16-31,48-63\n",
      "Vulnerability Itlb multihit:     KVM: Vulnerable\n",
      "Vulnerability L1tf:              Mitigation; PTE Inversion\n",
      "Vulnerability Mds:               Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unknown\n",
      "Vulnerability Meltdown:          Mitigation; PTI\n",
      "Vulnerability Spec store bypass: Vulnerable\n",
      "Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization\n",
      "Vulnerability Spectre v2:        Mitigation; Full generic retpoline, STIBP disabled, RSB filling\n",
      "Vulnerability Srbds:             Not affected\n",
      "Vulnerability Tsx async abort:   Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unknown\n",
      "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq monitor est ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm cpuid_fault invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm xsaveopt ida\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  *-firmware\n",
      "       description: BIOS\n",
      "       vendor: Xen\n",
      "       physical id: 0\n",
      "       version: 4.11.amazon\n",
      "       date: 08/24/2006\n",
      "       size: 96KiB\n",
      "       capabilities: pci edd\n",
      "  *-memory\n",
      "       description: System Memory\n",
      "       physical id: 1000\n",
      "       size: 256GiB\n",
      "       capabilities: ecc\n",
      "       configuration: errordetection=multi-bit-ecc\n",
      "     *-bank:0\n",
      "          description: DIMM RAM\n",
      "          physical id: 0\n",
      "          slot: DIMM 0\n",
      "          size: 16GiB\n",
      "          width: 64 bits\n",
      "     *-bank:1\n",
      "          description: DIMM RAM\n",
      "          physical id: 1\n",
      "          slot: DIMM 1\n",
      "          size: 16GiB\n",
      "          width: 64 bits\n",
      "     *-bank:2\n",
      "          description: DIMM RAM\n",
      "          physical id: 2\n",
      "          slot: DIMM 2\n",
      "          size: 16GiB\n",
      "          width: 64 bits\n",
      "     *-bank:3\n",
      "          description: DIMM RAM\n",
      "          physical id: 3\n",
      "          slot: DIMM 3\n",
      "          size: 16GiB\n",
      "          width: 64 bits\n",
      "     *-bank:4\n",
      "          description: DIMM RAM\n",
      "          physical id: 4\n",
      "          slot: DIMM 4\n",
      "          size: 16GiB\n",
      "          width: 64 bits\n",
      "     *-bank:5\n",
      "          description: DIMM RAM\n",
      "          physical id: 5\n",
      "          slot: DIMM 5\n",
      "          size: 16GiB\n",
      "          width: 64 bits\n",
      "     *-bank:6\n",
      "          description: DIMM RAM\n",
      "          physical id: 6\n",
      "          slot: DIMM 6\n",
      "          size: 16GiB\n",
      "          width: 64 bits\n",
      "     *-bank:7\n",
      "          description: DIMM RAM\n",
      "          physical id: 7\n",
      "          slot: DIMM 7\n",
      "          size: 16GiB\n",
      "          width: 64 bits\n",
      "     *-bank:8\n",
      "          description: DIMM RAM\n",
      "          physical id: 8\n",
      "          slot: DIMM 8\n",
      "          size: 16GiB\n",
      "          width: 64 bits\n",
      "     *-bank:9\n",
      "          description: DIMM RAM\n",
      "          physical id: 9\n",
      "          slot: DIMM 9\n",
      "          size: 16GiB\n",
      "          width: 64 bits\n",
      "     *-bank:10\n",
      "          description: DIMM RAM\n",
      "          physical id: a\n",
      "          slot: DIMM 10\n",
      "          size: 16GiB\n",
      "          width: 64 bits\n",
      "     *-bank:11\n",
      "          description: DIMM RAM\n",
      "          physical id: b\n",
      "          slot: DIMM 11\n",
      "          size: 16GiB\n",
      "          width: 64 bits\n",
      "     *-bank:12\n",
      "          description: DIMM RAM\n",
      "          physical id: c\n",
      "          slot: DIMM 12\n",
      "          size: 16GiB\n",
      "          width: 64 bits\n",
      "     *-bank:13\n",
      "          description: DIMM RAM\n",
      "          physical id: d\n",
      "          slot: DIMM 13\n",
      "          size: 16GiB\n",
      "          width: 64 bits\n",
      "     *-bank:14\n",
      "          description: DIMM RAM\n",
      "          physical id: e\n",
      "          slot: DIMM 14\n",
      "          size: 16GiB\n",
      "          width: 64 bits\n",
      "     *-bank:15\n",
      "          description: DIMM RAM\n",
      "          physical id: f\n",
      "          slot: DIMM 15\n",
      "          size: 16GiB\n",
      "          width: 64 bits\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo lshw -C memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux ip-10-0-0-140 5.4.0-1038-aws #40-Ubuntu SMP Fri Feb 5 23:50:40 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "uname -ar #r for kernel, a for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Observación\n",
    ":class: tip\n",
    "\n",
    "En la celda anterior se utilizó el comando de *magic* `%%bash`. Algunos comandos de *magic* los podemos utilizar también con `import`. Ver [ipython-magics](https://ipython.readthedocs.io/en/stable/interactive/magics.html#)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistemas de memoria compartida (SMC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un SMC en general se ve como el siguiente dibujo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/ao3if8tzwsvzfi7/shared_memory_sistems.png?dl=0\" heigth=\"500\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dibujo anterior es un SMC con acceso uniforme a la memoria ([UMA](https://en.wikipedia.org/wiki/Uniform_memory_access)), esto es, cada proceso o *thread* creado en el procesador o *core* accede con las mismas velocidades a la memoria.\n",
    "\n",
    "La **comunicación** en este tipo de sistemas depende si se utilizan procesos o *threads* ya que aunque los procesos generados por un proceso principal tienen acceso a la memoria, los cambios/actualizaciones que haga uno de ellos a una variable no lo llegan a ver los otros procesos. Esto es distinto con los *threads* dado que un cambio que realice un *thread* en una variable sí lo pueden ver los otros *threads*. Lo anterior se debe a las distintas direcciones de memoria que utilizan los procesos vs la misma dirección de memoria que utilizan los *threads*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Definición\n",
    "\n",
    "Las variables que pueden ser accesadas por todos los *threads* en un SMC se les nombra **variables compartidas**.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Observación\n",
    ":class: tip\n",
    "\n",
    "Hay paqueterías que crean subprocesos a partir de un proceso principal en lugar de *threads*. En este caso en lugar de un *fork* se realiza un *spawn*. Los subprocesos pueden ver cambios a variables hechos por otros. \n",
    "\n",
    "Ver [Contexts and start methods](https://docs.python.org/3.9/library/multiprocessing.html#contexts-and-start-methods) y [stackoverflow: difference between threadpool vs pool in python multiprocessing](https://stackoverflow.com/questions/46045956/whats-the-difference-between-threadpool-vs-pool-in-python-multiprocessing-modul) para diferencias entre *fork* y *spawn*.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajar sobre SMC tiene ventajas y desventajas. Una ventaja es facilidad de comunicación y una desventaja es la **coordinación** para ejecutar instrucciones. Por ejemplo, con variables compartidas se puede realizar la comunicación entre los *threads*, sin embargo, para el uso de tales variables por diferentes *threads* debemos crear candados, *locks*. Lo anterior surge pues si un *thread* con etiqueta $1$ accede a una variable compartida, otro *thread* con etiqueta $2$, no podrá utilizarla hasta que el thread $1$ finalice de usarla. Ver [Thread Safety](https://en.wikipedia.org/wiki/Thread_safety) y [Race Condition](https://en.wikipedia.org/wiki/Race_condition#Computing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Definición\n",
    "\n",
    "En una *race condition* múltiples *threads* intentan acceder a un recurso compartido, al menos uno de los accesos resulta en una modificación al recurso y posteriormente los siguientes accesos pueden no ver la modificación. A la sección del código que causa la *race condition* se le nombra *critical section*. Las *critical sections* se ejecutan con código secuencial o con *locks* para evitar las *race conditions*.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentarios\n",
    "\n",
    "* Para crear procesos o *threads* en los lenguajes de programación de *C, Python* o *R*, utilizamos las librerías, API's o extensiones vía paquetes a tales lenguajes. Lo anterior se debe a que *C, Python* y *R* en sus implementaciones más utilizadas o estándar, fueron diseñados con el propósito de utilizarse sobre sistemas con un sólo procesador. En distintas implementaciones de los lenguajes hay soporte para SMC. \n",
    "\n",
    "* Ejemplos de máquinas con SMC son las laptops, los celulares, máquinas de escritorio con más de un *core*.\n",
    "\n",
    "* Otro tipo de SMC se puede representar con el siguiente dibujo:\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/dqwdqdxiecj91vy/shared_memory_systems_2.png?dl=0\" heigth=\"500\" width=\"500\">\n",
    "\n",
    "en el que los procesos o *threads* pueden acceder a la memoria en una forma no uniforme [(NUMA)](https://en.wikipedia.org/wiki/Non-uniform_memory_access). Una de las diferencias que se tienen entre un NUMA y un UMA es la tasa de transferencia de datos para *cores* que están más cercanos a una memoria.\n",
    "\n",
    "* Un sistema de memoria distribuida (SMD) tiene una conexión, por ejemplo vía una *network*, entre pares de *core-memoria* y en general se ve como el siguiente dibujo:\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/iky7af1m3dcj3e0/distributed_memory_systems.png?dl=0\" heigth=\"600\" width=\"600\">\n",
    "\n",
    "La memoria en un SMD asociada al *core* sólo puede ser accesada por éste y es inaccesible a los demás *cores*, esto es, se tiene una memoria \"privada\". Lo anterior contrasta con los SMC en los que todos los *cores* accesan a una memoria compartida. En un SMD el cómputo distribuido crea múltiples procesos a partir de un proceso principal. En un SMC el cómputo paralelo crea múltiples procesos o *threads*. Un ejemplo de un SMD es un clúster de máquinas. Cada máquina en el clúster puede ser un SMC y por tanto los procesos en cada máquina tienen la capacidad de crear procesos o *threads*. En este caso se tiene un sistema híbrido SMD y SMC. Un programa diseñado para ejecutarse en un SMD puede ejecutarse en un SMC pues se divide su memoria de forma lógica en espacios de memoria privados para los *threads*.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OpenMP](http://www.openmp.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es una extensión al lenguaje *C* y es una API para cómputo en paralelo en un sistema de memoria compartida, *aka, shared memory parallel programming* con CPUs. Lo anterior *OpenMP* lo posibilita con el *threading*: *fork* y *join* de *threads* a partir de un proceso principal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/0vnjfdk7fo62m8h/threading.png?dl=0\" heigth=\"400\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver {ref}`Threading o Hyperthreading <THREADINGHYPER>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Las siglas *MP* se refieren a *multiprocessing*, un sinónimo de *shared memory parallel computing*. *OpenMP* se utiliza en un SMC por lo que cada *thread* tiene acceso a la memoria.\n",
    "\n",
    "* Algunas características de *OpenMP* son:\n",
    "\n",
    "    * Paralelización de ciclos *for* secuenciales en los que las iteraciones son independientes una de la otra de forma simple.\n",
    "\n",
    "    * Paralelización de tareas y sincronización explícita de *threads*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Las directivas son instrucciones que indican al [preprocesador](https://en.wikipedia.org/wiki/Preprocessor) (vía la compilación) que ejecutaremos una instrucción que no se encuentra en la especificación básica del lenguaje C. Ver [C preprocessor](https://en.wikipedia.org/wiki/C_preprocessor).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Provee **directivas** vía `#pragma omp` para el cómputo en paralelo en un SMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentario\n",
    "\n",
    "Los `pragma` se utilizan para extender la funcionalidad de *C* pues no son parte de su especificación básica. Las versiones más recientes del compilador `gcc` soportan a los `pragma` y todas las *preprocessor directives* son por *default* de longitud una línea.\n",
    "\n",
    "Ver [pragmas](https://gcc.gnu.org/onlinedocs/cpp/Pragmas.html).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directiva parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: *Hello world*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hello_world_omp.c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hello_world_omp.c\n"
     ]
    }
   ],
   "source": [
    "%%file hello_world_omp.c\n",
    "#include<stdio.h>\n",
    "#include<stdlib.h>\n",
    "#include<omp.h> \n",
    "\n",
    "void Hello(void);\n",
    "int main(){\n",
    "\n",
    "    #pragma omp parallel\n",
    "        Hello();\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "\n",
    "void Hello(void){\n",
    "    int my_rank = omp_get_thread_num(); \n",
    "    int num_th = omp_get_num_threads(); \n",
    "    printf(\"Hola del thread: %d de %d\\n\", my_rank, num_th);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcc -Wall -fopenmp hello_world_omp.c -o hello_world_omp.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola del thread: 5 de 64\n",
      "Hola del thread: 59 de 64\n",
      "Hola del thread: 24 de 64\n",
      "Hola del thread: 47 de 64\n",
      "Hola del thread: 32 de 64\n",
      "Hola del thread: 27 de 64\n",
      "Hola del thread: 22 de 64\n",
      "Hola del thread: 60 de 64\n",
      "Hola del thread: 40 de 64\n",
      "Hola del thread: 45 de 64\n",
      "Hola del thread: 51 de 64\n",
      "Hola del thread: 58 de 64\n",
      "Hola del thread: 53 de 64\n",
      "Hola del thread: 44 de 64\n",
      "Hola del thread: 10 de 64\n",
      "Hola del thread: 46 de 64\n",
      "Hola del thread: 11 de 64\n",
      "Hola del thread: 4 de 64\n",
      "Hola del thread: 15 de 64\n",
      "Hola del thread: 31 de 64\n",
      "Hola del thread: 8 de 64\n",
      "Hola del thread: 13 de 64\n",
      "Hola del thread: 16 de 64\n",
      "Hola del thread: 7 de 64\n",
      "Hola del thread: 21 de 64\n",
      "Hola del thread: 1 de 64\n",
      "Hola del thread: 14 de 64\n",
      "Hola del thread: 3 de 64\n",
      "Hola del thread: 37 de 64\n",
      "Hola del thread: 43 de 64\n",
      "Hola del thread: 18 de 64\n",
      "Hola del thread: 17 de 64\n",
      "Hola del thread: 62 de 64\n",
      "Hola del thread: 25 de 64\n",
      "Hola del thread: 29 de 64\n",
      "Hola del thread: 0 de 64\n",
      "Hola del thread: 30 de 64\n",
      "Hola del thread: 54 de 64\n",
      "Hola del thread: 2 de 64\n",
      "Hola del thread: 55 de 64\n",
      "Hola del thread: 50 de 64\n",
      "Hola del thread: 63 de 64\n",
      "Hola del thread: 23 de 64\n",
      "Hola del thread: 38 de 64\n",
      "Hola del thread: 20 de 64\n",
      "Hola del thread: 57 de 64\n",
      "Hola del thread: 28 de 64\n",
      "Hola del thread: 6 de 64\n",
      "Hola del thread: 56 de 64\n",
      "Hola del thread: 36 de 64\n",
      "Hola del thread: 26 de 64\n",
      "Hola del thread: 33 de 64\n",
      "Hola del thread: 9 de 64\n",
      "Hola del thread: 34 de 64\n",
      "Hola del thread: 19 de 64\n",
      "Hola del thread: 39 de 64\n",
      "Hola del thread: 49 de 64\n",
      "Hola del thread: 12 de 64\n",
      "Hola del thread: 48 de 64\n",
      "Hola del thread: 42 de 64\n",
      "Hola del thread: 61 de 64\n",
      "Hola del thread: 41 de 64\n",
      "Hola del thread: 35 de 64\n",
      "Hola del thread: 52 de 64\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./hello_world_omp.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{admonition} Comentarios\n",
    "\n",
    "* `omp.h` es un *header file* con prototipos y definiciones de macros para uso de la librería de funciones y macros de *OpenMP*.\n",
    "\n",
    "* La función `Hello` será ejecutada por los *threads*.\n",
    "\n",
    "* La función `omp_get_thread_num` da el *rank* asignado por el *run time system* a cada *thread*.\n",
    "\n",
    "* Con la función `omp_get_num_threads` se obtiene el número de *threads* que realizaron un *fork* del *thread* principal.\n",
    "\n",
    "* Obsérvese que para la compilación se utilizó la *flag* `-fopenmp` para soporte de *OpenMP*.\n",
    "\n",
    "* Dependiendo del número de cores de nuestro sistema tendremos diferentes número de `printf`'s.\n",
    "\n",
    "* Lo que continúa a la línea de `#pragma omp parallel` es un *structured block*, esto es, un *statement* o conjunto de *statements* que tienen un punto de entrada y un punto de salida. En el caso anterior sólo se llama a la función `Hello`, no se permiten statements como el siguiente:\n",
    "\n",
    "```C\n",
    "#pragma omp parallel\n",
    "\n",
    "if(...) break;\n",
    "\n",
    "```\n",
    "\n",
    "ni tampoco:\n",
    "    \n",
    "```C\n",
    "#pragma omp parallel\n",
    "\n",
    "    {\n",
    "        if(variable == valor) return 1;\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "```\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación de la directiva `parallel` podemos usar diferentes tipos de *clauses*. Una *clause* en *OpenMP* es un texto que modifica una directiva. Por ejemplo, podemos usar la *clause* `num_threads` para especificar el número de threads que ejecutarán el *structured block*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Clause* `num_threads`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: *Hello world*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hello_world_omp_num_threads.c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hello_world_omp_num_threads.c\n"
     ]
    }
   ],
   "source": [
    "%%file hello_world_omp_num_threads.c\n",
    "#include<stdio.h>\n",
    "#include<stdlib.h>\n",
    "#include<omp.h> \n",
    "\n",
    "void Hello(void); \n",
    "int main(){\n",
    "    int n_threads = 5;\n",
    "    #pragma omp parallel num_threads(n_threads) \n",
    "        Hello();\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "\n",
    "void Hello(void){\n",
    "    int my_rank = omp_get_thread_num(); \n",
    "    int num_th = omp_get_num_threads(); \n",
    "    printf(\"Hola del thread: %d de %d\\n\", my_rank, num_th);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcc -Wall -fopenmp hello_world_omp_num_threads.c -o hello_world_omp_num_threads.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola del thread: 0 de 5\n",
      "Hola del thread: 1 de 5\n",
      "Hola del thread: 2 de 5\n",
      "Hola del thread: 3 de 5\n",
      "Hola del thread: 4 de 5\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./hello_world_omp_num_threads.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Reduction clause* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*OpenMP* provee la *reduction clause* para aplicar la operación de suma (operador binario) a cada resultado calculado de un *thread* de forma repetida y almacenar en una variable la respuesta.\n",
    "\n",
    "Nombramos *reduction variable* a la variable que almacenará los resultados intermedios calculados por cada *thread* y *reduction operator* a la operación binaria (por ejemplo una suma o multiplicación) que se aplica repetidamente a una secuencia de operandos para obtener un resultado, en un proceso que se le nombra *reduction*. \n",
    "\n",
    "Por ejemplo, si `A` es un arreglo de `n` enteros, el cálculo:\n",
    "\n",
    "```C\n",
    "int sum = 0;\n",
    "for(i=0;i<n;i++)\n",
    "    sum += A[i];\n",
    "``` \n",
    "\n",
    "es un proceso de *reduction* en el que el *reduction operator* es la suma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En openMP utilizamos la *reduction clause* en la *parallel directive*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```C\n",
    "sum_shared = 0.0\n",
    "#pragma omp parallel num_threads(conteo_threads) reduction(+: sum_shared)\n",
    "    sum_shared += Rcf_parallel(a,h_hat,n_subintervals_per_core);\n",
    "\n",
    "```\n",
    "\n",
    "Con la *reduction clause* openMP crea una variable privada por cada *thread* y el *run time system* almacena el resultado de cada *thread* en esta variable. *openMP* también crea una *critical section* y los valores almacenados en las variables privadas son sumadas en esta *critical section* y almacenados en la *reduction variable* `sum_shared`. El *reduction operator* es: `+`.\n",
    "\n",
    "La sintaxis de la *reduction clause* es:\n",
    "\n",
    "```C\n",
    "reduction( <operator>: <variable list>)\n",
    "```\n",
    "\n",
    "El *reduction operator* puede ser cualquiera de los operadores: `+,*,-,&,|,^,&&,||`. Cabe señalar que el proceso de *reduction* asume que los operadores utilizados cumplen con la propiedad asociativa (por ejemplo, el operador de resta no cumple con esto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable que está en la *reduction clause* es compartida. Sin embargo una variable privada es creada por cada *thread* en el *team* (**con el mismo nombre** que aparece en la *reduction clause*) y si un *thread* ejecuta un statement en el *parallel block* que involucra a la variable, entonces se utiliza la variable privada y al finalizar el *parallel block*, los valores calculados en las variables privadas son combinados en la variable compartida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de uso de nombres de variables al definir variables privadas y compartidas en *reduction clause*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`private_shared_variable_reduction_clause_example.c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing private_shared_variable_reduction_clause_example.c\n"
     ]
    }
   ],
   "source": [
    "%%file private_shared_variable_reduction_clause_example.c\n",
    "#include<stdio.h>\n",
    "#include<stdlib.h>\n",
    "#include<omp.h>\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "    long n_threads;\n",
    "    int private_variable;\n",
    "    int sum_shared = 7;\n",
    "        \n",
    "    n_threads = strtol(argv[1], NULL, 10);\n",
    "    \n",
    "    printf(\"variable sum_shared al inicio : %d\\n\", sum_shared);\n",
    "    \n",
    "    #pragma omp parallel num_threads(n_threads) reduction(+: sum_shared)\n",
    "    {\n",
    "        int my_rank = omp_get_thread_num();\n",
    "        if(my_rank==0)\n",
    "            printf(\"sum_shared, printf 1 del thread 0: %d\\n\", sum_shared);\n",
    "        else\n",
    "            printf(\"sum_shared, prinftf 1 thread 1: %d\\n\", sum_shared);\n",
    "        sum_shared = (my_rank==0)?10:20;\n",
    "        if(my_rank==0)\n",
    "            printf(\"sum_shared, printf 2 del thread 0: %d\\n\", sum_shared);\n",
    "        else\n",
    "            printf(\"sum_shared, printf 2 del thread 1: %d\\n\", sum_shared);\n",
    "        private_variable = (my_rank==0)?1:2;\n",
    "        sum_shared += private_variable;\n",
    "        if(my_rank==0)\n",
    "            printf(\"sum_shared, printf 3 del thread 0: %d\\n\", sum_shared);\n",
    "        else\n",
    "            printf(\"sum_shared, printf 3 del thread 1: %d\\n\", sum_shared);\n",
    "    \n",
    "    }\n",
    "    printf(\"sum_shared al final de la directive parallel %d\\n\", sum_shared);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcc -Wall -fopenmp private_shared_variable_reduction_clause_example.c -o private_shared_variable_reduction_clause_example.out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable sum_shared al inicio : 7\n",
      "sum_shared, printf 1 del thread 0: 0\n",
      "sum_shared, printf 2 del thread 0: 10\n",
      "sum_shared, printf 3 del thread 0: 11\n",
      "sum_shared, prinftf 1 thread 1: 0\n",
      "sum_shared, printf 2 del thread 1: 20\n",
      "sum_shared, printf 3 del thread 1: 22\n",
      "sum_shared al final de la directive parallel 40\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./private_shared_variable_reduction_clause_example.out 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentario\n",
    "\n",
    "La variable `sum_shared` se inicializa en 0. En general, las variables privadas creadas para una *reduction clause* son inicializadas al *identity value* para el *operator*. Por ejemplo, si el *operator* es la multiplicación, entonces las variables privadas son inicializadas en 1.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo regla compuesta del rectángulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la medición de tiempos se utilizaron las ligas: [measuring-time-in-millisecond-precision](https://stackoverflow.com/questions/16764276/measuring-time-in-millisecond-precision) y [find-execution-time-c-program](https://www.techiedelight.com/find-execution-time-c-program/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Rcf_openmp.c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Rcf_openmp.c\n"
     ]
    }
   ],
   "source": [
    "%%file Rcf_openmp.c\n",
    "#include<stdio.h>\n",
    "#include<stdlib.h>\n",
    "#include<omp.h>\n",
    "#include<math.h> \n",
    "#include<time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "double Rcf_parallel(double a, double h_hat, int ns_p);\n",
    "\n",
    "double f(double node);\n",
    "\n",
    "int main(){\n",
    "    double sum_shared = 0.0; //shared variable for threads\n",
    "    double a = 0.0, b = 1.0;\n",
    "    int n = 1e7; //number of subintervals\n",
    "    double h_hat = (b-a)/n;\n",
    "    int n_subintervals_per_core; //number of subintervals assigned to each core\n",
    "    int n_threads[7] = {0};//n_threads must divide exactly n variable\n",
    "    int len_n_threads_array = 0;\n",
    "    double obj = 0.7468241328124271;\n",
    "    struct timeval start;\n",
    "    struct timeval end;\n",
    "    long seconds;\n",
    "    long long mili;\n",
    "    int i;\n",
    "    n_threads[0] = 1;\n",
    "    n_threads[1] = 2;\n",
    "    n_threads[2] = 4;\n",
    "    n_threads[3] = 8;\n",
    "    n_threads[4] = 16;\n",
    "    n_threads[5] = 32;\n",
    "    n_threads[6] = 64;\n",
    "    len_n_threads_array = sizeof(n_threads)/sizeof(n_threads[0]);\n",
    "    for(i=0;i<len_n_threads_array;i++){\n",
    "        n_subintervals_per_core = n/n_threads[i];\n",
    "        gettimeofday(&start, NULL);\n",
    "        #pragma omp parallel num_threads(n_threads[i]) reduction(+: sum_shared)\n",
    "            sum_shared += Rcf_parallel(a,h_hat,n_subintervals_per_core);\n",
    "        sum_shared = h_hat*sum_shared;\n",
    "        gettimeofday(&end, NULL);\n",
    "        seconds = (end.tv_sec - start.tv_sec);\n",
    "        mili = 1000*(seconds) + (end.tv_usec - start.tv_usec)/1000;\n",
    "        printf(\"Integral de %f a %f = %1.15e\\n\", a,b,sum_shared);\n",
    "        printf(\"Error relativo de la solución: %1.15e\\n\", fabs(sum_shared-obj)/fabs(obj));\n",
    "        printf(\"Tiempo de ejecución con %d threads: %lld miliseconds\\n\", n_threads[i],mili);\n",
    "        printf(\"----------------------\\n\");\n",
    "        sum_shared = 0.0;\n",
    "    }\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "double Rcf_parallel(double a, double h_hat, int n_s_c){\n",
    "    int begin, end;\n",
    "    int my_rank = omp_get_thread_num();\n",
    "    double local_int=0;\n",
    "    int i;\n",
    "    double x;\n",
    "    begin = my_rank*n_s_c;\n",
    "    end = begin + n_s_c; \n",
    "    for(i=begin;i<=end-1;i++){\n",
    "        x = a+(i+1/2.0)*h_hat;\n",
    "        local_int += f(x);\n",
    "    }   \n",
    "    return local_int;\n",
    "}\n",
    "        \n",
    "double f(double node){\n",
    "    double f_value;\n",
    "    f_value = exp(-pow(node,2));\n",
    "    return f_value;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcc -Wall -fopenmp Rcf_openmp.c -o Rcf_openmp.out -lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral de 0.000000 a 1.000000 = 7.468241328123898e-01\n",
      "Error relativo de la solución: 4.994950214975770e-14\n",
      "Tiempo de ejecución con 1 threads: 491 miliseconds\n",
      "----------------------\n",
      "Integral de 0.000000 a 1.000000 = 7.468241328124163e-01\n",
      "Error relativo de la solución: 1.441994556109076e-14\n",
      "Tiempo de ejecución con 2 threads: 239 miliseconds\n",
      "----------------------\n",
      "Integral de 0.000000 a 1.000000 = 7.468241328124452e-01\n",
      "Error relativo de la solución: 2.423145491193603e-14\n",
      "Tiempo de ejecución con 4 threads: 121 miliseconds\n",
      "----------------------\n",
      "Integral de 0.000000 a 1.000000 = 7.468241328124374e-01\n",
      "Error relativo de la solución: 1.382530863073651e-14\n",
      "Tiempo de ejecución con 8 threads: 60 miliseconds\n",
      "----------------------\n",
      "Integral de 0.000000 a 1.000000 = 7.468241328124298e-01\n",
      "Error relativo de la solución: 3.567821582125550e-15\n",
      "Tiempo de ejecución con 16 threads: 30 miliseconds\n",
      "----------------------\n",
      "Integral de 0.000000 a 1.000000 = 7.468241328124294e-01\n",
      "Error relativo de la solución: 3.121843884359856e-15\n",
      "Tiempo de ejecución con 32 threads: 21 miliseconds\n",
      "----------------------\n",
      "Integral de 0.000000 a 1.000000 = 7.468241328124260e-01\n",
      "Error relativo de la solución: 1.486592325885646e-15\n",
      "Tiempo de ejecución con 64 threads: 24 miliseconds\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./Rcf_openmp.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentarios\n",
    "\n",
    "* Dividimos el número de subintervalos  **n** entre el número de *threads* que deseamos lanzar, por esto, **n** debe ser **divisible** entre las entradas del *array* `n_threads`. Esta cantidad es el número de subintervalos contiguos que le corresponden a cada *thread*.\n",
    "\n",
    "* Además, se debe de agregar el resultado de la suma de cada *thread*. Esto es posible realizar de forma sencilla definiendo una variable que sea compartida. Al definir tal variable en la función *main* y antes de un *parallel block* el *default* es que sea considerada como compartida.\n",
    "\n",
    "* Las variables que son privadas se definen en la función `Rcf_parallel`.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Ejercicio\n",
    ":class: tip\n",
    "\n",
    "Implementar la regla de Simpson con *OpenMP* utilizando una *reduction clause* en una máquina de AWS con las mismas características que la que se presenta en esta nota y medir tiempo de ejecución.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Multiprocessing](https://docs.python.org/3.1/library/multiprocessing.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación estándar de Python, [CPython](https://github.com/python/cpython) no utiliza múltiples *cores* por *default* para procesamiento. En el apartado de [Cpython-Design](https://en.wikipedia.org/wiki/CPython) se menciona el por qué CPython no soporta ejecución *multithreaded* o *multiprocesses* y a continuación se coloca unos párrafos de tal discusión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A particular feature of CPython is that it makes use of a global interpreter lock (GIL) on each CPython interpreter process, which means that within a single process, only one thread may be processing Python bytecode at any one time. This does not mean that there is no point in multithreading; the most common multithreading scenario is where threads are mostly waiting on external processes to complete.*\n",
    "\n",
    "*For example, imagine when three threads are servicing separate clients. One thread may be waiting for a client to reply, and another may be waiting for a database query to execute, while the third thread is actually processing Python code.*\n",
    "\n",
    "*However, the GIL does mean that CPython is not suitable for processes that implement CPU-intensive algorithms in Python code that could potentially be distributed across multiple cores. ...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El módulo *multiprocessing* permite realizar procesamientos basados en procesos o *threads* para compartir trabajo y datos y lidiar con lo mencionado anteriormente. \n",
    "\n",
    "Se recomienda usar este módulo para el *shared memory programming* y para trabajos que son demandantes de CPU. Para paralelizar trabajos demandantes en I/O no se recomienda su uso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentario\n",
    "\n",
    "Otro módulo en *Python* para procesamiento utilizando los cores de tu máquina es [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html) que provee el comportamiento principal de *multiprocessing*. Ver [concurrent-futures-processpoolexecutor-vs-multiprocessing-pool-pool](https://stackoverflow.com/questions/38311431/concurrent-futures-processpoolexecutor-vs-multiprocessing-pool-pool?noredirect=1&lq=1) y [concurrent-futures-vs-multiprocessing-in-python-3](https://stackoverflow.com/questions/20776189/concurrent-futures-vs-multiprocessing-in-python-3) para más sobre *concurrent.futures* y *concurrent.futures* vs *multiprocessing*.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nota sobre el GIL y *multiprocessing*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque en *Python* los *threads* son nativos del sistema operativo (esto es, no se simulan, son realmente *threads* del sistema operativo creados en el hardware), están limitados por el *global interpreter lock* (GIL), de modo que un sólo *thread* interactúe con un objeto Python en un único tiempo. Esto degrada el *performance* de los programas pues los threads **compiten** por el *GIL* presente en el intérprete de Python, ver [Understanding the Python GIL](http://www.dabeaz.com/GIL/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al usar el módulo *multiprocessing* ejecutamos en paralelo un número de intérpretes Python (CPython), cada uno con su propio espacio de memoria privada y su propio GIL que se ejecutan en un instante (y con un *thread*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Observación\n",
    ":class: tip\n",
    "\n",
    "En *multiprocessing* se utilizan subprocesos en lugar de *threads* y en lugar de *fork* se realiza *spawn*.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Dask](https://docs.dask.org/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Parallel](https://www.rdocumentation.org/packages/parallel/versions/3.6.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias de interés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Use cases with dask](https://stories.dask.org/en/latest/)\n",
    "\n",
    "* [dask-tutorial](https://github.com/dask/dask-tutorial)\n",
    "\n",
    "En *dask* se hace referencia al uso de funciones *pure*. Ver: [Pure Functions by Default](https://distributed.dask.org/en/latest/client.html#pure-functions-by-default) y [Function Purity](https://toolz.readthedocs.io/en/latest/purity.html) para ejemplos de funciones *pure*.\n",
    "\n",
    "En [Dask JupyterLab Extension](https://www.youtube.com/watch?v=EX_voquHdk0) se muestra cómo instalar la extensión en jupyterlab para dask.\n",
    "\n",
    "* [snow Simplified](http://www.sfu.ca/~sblay/R/snow.html)\n",
    "\n",
    "* [Using foreach and iterators for manual parallel execution](https://docs.microsoft.com/en-us/machine-learning-server/r/how-to-revoscaler-distributed-computing-foreach)\n",
    "\n",
    "Paquete de *R*: [future](https://www.rdocumentation.org/packages/future/versions/1.21.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Ejercicios\n",
    ":class: tip\n",
    "\n",
    "1.Resuelve los ejercicios y preguntas de la nota.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preguntas de comprehensión:**\n",
    "\n",
    "1)Menciona diferencias que surgen en un programa que se ejecuta en un sistema de memoria compartida contra los que se ejecutan en un sistema de memoria distribuida.\n",
    "\n",
    "2)¿A qué se le llama no determinismo y da un ejemplo en el que esto surge en un sistema de memoria compartida?\n",
    "\n",
    "3)¿Qué es una *critical section*? ¿qué es una *race condition*? ¿cómo se puede lidiar con las *critical sections*?\n",
    "\n",
    "4)¿Cuál es la terminología para nombrar a las variables que pueden ser accesadas por todos los *threads* y para las variables que sólo pueden ser accesadas por un *thread*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias:**\n",
    "\n",
    "1. P. Pacheco, An Introduction to Parallel Programming, Morgan Kaufmann, 2011.\n",
    "\n",
    "2. M. Gorelick, I. Ozsvald, High Performance Python, O'Reilly Media, 2014.\n",
    "\n",
    "3. N. Matloff, Parallel Computing for Data Science. With Examples in R, C++ and CUDA, 2014.\n",
    "\n",
    "4. B. W. Kernighan, D. M. Ritchie, The C Programming Language, Prentice Hall Software Series, 1988\n",
    "\n",
    "5. [C/extensiones_a_C/openMP](https://github.com/palmoreck/programming-languages/tree/master/C/extensiones_a_C/openMP)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
