{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tjCNM9809JZB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JGxS3AdWt0sx"
   },
   "outputs": [],
   "source": [
    "def bfgs(f, gradiente, x_init, tol=1e-3):\n",
    "    \"\"\"\n",
    "    Cálculo de aproximación numérica de mínimo de una función por el método de BFGS.\n",
    "    Se usa búsqueda de línea de el paquete scipy. \n",
    "    Args:\n",
    "    \n",
    "        f (function): función a la cual aproximar el mínimo.\n",
    "        \n",
    "        gradiente (function): Expresión para el gradiente de f.\n",
    "        \n",
    "        x_init (np.array): Punto inicial del cual seguirá el método.\n",
    "        \n",
    "        tol (float): Tolerancia para el problema.\n",
    "        \n",
    "    Regresa:\n",
    "    \n",
    "        xk (np.array): Valor final de la aproximación. \n",
    "\n",
    "        k (integer): Número de iteraciones. \n",
    "    \"\"\"\n",
    "    # Se inicializa el número de iteraciones\n",
    "    k = 0\n",
    "\n",
    "    # Se inicializa el gradiente\n",
    "    grad_k = gradiente(x_init)\n",
    "\n",
    "    # Se calcula el tamaño necesario para la Hessiana `Hess`, dependiendo del tamaño \n",
    "    # del vector x_init. Se inicializa como la identidad. \n",
    "    n = len(x_init)\n",
    "    Hess = np.eye(n)\n",
    "\n",
    "    # Inicialización del vector solución. \n",
    "    x_k = x_init\n",
    "\n",
    "    # Inicializamos alfa\n",
    "    alfa = 0.001\n",
    "\n",
    "    while np.linalg.norm(grad_k,2) > tol and k < 2000:\n",
    "        # pk: Aproximación a la dirección de descenso por Newton. \n",
    "        p_k = - Hess @ grad_k\n",
    "\n",
    "        # Busqueda de línea de scipy. Regresa varias cosas, pero solamente nos \n",
    "        # interesa el primer término, alfa. \n",
    "        alfa = sp.optimize.line_search(f, gradiente, x_k, p_k)[0]\n",
    "        if alfa == None: \n",
    "          alfa = 0.01\n",
    "\n",
    "        # Creando nueva x para siguiente iteración. \n",
    "        x_new = x_k + alfa * p_k\n",
    "        \n",
    "        # Calculamos `s` y `y` para la iteración k, y actualizamos x y el gradiente\n",
    "        s_k = x_new - x_k\n",
    "        x_k = x_new\n",
    "        grad_new = gradiente(x_new)\n",
    "        y_k = grad_new - grad_k\n",
    "        grad_k = grad_new\n",
    "        \n",
    "\n",
    "        # Actualización de la aproximación a la Hessiana\n",
    "        rho_k = 1.0 / (y_k.transpose() @ s_k)\n",
    "        A1 = np.eye(n) - rho_k * np.outer(s_k, y_k)\n",
    "        A2 = np.eye(n) - rho_k * np.outer(y_k, s_k)\n",
    "        Hess = A1 @ (Hess @ A2) + (rho_k * np.outer(s_k,s_k))\n",
    "\n",
    "        # Subimos el número de iteraciones\n",
    "        k += 1\n",
    "    return (x_k, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0a60dwnr9pGY"
   },
   "outputs": [],
   "source": [
    "# Definimos una función objetivo para prueba.\n",
    "def prueba(p):\n",
    "    return -(p**2 * (1-p)**6)\n",
    "# Gradiente de prueba (en este caso derivada, porque es una sola dimensión)\n",
    "def prueba_gradiente(p):\n",
    "    return 2 * p * (4*p - 1) * (1-p)**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nd0Mr33_9pJJ",
    "outputId": "33947cc9-cb48-4a7a-b84a-f0c652c27a1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "x_k, k = bfgs(f = prueba, \n",
    "                 gradiente = prueba_gradiente, \n",
    "                 x_init = np.array([0.1]), \n",
    "                tol = 1e-6)\n",
    "\n",
    "print(x_k)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = scipy.optimize.minimize(fun = prueba, \n",
    "                        jac = prueba_gradiente,\n",
    "                        x0 = np.array([0.1]), \n",
    "                        method='BFGS', \n",
    "                        tol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sol.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol.x == x_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Test1D.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
